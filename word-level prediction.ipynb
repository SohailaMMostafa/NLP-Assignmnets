{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wJ6cUJUKEMv",
        "outputId": "e3f13234-7e9b-4bc6-a0d7-e3994fc661eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=9ab3baffb75a78b35d4acd5d61a5e398c86aa04cd900f3f70c086abb1a9a8827\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia\n",
        "import wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input,Conv1D,MaxPooling1D,Dense,GlobalMaxPooling1D,Embedding,SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import gensim\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import random\n",
        "\n",
        "# nltk.download('wordnet', \"/kaggle/working/nltk_data/\")\n",
        "# nltk.download('omw-1.4', \"/kaggle/working/nltk_data/\")\n",
        "# ! unzip /kaggle/working/nltk_data/corpora/wordnet.zip -d /kaggle/working/nltk_data/corpora\n",
        "# ! unzip /kaggle/working/nltk_data/corpora/omw-1.4.zip -d /kaggle/working/nltk_data/corpora\n",
        "# nltk.data.path.append(\"/kaggle/working/nltk_data/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOarn86IKKeX",
        "outputId": "fbbb8649-8210-4fd5-d456-b44c96bf5f51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch entire articles\n",
        "full_article1 = wikipedia.page(\"Artificial Intelligence\").content\n",
        "full_article2 = wikipedia.page(\"neural network\").content\n",
        "full_article3 = wikipedia.page(\"Deep learning\").content\n",
        "full_article4 = wikipedia.page(\"Machine ;earning\").content\n",
        "full_article5 = wikipedia.page(\"Data Science\").content\n",
        "full_article6 = wikipedia.page(\"Recurrent Neural Network\").content\n",
        "full_article7 = wikipedia.page(\"convolutional neural network\").content"
      ],
      "metadata": {
        "id": "irnJKsHTKKjm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [[full_article1], [full_article2], [full_article3], [full_article4], [full_article5], [full_article6], [full_article7]]\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wzf1CcOKKyx",
        "outputId": "726b3dc0-4165-4f1f-d9d6-8c912bf6aff0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and uses learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nAI technology is widely used throughout industry, government, and science. Some high-profile applications include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nAlan Turing was the first person to conduct substantial research in the field that he called machine intelligence. Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism, followed by periods of disappointment and loss of funding, known as AI winter. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\\nThe growing use of artificial intelligence in the 21st century is influencing a societal and economic shift towards increased automation, data-driven decision-making, and the integration of AI systems into various economic sectors and areas of life, impacting job markets, healthcare, government, industry, and education. This raises questions about the long-term effects, ethical implications, and risks of AI, prompting discussions about regulatory policies to ensure the safety and benefits of the technology. \\nThe various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field\\'s long-term goals.\\nTo reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\n\\n\\n== Goals ==\\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\\n\\n\\n=== Reasoning and problem-solving ===\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\\n\\n\\n=== Knowledge representation ===\\n\\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.\\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.\\n\\n\\n=== Planning and decision-making ===\\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.\\nIn classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\\nIn some problems, the agent\\'s preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.\\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.\\n\\n\\n=== Learning ===\\nMachine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.\\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.\\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\\n\\n\\n=== Natural language processing ===\\nNatural language processing (NLP) allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.\\nEarly work, based on Noam Chomsky\\'s generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023 these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.\\n\\n\\n=== Perception ===\\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.\\nThe field includes speech recognition, image classification, facial recognition, object recognition, and robotic perception.\\n\\n\\n=== Social intelligence ===\\n\\nAffective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood. For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\\nHowever, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.\\n\\n\\n=== General intelligence ===\\nA machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.\\n\\n\\n== Techniques ==\\nAI research uses a wide variety of techniques to accomplish the goals above.\\n\\n\\n=== Search and optimization ===\\nAI can solve many problems by intelligently searching through many possible solutions. There are two very different kinds of search used in AI: state space search and local search.\\n\\n\\n==== State space search ====\\nState space search searches through a tree of possible states to try to find a goal state. For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.\\nSimple exhaustive searches are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. \"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.\\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and counter-moves, looking for a winning position.\\n\\n\\n==== Local search ====\\nLocal search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.\\nGradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks.\\nAnother type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.\\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).\\n\\n\\n=== Logic ===\\nFormal logic is used for reasoning and knowledge representation.\\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\") and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").\\nDeductive reasoning in logic is the process of proving a new statement (conclusion) from other statements that are given and assumed to be true (the premises). Proofs can be structured as proof trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules.\\nGiven a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem. In the more general case of the clausal form of first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.\\nInference in both Horn clause logic and first-order logic is undecidable, and therefore intractable. However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with computation in other symbolic programming languages.\\nFuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.\\nNon-monotonic logics, including logic programming with negation as failure, are designed to handle default reasoning.\\nOther specialized versions of logic have been developed to describe many complex domains.\\n\\n\\n=== Probabilistic methods for uncertain reasoning ===\\n\\nMany problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis, and information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.\\nBayesian networks are a tool that can be used for reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks) and perception (using dynamic Bayesian networks).\\n\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).\\n\\n\\n=== Classifiers and statistical learning methods ===\\nThe simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand. Classifiers are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.\\nThere are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm. K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\\nThe naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.\\nNeural networks are also used as classifiers.\\n\\n\\n=== Artificial neural networks ===\\n\\nAn artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.\\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.\\nNeural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.\\nIn feedforward neural networks the signal passes in only one direction. Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.\\nPerceptrons\\nuse only a single layer of neurons, deep learning uses multiple layers.\\nConvolutional neural networks strengthen the connection between neurons that are \"close\" to each other—this is especially important in image processing, where a local set of neurons must identify an \"edge\" before the network can identify an object.\\n\\n\\n=== Deep learning ===\\n\\nDeep learning\\nuses several layers of neurons between the network\\'s inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.\\nDeep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification, and others. The reason that deep learning performs so well in so many applications is not known as of 2023.\\nThe sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.\\n\\n\\n=== GPT ===\\nGenerative pre-trained transformers (GPT) are large language models that are based on the semantic relationships between words in sentences (natural language processing). Text-based GPT models are pre-trained on a large corpus of text which can be from the internet. The pre-training consists in predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pre-training, GPT models accumulate knowledge about the world, and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are still prone to generating falsehoods called \"hallucinations\", although this can be reduced with RLHF and quality data. They are used in chatbots, which allow you to ask a question or request a task in simple text.\\nCurrent models and services include: Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot and LLaMA. Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.\\n\\n\\n=== Specialized hardware and software ===\\n\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models\\' training. Historically, specialized languages, such as Lisp, Prolog, Python and others, had been used.\\n\\n\\n== Applications ==\\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple\\'s Face ID or Microsoft\\'s DeepFace and Google\\'s FaceNet) and image labeling (used by Facebook, Apple\\'s iPhoto and TikTok).\\n\\n\\n=== Health and medicine ===\\n\\nThe application of AI in medicine and medical research has the potential to increase patient care and quality of life. Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.\\nFor medical research, AI is an important tool for processing and integrating big data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication. It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research. New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein. In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria. In 2024, researchers used machine learning to accelerate the search for Parkinson\\'s disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson\\'s disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.\\n\\n\\n=== Games ===\\n\\nGame playing programs have been used since the 1950s to demonstrate and test AI\\'s most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. In 2011, in a Jeopardy! quiz show exhibition match, IBM\\'s question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then in 2017 it defeated Ke Jie, who was the best Go player in the world. Other programs handle imperfect-information games, such as the poker-playing program Pluribus. DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games. In 2019, DeepMind\\'s AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map. In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world\\'s best Gran Turismo drivers using deep reinforcement learning.\\n\\n\\n=== Military ===\\n\\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams. AI was incorporated into military operations in Iraq and Syria.\\nIn November 2023, US Vice President Kamala Harris disclosed a declaration signed by 31 nations to set guardrails for the military use of AI. The commitments include using legal reviews to ensure the compliance of military AI with international laws, and being cautious and transparent in the development of this technology.\\n\\n\\n=== Generative AI ===\\n\\nIn the early 2020s, generative AI gained widespread prominence. In March 2023, 58% of U.S. adults had heard about ChatGPT and 14% had tried it. The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion sparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat, the fictional arrest of Donald Trump, and a hoax of an attack on the Pentagon, as well as the usage in professional creative arts.\\n\\n\\n=== Industry-specific tasks ===\\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes. A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\\nIn agriculture, AI has helped farmers identify areas that need irrigation, fertilization, pesticide treatments or increasing yield. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\\n\\n\\n== Ethics ==\\n\\nAI has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified. In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.\\n\\n\\n=== Risks and harm ===\\n\\n\\n==== Privacy and copyright ====\\n\\nMachine-learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\\nTechnology companies collect a wide range of data from their users, including online activity, geolocation data, video and audio.\\nFor example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them. Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.\\nAI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy. Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of \\'what they know\\' to the question of \\'what they\\'re doing with it\\'.\"\\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\". Website owners who do not wish to have their content scraped can indicate it in a \"robots.txt\" file. In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI. Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.\\n\\n\\n==== Misinformation ====\\n\\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem.\\nIn 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films or human writing. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda. AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.\\n\\n\\n==== Algorithmic bias and fairness ====\\n\\nMachine learning applications will be biased if they learn from biased data. The developers may not be aware that the bias exists.\\nBias can be introduced by the way training data is selected and by the way a model is deployed. If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.\\nFairness in machine learning is the study of how to prevent the harm caused by algorithmic bias. It has become serious area of academic study within AI. Researchers have discovered it is not always possible to define \"fairness\" in a way that satisfies all stakeholders.\\nOn June 28, 2015, Google Photos\\'s new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people, a problem called \"sample size disparity\". Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.\\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist.\\nIn 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. In 2017, several researchers showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.\\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".\\nMoritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn\\'t work.\"\\nCriticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist. Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is necessarily descriptive and not proscriptive.\\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.\\nAt its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.\\n\\n\\n==== Lack of transparency ====\\n\\nMany AI systems are so complex that their designers cannot explain how they reach their decisions. Particularly with deep neural networks, in which there are a large amount of non-linear relationships between inputs and outputs. But some popular explainability techniques exist.\\nIt is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale. Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.\\nPeople who have been harmed by an algorithm\\'s decision have a right to an explanation. Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union\\'s General Data Protection Regulation in 2016 included an explicit statement that this right exists. Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.\\nDARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try and solve these problems. \\nThere are several possible solutions to the transparency problem. SHAP tried to solve the transparency problems by visualising the contribution of each feature to the output. LIME can locally approximate a model with a simpler, interpretable model. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network have learned and produce output that can suggest what the network is learning.\\n\\n\\n==== Bad actors and weaponized AI ====\\n\\nArtificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states.\\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction. Even when used in conventional warfare, it is unlikely that they will be unable to reliably choose targets and could potentially kill an innocent person. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations\\' Convention on Certain Conventional Weapons, however the United States and others disagreed. By 2015, over fifty countries were reported to be researching battlefield robots.\\nAI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware. All these technologies have been available since 2020 or earlier—AI facial recognition systems are already being used for mass surveillance in China.\\nThere many other ways that AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.\\n\\n\\n==== Reliance on industry giants ====\\nTraining AI systems requires an enormous amount of computing power. Usually only Big Tech companies have the financial resources to make such investments. Smaller startups such as Cohere and OpenAI end up buying access to data centers from Google and Microsoft respectively.\\n\\n\\n==== Technological unemployment ====\\n\\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.\\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we\\'re in uncharted territory\" with AI. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed. Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\". The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies. In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.\\nFrom the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.\\n\\n\\n==== Existential risk ====\\n\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\". This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character. These sci-fi scenarios are misleading in several ways.\\nFirst, AI does not require human-like \"sentience\" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager). Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can\\'t fetch the coffee if you\\'re dead.\" In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity\\'s morality and values so that it is \"fundamentally on our side\".\\nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.\\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. Personalities such as Stephen Hawking, Bill Gates, and Elon Musk have expressed concern about existential risk from AI.\\nAI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI. In 2023, many leading AI experts issued the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".\\nOther researchers, however, spoke in favor of a less dystopian view. AI pioneer Juergen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\" While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\" Andrew Ng also argued that \"it\\'s a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\" Yann LeCun \"scoffs at his peers\\' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\" In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine. However, after 2016, the study of current and future risks and possible solutions became a serious area of research.\\n\\n\\n=== Ethical machines and alignment ===\\n\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.\\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\\nThe field of machine ethics is also called computational morality,\\nand was founded at an AAAI symposium in 2005.\\nOther approaches include Wendell Wallach\\'s \"artificial moral agents\" and Stuart J. Russell\\'s three principles for developing provably beneficial machines.\\n\\n\\n=== Open source ===\\nActive organizations in the AI open-source community include Hugging Face, Google, EleutherAI and Meta. Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight, meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case. Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism), and that once released on the Internet, they can\\'t be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.\\n\\n\\n=== Frameworks ===\\nArtificial Intelligence projects can have their ethical permissibility tested while designing, developing, and implementing an AI system. An AI framework such as the Care and Act Framework containing the SUM values—developed by the Alan Turing Institute tests projects in four main areas:\\n\\nRESPECT the dignity of individual people\\nCONNECT with other people sincerely, openly and inclusively\\nCARE for the wellbeing of everyone\\nPROTECT social values, justice and the public interest\\nOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE\\'s Ethics of Autonomous Systems initiative, among others; however, these principles do not go without their criticisms, especially regards to the people chosen contributes to these frameworks.\\nPromotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\\nThe AI Safety Institute in the UK has released a testing toolset called ‘Inspect’ for AI safety evaluations available under a MIT open-source licence which is freely available on Github and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.\\n\\n\\n=== Regulation ===\\n\\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone. Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI. Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia. The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI. In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, governments officials and academics.\\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity. In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".\\nIn November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks. 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.\\n\\n\\n== History ==\\n\\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing\\'s theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning. This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\". \\nThey developed several areas of research that would become part of AI,\\nsuch as McCullouch and Pitts design for \"artificial neurons\" in 1943, and Turing\\'s influential 1950 paper \\'Computing Machinery and Intelligence\\', which introduced the Turing test and showed that \"machine intelligence\" was plausible.\\nThe field of AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial intelligence laboratories were set up at a number of British and U.S. Universities in the latter 1950s and early 1960s.\\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field. Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\". Marvin Minsky agreed, writing, \"within a generation ... the problem of creating \\'artificial intelligence\\' will substantially be solved\". They had, however, underestimated the difficulty of the problem. In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky\\'s and Papert\\'s book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.\\nIn the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan\\'s fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.\\nUp to this point, most of AI\\'s funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition, and began to look into \"sub-symbolic\" approaches. Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.\\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics). By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".\\nHowever, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.\\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.\\nFor many specific tasks, other methods were abandoned.\\nDeep learning\\'s success was based on both hardware improvements (faster computers, graphics processing units, cloud computing) and access to large amounts of data (including curated datasets, such as ImageNet). Deep learning\\'s success led to an enormous increase in interest and funding in AI. The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.\\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\\nIn the late teens and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program was taught only the rules of the game and developed strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text. These programs, and others, inspired an aggressive AI boom, where large companies began investing billions in AI research. According to AI Impacts, about $50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".\\nAbout 800,000 \"AI\"-related U.S. job openings existed in 2022.\\n\\n\\n== Philosophy ==\\n\\n\\n=== Defining artificial intelligence ===\\n\\nAlan Turing wrote in 1950 \"I propose to consider the question \\'can machines think\\'?\" He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\". He devised the Turing test, which measures the ability of a machine to simulate human conversation. Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks\"\\nRussell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure. However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts,\" they wrote, \"do not define the goal of their field as making \\'machines that fly so exactly like pigeons that they can fool other pigeons.\\'\" AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".\\nMcCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\". Another AI founder, Marvin Minsky similarly describes it as \"the ability to solve hard problems\". The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals. These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible.\\nAnother definition has been adopted by Google, a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\\n\\n\\n=== Evaluating approaches to AI ===\\nNo established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\\n\\n\\n==== Symbolic AI and its limits ====\\nSymbolic AI (or \"GOFAI\") simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"\\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec\\'s paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult. Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge. Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.\\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\\n\\n\\n==== Neat vs. scruffy ====\\n\\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s, but eventually was seen as irrelevant. Modern AI has elements of both.\\n\\n\\n==== Soft vs. hard computing ====\\n\\nFinding a provably correct or optimal solution is intractable for many important problems. Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\n\\n\\n==== Narrow vs. general AI ====\\n\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field\\'s long-term goals. General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\\n\\n\\n=== Machine consciousness, sentience, and mind ===\\n\\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\n\\n\\n==== Consciousness ====\\n\\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett\\'s consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.\\n\\n\\n==== Computationalism and functionalism ====\\n\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.\\nPhilosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\" Searle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.\\n\\n\\n==== AI welfare and rights ====\\nIt is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree. But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals. Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights. Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.\\nIn 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities. Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part to society on their own.\\nProgress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.\\n\\n\\n== Future ==\\n\\n\\n=== Superintelligence and the singularity ===\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.\\nIf research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".\\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\\n\\n\\n=== Transhumanism ===\\nRobot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.\\nEdward Fredkin argues that \"artificial intelligence is the next stage in evolution\", an idea first proposed by Samuel Butler\\'s \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.\\n\\n\\n== In fiction ==\\n\\nThought-capable artificial beings have appeared as storytelling devices since antiquity, and have been a persistent theme in science fiction.\\nA common trope in these works began with Mary Shelley\\'s Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke\\'s and Stanley Kubrick\\'s 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.\\nIsaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov\\'s laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov\\'s laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.\\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek\\'s R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\\n\\n\\n== See also ==\\nArtificial intelligence detection software – Software to detect AI-generated contentPages displaying short descriptions of redirect targets\\nBehavior selection algorithm – Algorithm that selects actions for intelligent agents\\nBusiness process automation – Technology-enabled automation of complex business processes\\nCase-based reasoning – Process of solving new problems based on the solutions of similar past problems\\nComputational intelligence – Ability of a computer to learn a specific task from data or experimental observation\\nDigital immortality – Hypothetical concept of storing a personality in digital form\\nEmergent algorithm – Algorithm exhibiting emergent behavior\\nFemale gendering of AI technologies – Gender biases in digital technologyPages displaying short descriptions of redirect targets\\nGlossary of artificial intelligence – List of definitions of terms and concepts commonly used in the study of artificial intelligence\\nIntelligence amplification – Use of information technology to augment human intelligence\\nMind uploading – Hypothetical process of digitally emulating a brain\\nRobotic process automation – Form of business process automation technology\\nWeak artificial intelligence – Form of artificial intelligence\\nWetware computer – Computer composed of organic material\\n\\n\\n== Explanatory notes ==\\n\\n\\n== References ==\\n\\n\\n=== AI textbooks ===\\nThe two most widely used textbooks in 2023. (See the Open Syllabus).\\n\\nRussell, Stuart J.; Norvig, Peter. (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0134610993. LCCN 20190474.\\nRich, Elaine; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0070087705.\\nThese were the four of the most widely used AI textbooks in 2008:\\n\\n\\n=== History of AI ===\\n\\n\\n=== Other sources ===\\n\\n\\n== Further reading ==\\n\\n\\n== External links ==\\n\\n\"Artificial Intelligence\". Internet Encyclopedia of Philosophy.\\nThomason, Richmond. \"Logic and Artificial Intelligence\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\\nArtificial Intelligence. BBC Radio 4 discussion with John Agar, Alison Adam & Igor Aleksander (In Our Time, 8 December 2005).\\nTheranostics and AI – The Next Advance in Cancer Precision Medicine'],\n",
              " ['A neural network is a group of interconnected units called neurons that send signals to one another. Neurons can be either biological cells or mathematical models. While individual neurons are simple, many of them together in a network can perform complex tasks. There are two main types of neural network.\\n\\nIn neuroscience, a biological neural network is a physical structure found in brains and complex nervous systems – a population of nerve cells connected by synapses.\\nIn machine learning, an artificial neural network is a mathematical model used to approximate nonlinear functions. Artificial neural networks are used to solve artificial intelligence problems.\\n\\n\\n== In biology ==\\n\\nIn the context of biology, a neural network is a population of biological neurons chemically connected to each other by synapses. A given neuron can be connected to hundreds of thousands of synapses.\\nEach neuron sends and receives electrochemical signals called action potentials to its connected neighbors. A neuron can serve an excitatory role, amplifying and propagating signals it receives, or an inhibitory role, suppressing signals instead.\\nPopulations of interconnected neurons that are smaller than neural networks are called neural circuits. Very large interconnected networks are called large scale brain networks, and many of these together form brains and nervous systems.\\nSignals generated by neural networks in the brain eventually travel through the nervous system and across neuromuscular junctions to muscle cells, where they cause contraction and thereby motion.\\n\\n\\n== In machine learning ==\\n\\nIn the context of machine learning, a neural network is an artificial mathematical model used to approximate nonlinear functions. While early artificial neural networks were physical machines, today they are almost always implemented in software.\\nNeurons in an artificial neural network are usually arranged into layers, with information passing from the first layer (the input layer) through one or more intermediate layers (hidden layers) to the final layer (the output layer).\\nThe \"signal\" input to each neuron is a number, specifically a linear combination of the outputs of the connected neurons in the previous layer. The signal each neuron outputs is calculated from this number, according to its activation function. The behavior of the network depends on the strengths (or weights) of the connections between neurons. A network is trained by modifying these weights through empirical risk minimization or backpropagation in order to fit some preexisting dataset.\\nNeural networks are used to solve problems in artificial intelligence, and have thereby found applications in many disciplines, including predictive modeling, adaptive control, facial recognition, handwriting recognition, general game playing, and generative AI.\\n\\n\\n== History ==\\n\\nThe theoretical base for contemporary neural networks was independently proposed by Alexander Bain in 1873 and William James in 1890. Both posited that human thought emerged from interactions among large numbers of neurons inside the brain. In 1949, Donald Hebb described Hebbian learning, the idea that neural networks can change and learn over time by strengthening a synapse every time a signal travels along it.\\nArtificial neural networks were originally used to model biological neural networks starting in the 1930s under the approach of connectionism. However, starting with the invention of the perceptron, a simple artificial neural network, by Warren McCulloch and Walter Pitts in 1943, followed by the implementation of one in hardware by Frank Rosenblatt in 1957,\\nartificial neural networks became increasingly used for machine learning applications instead, and increasingly different from their biological counterparts.\\n\\n\\n== See also ==\\nEmergence\\nBiological cybernetics\\nBiologically-inspired computing\\n\\n\\n== References =='],\n",
              " ['Deep learning is the subset of machine learning methods based on neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.\\nDeep-learning architectures such as deep neural networks, deep belief networks, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, in particular the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low quality models for that purpose.\\n\\n\\n== Overview ==\\nMost modern deep learning models are based on multi-layered neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.\\nFundamentally, deep learning refers to a class of machine learning algorithms in which a hierarchy of layers is used to transform input data into a slightly more abstract and composite representation. For example, in an image recognition model, the raw input may be an image (represented as a tensor of pixels). The first representational layer may attempt to identify basic shapes such as lines and circles, the second layer may compose and encode arrangements of edges, the third layer may encode a nose and eyes, and the fourth layer may recognize that the image contains a face.\\nImportantly, a deep learning process can learn which features to optimally place in which level on its own. Prior to deep learning, machine learning techniques often involved hand-crafted feature engineering to transform the data into a more suitable representation for a classification algorithm to operate upon. In the deep learning approach, features are not hand-crafted and the model discovers useful feature representations from the data automatically. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.\\nThe word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\\nDeep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.\\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.\\n\\n\\n== Interpretations ==\\nDeep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.\\nThe classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as Kunihiko Fukushima\\'s rectified linear unit.\\nThe universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.\\nThe probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.\\n\\n\\n== History ==\\nThere were two types of artificial neural network (ANN): feedforward neural networks (FNNs) and recurrent neural networks (RNNs). RNNs have cycles in their connectivity structure, FNNs don\\'t. In the 1920s, Wilhelm Lenz and Ernst Ising created and analyzed the Ising model which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun\\'ichi Amari made this architecture adaptive. His learning RNN was popularised by John Hopfield in 1982.\\nCharles Tappert writes that Frank Rosenblatt developed and explored all of the basic ingredients of the deep learning systems of today, referring to Rosenblatt\\'s 1962 book which introduced multilayer perceptron (MLP) with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. It also introduced variants, including a version with four-layer perceptrons where the last two layers have learned weights (and thus a proper multilayer perceptron).:\\u200asection 16\\u200a In addition, term deep learning was proposed in 1986 by Rina Dechter although the history of its appearance is apparently more complicated.\\nThe first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey Ivakhnenko and Lapa in 1967. A 1971 paper described a deep network with eight layers trained by the group method of data handling.\\nThe first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun\\'ichi Amari. In computer experiments conducted by Amari\\'s student Saito, a five layer MLP with two modifiable layers learned  internal representations to classify non-linearily separable pattern classes. In 1987 Matthew Brand reported that wide 12-layer nonlinear perceptrons could be fully end-to-end trained to reproduce logic functions of nontrivial circuit depth via gradient descent on small batches of random input/output samples, but concluded that training time on contemporary hardware (sub-megaflop computers) made the technique impractical, and proposed using fixed random early layers as an input hash for a single modifiable layer.  Instead, subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\\nIn 1970, Seppo Linnainmaa published the reverse mode of automatic differentiation of discrete connected networks of nested differentiable functions. This became known as backpropagation. It is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673 to networks of differentiable nodes. \\nThe terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt, but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation already in 1960 in the context of control theory. In 1982, Paul Werbos applied backpropagation to MLPs in the way that has become standard. In 1985, David E. Rumelhart et al. published an experimental analysis of the technique.\\nDeep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers began with the Neocognitron introduced by Kunihiko Fukushima in 1980. In 1969, he also introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for CNNs and deep learning in general. CNNs have become an essential tool for computer vision.\\nThe term Deep Learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.\\nIn 1988, Wei Zhang et al. applied the backpropagation algorithm \\nto a convolutional neural network (a simplified Neocognitron with convolutional interconnections between the image feature layers and the last fully connected layer) for alphabet recognition. They also proposed an implementation of the CNN with an optical computing system. \\nIn 1989, Yann LeCun et al. applied backpropagation to a CNN with the purpose of recognizing handwritten ZIP codes on mail. While the algorithm worked, training required 3 days. Subsequently, Wei Zhang, et al. modified their model by removing the last fully connected layer and applied it for medical image object segmentation in 1991 and breast cancer detection in mammograms in 1994. LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks  digitized in 32x32 pixel images.\\nIn the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, Jürgen Schmidhuber (1992) proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning. It uses predictive coding  to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by distilling a higher level chunker network into a lower level automatizer network. In 1993, a chunker solved a deep learning task whose depth exceeded 1000.\\nIn 1992, Jürgen Schmidhuber also published an alternative to RNNs which is now called a linear Transformer or a  Transformer with linearized self-attention (save for a normalization operator). It learns internal spotlights of attention: a slow feedforward neural network learns by gradient descent to control the fast weights of another neural network through outer products of self-generated activation patterns FROM and TO (which are now called key and value for self-attention). This fast weight attention mapping is applied to a query pattern.\\nThe modern Transformer was introduced by Ashish Vaswani et al. in their 2017 paper \"Attention Is All You Need\". \\nIt combines this with a softmax operator and a projection matrix.\\nTransformers have increasingly become the model of choice for natural language processing. Many modern large language models such as ChatGPT, GPT-4, and BERT use it. Transformers are also increasingly being used in computer vision.\\nIn 1991, Jürgen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network\\'s gain is the other network\\'s loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in a generative adversarial network (GAN) by Ian Goodfellow et al. Here the environmental reaction is 1 or 0 depending on whether the first network\\'s output is in a given set. This can be used to create realistic deepfakes. Excellent image quality is achieved by Nvidia\\'s StyleGAN (2018) based on the Progressive GAN by Tero Karras et al. Here the GAN generator is grown from small to large scale in a pyramidal fashion.\\nSepp Hochreiter\\'s diploma thesis (1991) was called \"one of the most important documents in the history of machine learning\" by his supervisor Schmidhuber. It not only tested the neural history compressor, but also identified and analyzed the vanishing gradient problem. Hochreiter proposed recurrent residual connections to solve this problem. This led to the deep learning method called long short-term memory (LSTM), published in 1997. LSTM recurrent neural networks can learn \"very deep learning\" tasks with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. The \"vanilla LSTM\" with forget gate was introduced in 1999 by Felix Gers, Schmidhuber and Fred Cummins. LSTM has become the  most cited neural network of the 20th century.\\nIn 2015, Rupesh Kumar Srivastava, Klaus Greff, and Schmidhuber used LSTM principles to create the Highway network, a feedforward neural network with hundreds of layers, much deeper than previous networks. 7 months later, Kaiming He, Xiangyu Zhang;  Shaoqing Ren, and Jian Sun won the ImageNet 2015 competition with an open-gated or gateless Highway network variant called Residual neural network. This has become the most cited neural network of the 21st century.\\nIn 1994, André de Carvalho, together with Mike Fairhurst and David Bisset, published experimental results of a multi-layer boolean neural network, also known as a weightless neural network, composed of a 3-layers self-organising feature extraction neural network module (SOFT) followed by a multi-layer classification neural network module (GSN), which were independently trained. Each layer in the feature extraction module extracted features with growing complexity regarding the previous layer.\\nIn 1995, Brendan Frey demonstrated that it was possible to train (over two days) a network containing six fully connected layers and several hundred hidden units using the wake-sleep algorithm, co-developed with Peter Dayan and Hinton.\\nSince 1997, Sven Behnke extended the feed-forward hierarchical convolutional approach in the Neural Abstraction Pyramid by lateral and backward connections in order to flexibly incorporate context into decisions and iteratively resolve local ambiguities.\\nSimpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) were a popular choice in the 1990s and 2000s, because of artificial neural networks\\' computational cost and a lack of understanding of how the brain wires its biological networks.\\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power. Most speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government\\'s NSA and DARPA, SRI studied deep neural networks (DNNs) in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 National Institute of Standards and Technology Speaker Recognition evaluation. The SRI deep neural network was then deployed in the Nuance Verifier, representing the first major industrial application of deep learning. The principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s, showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.\\nSpeech recognition was taken over by LSTM. In 2003, LSTM started to become competitive with traditional speech recognizers on certain tasks. In 2006, Alex Graves, Santiago Fernández, Faustino Gomez, and Schmidhuber combined it with connectionist temporal classification (CTC) in stacks of LSTM RNNs. In 2015, Google\\'s speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM, which they made available through Google Voice Search.\\nThe impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around 2010.\\nIn 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh showed how a many-layered feedforward neural network could be effectively pre-trained one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then fine-tuning it using supervised backpropagation. The papers referred to learning for deep belief nets.\\nThe 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.  That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.\\nIn 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.\\nDeep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks were superseded for ASR by CTC for LSTM. but are more successful in computer vision.\\nAdvances in hardware have driven renewed interest in deep learning. In 2009, Nvidia was involved in what was called the \"big bang\" of deep learning, \"as deep-learning neural networks were trained with Nvidia graphics processing units (GPUs)\". That year, Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times. In particular, GPUs are well-suited for the matrix/vector computations involved in machine learning. GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days. Further, specialized hardware and algorithm optimizations can be used for efficient processing of deep learning models.\\n\\n\\n=== Deep learning revolution ===\\n\\nIn the late 2000s, deep learning started to outperform other methods in machine learning competitions.\\nIn 2009, a long short-term memory trained by connectionist temporal classification (Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber, 2006) was the first RNN to win pattern recognition contests, winning three competitions in connected handwriting recognition. Google later used CTC-trained LSTM for speech recognition on the smartphone.\\nSignificant impacts in image or object recognition were felt from 2011 to 2012. Although CNNs trained by backpropagation had been around for decades, and GPU implementations of NNs for years, including CNNs, faster implementations of CNNs on GPUs were needed to progress on computer vision. In 2011, the DanNet by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and Jürgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3. Also in 2011, DanNet won the ICDAR Chinese handwriting contest, and in May 2012, it won the ISBI image segmentation contest. Until 2011, CNNs did not play a major role at computer vision conferences, but in June 2012, a paper by Ciresan et al. at the leading conference CVPR showed how max-pooling CNNs on GPU can dramatically improve many vision benchmark records.  In September 2012, DanNet also won the ICPR contest on analysis of large medical images for cancer detection, and in the following year also the MICCAI Grand Challenge on the same topic. In October 2012, the similar AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. \\nThe VGG-16 network by Karen Simonyan and Andrew Zisserman further reduced the error rate and\\nwon the ImageNet 2014 competition, following a similar trend in large-scale speech recognition.\\nImage classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.\\nIn 2012, a team led by George E. Dahl won the \"Merck Molecular Activity Challenge\" using multi-task deep neural networks to predict the biomolecular target of one drug. In 2014, Sepp Hochreiter\\'s group used deep learning to detect off-target and toxic effects of environmental chemicals in nutrients, household products and drugs and won the \"Tox21 Data Challenge\" of NIH, FDA and NCATS.\\nIn 2016, Roger Parloff mentioned a \"deep learning revolution\" that has transformed the AI industry.\\nIn March 2019, Yoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the Turing Award for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.\\n\\n\\n== Neural networks ==\\n\\nArtificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.\\nAn ANN is based on a collection of connected units called artificial neurons, (analogous to biological neurons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\\nTypically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\\nThe original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information.\\nNeural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\\nAs of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\").\\n\\n\\n=== Deep neural networks ===\\nA deep neural network (DNN) is an artificial neural network with multiple layers between the input and output layers. There are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions. These components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.\\nFor example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer, and complex DNN have many layers, hence the name \"deep\" networks.\\nDNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of primitives. The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network. For instance, it was proved that sparse multivariate polynomials are exponentially easier to approximate with DNNs than with shallow networks.\\nDeep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.\\nDNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights. That way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data.\\nRecurrent neural networks, in which data can flow in any direction, are used for applications such as language modeling. Long short-term memory is particularly effective for this use.\\nConvolutional neural networks (CNNs) are used in computer vision. CNNs also have been applied to acoustic modeling for automatic speech recognition (ASR).\\n\\n\\n==== Challenges ====\\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues are overfitting and computation time.\\nDNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. Regularization methods such as Ivakhnenko\\'s unit pruning or weight decay (\\n  \\n    \\n      \\n        \\n          ℓ\\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\ell _{2}}\\n  \\n-regularization) or sparsity (\\n  \\n    \\n      \\n        \\n          ℓ\\n          \\n            1\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\ell _{1}}\\n  \\n-regularization) can be applied during training to combat overfitting. Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies. Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.\\nDNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate, and initial weights. Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as batching (computing the gradient on several training examples at once rather than individual examples) speed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.\\nAlternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (cerebellar model articulation controller) is one such kind of neural network. It doesn\\'t require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.\\n\\n\\n== Hardware ==\\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.\\nSpecial electronic circuits called deep learning processors were designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in Huawei cellphones and cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform. Cerebras Systems has also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).\\nAtomically thin semiconductors are considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage.\\nIn 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on floating-gate field-effect transistors (FGFETs).\\nIn 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for parallel convolutional processing. The authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through wavelength division multiplexing in conjunction with frequency combs, and (2) extremely high data modulation speeds. Their system can execute trillions of multiply-accumulate operations per second, indicating the potential of integrated photonics in data-heavy AI applications.\\n\\n\\n== Applications ==\\n\\n\\n=== Automatic speech recognition ===\\n\\nLarge-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.\\nThe initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.\\n\\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003–2007, accelerated progress in eight major areas:\\n\\nScale-up/out and accelerated DNN training and decoding\\nSequence discriminative training\\nFeature processing by deep models with solid understanding of the underlying mechanisms\\nAdaptation of DNNs and related deep models\\nMulti-task and transfer learning by DNNs and related deep models\\nCNNs and how to design them to best exploit domain knowledge of speech\\nRNN and its rich LSTM variants\\nOther types of deep models including tensor-based models and integrated deep generative/discriminative models.\\nAll major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning.\\n\\n\\n=== Image recognition ===\\n\\nA common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.\\nDeep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.\\nDeep learning-trained vehicles now interpret 360° camera views. Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\\n\\n\\n=== Visual art processing ===\\n\\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of\\n\\nidentifying the style period of a given painting\\nNeural Style Transfer –  capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video\\ngenerating striking imagery based on random visual input fields.\\n\\n\\n=== Natural language processing ===\\n\\nNeural networks have been used for implementing language models since the early 2000s. LSTM helped to improve machine translation and language modeling.\\nOther key techniques in this field are negative sampling and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures provide the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, named-entity recognition (token classification), text classification, and others.\\nRecent developments generalize word embedding to sentence embedding.\\nGoogle Translate (GT) uses a large end-to-end long short-term memory (LSTM) network. Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system \"learns from millions of examples\". It translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages. The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\". GT uses English as an intermediate between most language pairs.\\n\\n\\n=== Drug discovery and toxicology ===\\n\\nA large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects. Research has explored use of deep learning to predict the biomolecular targets, off-targets, and toxic effects of environmental chemicals in nutrients, household products and drugs.\\nAtomNet is a deep learning system for structure-based rational drug design. AtomNet was used to predict novel candidate biomolecules for disease targets such as the Ebola virus and multiple sclerosis.\\nIn 2017 graph neural networks were used for the first time to predict various properties of molecules in a large toxicology data set. In 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.\\n\\n\\n=== Customer relationship management ===\\n\\nDeep reinforcement learning has been used to approximate the value of possible direct marketing actions, defined in terms of RFM variables. The estimated value function was shown to have a natural interpretation as customer lifetime value.\\n\\n\\n=== Recommendation systems ===\\n\\nRecommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations. Multi-view deep learning has been applied for learning user preferences from multiple domains. The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\\n\\n\\n=== Bioinformatics ===\\n\\nAn autoencoder ANN was used in bioinformatics, to predict gene ontology annotations and gene-function relationships.\\nIn medical informatics, deep learning was used to predict sleep quality based on data from wearables and predictions of health complications from electronic health record data.\\nDeep neural networks have shown unparalleled performance in predicting protein structure, according to the sequence of the amino acids that make it up. In 2020, AlphaFold, a deep-learning based system, achieved a level of accuracy significantly higher than all previous computational methods.\\n\\n\\n=== Deep Neural Network Estimations ===\\nDeep neural networks can be used to estimate the entropy of a stochastic process and called Neural Joint Entropy Estimator (NJEE). Such an estimation provides insights on the effects of input random variables on an independent random variable. Practically, the DNN is trained as a classifier that maps an input vector or matrix X to an output probability distribution over the possible classes of random variable Y, given input X. For example, in image classification tasks, the NJEE maps a vector of pixels\\' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a Softmax layer with number of nodes that is equal to the alphabet size of Y. NJEE uses continuously differentiable activation functions, such that the conditions for the universal approximation theorem holds. It is shown that this method provides a strongly consistent estimator and outperforms other methods in case of large alphabet sizes.\\n\\n\\n=== Medical image analysis ===\\nDeep learning has been shown to produce competitive results in medical application such as cancer cell classification, lesion detection, organ segmentation and image enhancement. Modern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.\\n\\n\\n=== Mobile advertising ===\\nFinding the appropriate mobile audience for mobile advertising is always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server. Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\\n\\n\\n=== Image restoration ===\\nDeep learning has been successfully applied to inverse problems such as denoising, super-resolution, inpainting, and film colorization. These applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\" which trains on an image dataset, and Deep Image Prior, which trains on the image that needs restoration.\\n\\n\\n=== Financial fraud detection ===\\nDeep learning is being successfully applied to financial fraud detection, tax evasion detection, and anti-money laundering.\\n\\n\\n=== Materials science ===\\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system\\'s predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.\\n\\n\\n=== Military ===\\nThe United States Department of Defense applied deep learning to train robots in new tasks through observation.\\n\\n\\n=== Partial differential equations ===\\nPhysics informed neural networks have been used to solve partial differential equations in both forward and inverse problems in a data driven manner. One example is the reconstructing fluid flow governed by the Navier-Stokes equations. Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods relies on.\\n\\n\\n=== Image reconstruction ===\\nImage reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging  and ultrasound imaging.\\n\\n\\n=== Epigenetic clock ===\\n\\nAn epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples. The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.\\n\\n\\n== Relation to human cognitive and brain development ==\\nDeep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant\\'s brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".\\nA variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism. Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.\\nAlthough a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.\\n\\n\\n== Commercial activity ==\\nFacebook\\'s AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.\\nGoogle\\'s DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.\\nIn 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.\\nAs of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot with the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".\\n\\n\\n== Criticism and comment ==\\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\\n\\n\\n=== Theory ===\\n\\nA main criticism concerns the lack of theory surrounding some methods. Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear. (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.\\nOthers point out that deep learning should be looked at as a step towards realizing strong AI, not as an all-encompassing solution. Despite the power of deep learning methods, they still lack much of the functionality needed to realize this goal entirely. Research psychologist Gary Marcus noted:\\n\\nRealistically, deep learning is only part of the larger challenge of building intelligent machines. Such techniques lack ways of representing causal relationships (...) have no obvious ways of performing logical inferences, and they are also still a long way from integrating abstract knowledge, such as information about what objects are, what they are for, and how they are typically used. The most powerful A.I. systems, like Watson (...) use techniques like deep learning as just one element in a very complicated ensemble of techniques, ranging from the statistical technique of Bayesian inference to deductive reasoning.\\n\\nIn further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on The Guardian\\'s website.\\n\\n\\n=== Errors ===\\nSome deep learning architectures display problematic behaviors, such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014) and misclassifying minuscule perturbations of correctly classified images (2013). Goertzel hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component artificial general intelligence (AGI) architectures. These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar decompositions of observed entities and events. Learning a grammar (visual or linguistic) from training data would be equivalent to restricting the system to commonsense reasoning that operates on concepts in terms of grammatical production rules and is a basic goal of both human language acquisition and artificial intelligence (AI).\\n\\n\\n=== Cyber threat ===\\nAs deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception. By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"adversarial attack\".\\nIn 2016 researchers used one ANN to doctor images in trial and error fashion, identify another\\'s focal points, and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system. One defense is reverse image search, in which a possible fake image is submitted to a site such as TinEye that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken.\\nAnother group showed that certain psychedelic spectacles could fool a facial recognition system into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to stop signs and caused an ANN to misclassify them.\\nANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the malware defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.\\nIn 2016, another group demonstrated that certain sounds could make the Google Now voice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".\\nIn \"data poisoning\", false data is continually smuggled into a machine learning system\\'s training set to prevent it from achieving mastery.\\n\\n\\n=== Data collection ethics ===\\n\\nMost Deep Learning systems rely on training and verification data that is generated and/or annotated by humans. It has been argued in media philosophy that not only low-paid clickwork (e.g. on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such. The philosopher Rainer Mühlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.\\nMühlhoff argues that in most commercial end-user applications of Deep Learning such as Facebook\\'s face recognition system, the need for training data does not stop once an ANN is trained. Rather, there is a continued demand for human-generated verification data to constantly calibrate and update the ANN. For this purpose, Facebook introduced the feature that once a user is automatically recognized in an image, they receive a notification. They can choose whether or not they like to be publicly labeled on the image, or tell Facebook that it is not them in the picture. This user interface is a mechanism to generate \"a constant stream of verification data\" to further train the network in real-time. As Mühlhoff argues, the involvement of human users to generate training and verification data is so typical for most commercial end-user applications of Deep Learning that such systems may be referred to as \"human-aided artificial intelligence\".\\n\\n\\n== See also ==\\nApplications of artificial intelligence\\nComparison of deep learning software\\nCompressed sensing\\nDifferentiable programming\\nEcho state network\\nList of artificial intelligence projects\\nLiquid state machine\\nList of datasets for machine-learning research\\nReservoir computing\\nScale space and deep learning\\nSparse coding\\nStochastic parrot\\nTopological deep learning\\n\\n\\n== References ==\\n\\n\\n== Further reading =='],\n",
              " ['A slot machine, fruit machine (British English), poker machine or pokies (Australian English and New Zealand English) is a gambling machine that creates a game of chance for its customers.\\nA slot machine\\'s standard layout features a screen displaying three or more reels that \"spin\" when the game is activated. Some modern slot machines still include a lever as a skeuomorphic design trait to trigger play. However, the mechanical operations of early machines have been superseded by random number generators, and most are now operated using buttons and touchscreens.\\nSlot machines include one or more currency detectors that validate the form of payment, whether coin, banknote, voucher, or token. The machine pays out according to the pattern of symbols displayed when the reels stop \"spinning\". Slot machines are the most popular gambling method in casinos and contribute about 70% of the average U.S. casino\\'s income.\\nDigital technology has resulted in variations in the original slot machine concept. As the player is essentially playing a video game, manufacturers can offer more interactive elements, such as advanced bonus rounds and more varied video graphics.\\n\\n\\n== Terms and their sources ==\\nThe \"slot machine\" term derives from the slots on the machine for inserting and retrieving coins. \"Fruit machine\" comes from the traditional fruit images on the spinning reels such as lemons and cherries. Slot machines are also known pejoratively as \"one-armed bandits\", alluding to the large mechanical levers affixed to the sides of early mechanical machines, and to the games\\' ability to empty players\\' pockets and wallets as thieves would.\\n\\n\\n== History ==\\n\\nSittman and Pitt of Brooklyn, New York, developed a gambling machine in 1891 that was a precursor to the modern slot machine. It contained five drums holding a total of 50 card faces and was based on poker. The machine proved extremely popular, and soon many bars in the city had one or more of them. Players would insert a nickel and pull a lever, which would spin the drums and the cards that they held, the player hoping for a good poker hand. There was no direct payout mechanism, so a pair of kings might get the player a free beer, whereas a royal flush could pay out cigars or drinks; the prizes were wholly dependent upon what the establishment would offer. To improve the odds for the house, two cards were typically removed from the deck, the ten of spades and the jack of hearts, doubling the odds against winning a royal flush. The drums could also be rearranged to further reduce a player\\'s chance of winning.\\nBecause of the vast number of possible wins in the original poker-based game, it proved practically impossible to make a machine capable of awarding an automatic payout for all possible winning combinations. At some time between 1887 and 1895, Charles Fey of San Francisco, California devised a much simpler automatic mechanism with three spinning reels containing a total of five symbols: horseshoes, diamonds, spades, hearts and a Liberty Bell; the bell gave the machine its name. By replacing ten cards with five symbols and using three reels instead of five drums, the complexity of reading a win was considerably reduced, allowing Fey to design an effective automatic payout mechanism. Three bells in a row produced the biggest payoff, ten nickels (50¢). Liberty Bell was a huge success and spawned a thriving mechanical gaming device industry. After a few years, the devices were banned in California, but Fey still could not keep up with the demand for them elsewhere. The Liberty Bell machine was so popular that it was copied by many slot machine manufacturers. The first of these, also called the \"Liberty Bell\", was produced by the manufacturer Herbert Mills in 1907. By 1908, \"bell\" machines had been installed in cigar stores, brothels and barber shops. Early machines, including an 1899 Liberty Bell, are now part of the Nevada State Museum\\'s Fey Collection.\\nThe first Liberty Bell machines produced by Mills used the same symbols on the reels as did Charles Fey\\'s original. Soon afterward, another version was produced with patriotic symbols, such as flags and wreaths, on the wheels. Later, a similar machine called the Operator\\'s Bell was produced that included the option of adding a gum-vending attachment. As the gum offered was fruit-flavored, fruit symbols were placed on the reels: lemons, cherries, oranges and plums. A bell was retained, and a picture of a stick of Bell-Fruit Gum, the origin of the bar symbol, was also present. This set of symbols proved highly popular and was used by other companies that began to make their own slot machines: Caille, Watling, Jennings and Pace.\\nA commonly used technique to avoid gambling laws in several states was to award food prizes. For this reason, several gumball and other vending machines were regarded with mistrust by the courts. The two Iowa cases of State v. Ellis and State v. Striggles are both used in criminal law classes to illustrate the concept of reliance upon authority as it relates to the axiomatic ignorantia juris non excusat (\"ignorance of the law is no excuse\"). In these cases, a mint vending machine was declared to be a gambling device because the machine would, by internally manufactured chance, occasionally give the next user several tokens exchangeable for more candy. Despite the display of the result of the next use on the machine, the courts ruled that \"[t]he machine appealed to the player\\'s propensity to gamble, and that is [a] vice.\"\\nIn 1963, Bally developed the first fully electromechanical slot machine called Money Honey (although earlier machines such as Bally\\'s High Hand draw-poker machine had exhibited the basics of electromechanical construction as early as 1940). Its electromechanical workings made Money Honey the first slot machine with a bottomless hopper and automatic payout of up to 500 coins without the help of an attendant. The popularity of this machine led to the increasing predominance of electronic games, with the side lever soon becoming vestigial.\\nThe first video slot machine was developed in 1976 in Kearny Mesa, California by the Las Vegas–based Fortune Coin Co. This machine used a modified 19-inch (48 cm) Sony Trinitron color receiver for the display and logic boards for all slot-machine functions. The prototype was mounted in a full-size, show-ready slot-machine cabinet. The first production units went on trial at the Las Vegas Hilton Hotel. After some modifications to defeat cheating attempts, the video slot machine was approved by the Nevada State Gaming Commission and eventually found popularity on the Las Vegas Strip and in downtown casinos. Fortune Coin Co. and its video slot-machine technology were purchased by IGT (International Gaming Technology) in 1978.\\nThe first American video slot machine to offer a \"second screen\" bonus round was Reel ’Em In, developed by WMS Industries in 1996. This type of machine had appeared in Australia from at least 1994 with the Three Bags Full game. With this type of machine, the display changes to provide a different game in which an additional payout may be awarded.\\n\\n\\n== Operation ==\\n\\nDepending on the machine, the player can insert cash or, in \"ticket-in, ticket-out\" machines, a paper ticket with a barcode, into a designated slot on the machine. The machine is then activated by means of a lever or button (either physical or on a touchscreen), which activates reels that spin and stop to rearrange the symbols. If a player matches a winning combination of symbols, the player earns credits based on the paytable. Symbols vary depending on the theme of the machine. Classic symbols include objects such as fruits, bells, and stylized lucky sevens. Most slot games have a theme, such as a specific style, location, or character. Symbols and other bonus features of the game are typically aligned with the theme. Some themes are licensed from popular media franchises, including films, television series (including game shows such as Wheel of Fortune, which has been one of the most popular lines of slot machines), entertainers, and musicians.\\nMulti-line slot machines have become more popular since the 1990s. These machines have more than one payline, meaning that visible symbols that are not aligned on the main horizontal may be considered as winning combinations. Traditional three-reel slot machines commonly have one, three, or five paylines while video slot machines may have 9, 15, 25, or as many as 1024 different paylines. Most accept variable numbers of credits to play, with 1 to 15 credits per line being typical. The higher the amount bet, the higher the payout will be if the player wins.\\nOne of the main differences between video slot machines and reel machines is in the way payouts are calculated. With reel machines, the only way to win the maximum jackpot is to play the maximum number of coins (usually three, sometimes four or even five coins per spin). With video machines, the fixed payout values are multiplied by the number of coins per line that is being bet. In other words: on a reel machine, the odds are more favorable if the gambler plays with the maximum number of coins available. However, depending on the structure of the game and its bonus features, some video slots may still include features that improve chances at payouts by making increased wagers.\\n\\n\"Multi-way\" games eschew fixed paylines in favor of allowing symbols to pay anywhere, as long as there is at least one in at least three consecutive reels from left to right. Multi-way games may be configured to allow players to bet by-reel: for example, on a game with a 3x5 pattern (often referred to as a 243-way game), playing one reel allows all three symbols in the first reel to potentially pay, but only the center row pays on the remaining reels (often designated by darkening the unused portions of the reels). Other multi-way games use a 4x5 or 5x5 pattern, where there are up to five symbols in each reel, allowing for up to 1,024 and 3,125 ways to win respectively. The Australian manufacturer Aristocrat Leisure brands games featuring this system as \"Reel Power\", \"Xtra Reel Power\" and \"Super Reel Power\" respectively. A variation involves patterns where symbols are adjacent to one another. Most of these games have a hexagonal reel formation, and much like multi-way games, any patterns not played are darkened out of use.\\nDenominations can range from 1 cent (\"penny slots\") all the way up to $100.00 or more per credit. The latter are typically known as \"high limit\" machines, and machines configured to allow for such wagers are often located in dedicated areas (which may have a separate team of attendants to cater to the needs of those who play there). The machine automatically calculates the number of credits the player receives in exchange for the cash inserted. Newer machines often allow players to choose from a selection of denominations on a splash screen or menu.\\n\\n\\n== Terminology ==\\nA bonus is a special feature of the particular game theme, which is activated when certain symbols appear in a winning combination. Bonuses and the number of bonus features vary depending upon the game. Some bonus rounds are a special session of free spins (the number of which is often based on the winning combination that triggers the bonus), often with a different or modified set of winning combinations as the main game and/or other multipliers or increased frequencies of symbols, or a \"hold and re-spin\" mechanic in which specific symbols (usually marked with values of credits or other prizes) are collected and locked in place over a finite number of spins. In other bonus rounds, the player is presented with several items on a screen from which to choose. As the player chooses items, a number of credits is revealed and awarded. Some bonuses use a mechanical device, such as a spinning wheel, that works in conjunction with the bonus to display the amount won.\\nA candle is a light on top of the slot machine. It flashes to alert the operator that change is needed, hand pay is requested or a potential problem with the machine. It can be lit by the player by pressing the \"service\" or \"help\" button.\\nCarousel refers to a grouping of slot machines, usually in a circle or oval formation.\\nA coin hopper is a container where the coins that are immediately available for payouts are held. The hopper is a mechanical device that rotates coins into the coin tray when a player collects credits/coins (by pressing a \"Cash Out\" button). When a certain preset coin capacity is reached, a coin diverter automatically redirects, or \"drops\", excess coins into a \"drop bucket\" or \"drop box\". (Unused coin hoppers can still be found even on games that exclusively employ Ticket-In, Ticket-Out technology, as a vestige.)\\nThe credit meter is a display of the amount of money or number of credits on the machine. On mechanical slot machines, this is usually a seven-segment display, but video slot machines typically use stylized text that suits the game\\'s theme and user interface.\\nThe drop bucket or drop box is a container located in a slot machine\\'s base where excess coins are diverted from the hopper. Typically, a drop bucket is used for low-denomination slot machines and a drop box is used for high-denomination slot machines. A drop box contains a hinged lid with one or more locks whereas a drop bucket does not contain a lid. The contents of drop buckets and drop boxes are collected and counted by the casino on a scheduled basis.\\nEGM is short for \"Electronic Gaming Machine\".\\nFree spins are a common form of bonus, where a series of spins are automatically played at no charge at the player\\'s current wager. Free spins are usually triggered via a scatter of at least three designated symbols (with the number of spins dependent on the number of symbols that land). Some games allow the free spins bonus to \"retrigger\", which adds additional spins on top of those already awarded. There is no theoretical limit to the number of free spins obtainable. Some games may have other features that can also trigger over the course of free spins.\\nA hand pay refers to a payout made by an attendant or at an exchange point (\"cage\"), rather than by the slot machine itself. A hand pay occurs when the amount of the payout exceeds the maximum amount that was preset by the slot machine\\'s operator. Usually, the maximum amount is set at the level where the operator must begin to deduct taxes. A hand pay could also be necessary as a result of a short pay.\\nHopper fill slip is a document used to record the replenishment of the coin in the coin hopper after it becomes depleted as a result of making payouts to players. The slip indicates the amount of coin placed into the hoppers, as well as the signatures of the employees involved in the transaction, the slot machine number and the location and the date.\\nMEAL book (Machine entry authorization log) is a log of the employee\\'s entries into the machine.\\nLow-level or slant-top slot machines include a stool so the player may sit down. Stand-up or upright slot machines are played while standing.\\nOptimal play is a payback percentage based on a gambler using the optimal strategy in a skill-based slot machine game.\\nPayline is a line that crosses through one symbol on each reel, along which a winning combination is evaluated. Classic spinning reel machines usually have up to nine paylines, while video slot machines may have as many as one hundred. Paylines could be of various shapes (horizontal, vertical, oblique, triangular, zigzag, etc.)\\nPersistent state refers to passive features on some slot machines, some of which able to trigger bonus payouts or other special features if certain conditions are met over time by players on that machine.\\nRoll-up is the process of dramatizing a win by playing sounds while the meters count up to the amount that has been won.\\nShort pay refers to a partial payout made by a slot machine, which is less than the amount due to the player. This occurs if the coin hopper has been depleted as a result of making earlier payouts to players. The remaining amount due to the player is either paid as a hand pay or an attendant will come and refill the machine.\\nA scatter is a pay combination based on occurrences of a designated symbol landing anywhere on the reels, rather than falling in sequence on the same payline. A scatter pay usually requires a minimum of three symbols to land, and the machine may offer increased prizes or jackpots depending on the number that land. Scatters are frequently used to trigger bonus games, such as free spins (with the number of spins multiplying based on the number of scatter symbols that land). The scatter symbol usually cannot be matched using wilds, and some games may require the scatter symbols to appear on consecutive reels in order to pay. On some multiway games, scatter symbols still pay in unused areas.\\nTaste is a reference to the small amount often paid out to keep a player seated and continuously betting. Only rarely will machines fail to pay even the minimum out over the course of several pulls.\\n\\nTilt is a term derived from electromechanical slot machines\\' \"tilt switches\", which would make or break a circuit when they were tilted or otherwise tampered with that triggered an alarm. While modern machines no longer have tilt switches, any kind of technical fault (door switch in the wrong state, reel motor failure, out of paper, etc.) is still called a \"tilt\".\\nA theoretical hold worksheet is a document provided by the manufacturer for every slot machine that indicates the theoretical percentage the machine should hold based on the amount paid in. The worksheet also indicates the reel strip settings, number of coins that may be played, the payout schedule, the number of reels and other information descriptive of the particular type of slot machine.\\nVolatility or variance refers to the measure of risk associated with playing a slot machine. A low-volatility slot machine has regular but smaller wins, while a high-variance slot machine has fewer but bigger wins.\\nWeight count is an American term referring to the total value of coins or tokens removed from a slot machine\\'s drop bucket or drop box for counting by the casino\\'s hard count team through the use of a weigh scale.\\nWild symbols substitute for most other symbols in the game (similarly to a joker card), usually excluding scatter and jackpot symbols (or offering a lower prize on non-natural combinations that include wilds). How jokers behave are dependent on the specific game and whether the player is in a bonus or free games mode. Sometimes wild symbols may only appear on certain reels, or have a chance to \"stack\" across the entire reel.\\n\\n\\n== Pay table ==\\n\\nEach machine has a table that lists the number of credits the player will receive if the symbols listed on the pay table line up on the pay line of the machine. Some symbols are wild and can represent many, or all, of the other symbols to complete a winning line. Especially on older machines, the pay table is listed on the face of the machine, usually above and below the area containing the wheels. On video slot machines, they are usually contained within a help menu, along with information on other features.\\n\\n\\n== Technology ==\\n\\n\\n=== Reels ===\\nHistorically, all slot machines used revolving mechanical reels to display and determine results. Although the original slot machine used five reels, simpler, and therefore more reliable, three reel machines quickly became the standard.\\nA problem with three reel machines is that the number of combinations is only cubic – the original slot machine with three physical reels and 10 symbols on each reel had only 103 = 1,000 possible combinations. This limited the manufacturer\\'s ability to offer large jackpots since even the rarest event had a likelihood of 0.1%. The maximum theoretical payout, assuming 100% return to player would be 1000 times the bet, but that would leave no room for other pays, making the machine very high risk, and also quite boring.\\nAlthough the number of symbols eventually increased to about 22, allowing 10,648 combinations, this still limited jackpot sizes as well as the number of possible outcomes.\\nIn the 1980s, however, slot machine manufacturers incorporated electronics into their products and programmed them to weight particular symbols. Thus the odds of losing symbols appearing on the payline became disproportionate to their actual frequency on the physical reel. A symbol would only appear once on the reel displayed to the player, but could, in fact, occupy several stops on the multiple reel.\\nIn 1984, Inge Telnaes received a patent for a device titled, \"Electronic Gaming Device Utilizing a Random Number Generator for Selecting the Reel Stop Positions\" (US Patent 4448419), which states: \"It is important to make a machine that is perceived to present greater chances of payoff than it actually has within the legal limitations that games of chance must operate.\" The patent was later bought by International Game Technology and has since expired.\\nA virtual reel that has 256 virtual stops per reel would allow up to 2563 = 16,777,216 final positions. The manufacturer could choose to offer a $1 million jackpot on a $1 bet, confident that it will only happen, over the long term, once every 16.8 million plays.\\n\\n\\n=== Computerization ===\\nWith microprocessors now ubiquitous, the computers inside modern slot machines allow manufacturers to assign a different probability to every symbol on every reel. To the player, it might appear that a winning symbol was \"so close\", whereas in fact the probability is much lower.\\nIn the 1980s in the U.K., machines embodying microprocessors became common. These used a number of features to ensure the payout was controlled within the limits of the gambling legislation. As a coin was inserted into the machine, it could go either directly into the cashbox for the benefit of the owner or into a channel that formed the payout reservoir, with the microprocessor monitoring the number of coins in this channel. The drums themselves were driven by stepper motors, controlled by the processor and with proximity sensors monitoring the position of the drums. A \"look-up table\" within the software allows the processor to know what symbols were being displayed on the drums to the gambler. This allowed the system to control the level of payout by stopping the drums at positions it had determined. If the payout channel had filled up, the payout became more generous; if nearly empty, the payout became less so (thus giving good control of the odds).\\n\\n\\n=== Video slot machines ===\\nVideo slot machines do not use mechanical reels, but use graphical reels on a computerized display. As there are no mechanical constraints on the design of video slot machines, games often use at least five reels, and may also use non-standard layouts. This greatly expands the number of possibilities: a machine can have 50 or more symbols on a reel, giving odds as high as 300 million to 1 against – enough for even the largest jackpot. As there are so many combinations possible with five reels, manufacturers do not need to weight the payout symbols (although some may still do so). Instead, higher paying symbols will typically appear only once or twice on each reel, while more common symbols earning a more frequent payout will appear many times. Video slot machines usually make more extensive use of multimedia, and can feature more elaborate minigames as bonuses. Modern cabinets typically use flat-panel displays, but cabinets using larger curved screens (which can provide a more immersive experience for the player) are not uncommon.\\nVideo slot machines typically encourage the player to play multiple \"lines\": rather than simply taking the middle of the three symbols displayed on each reel, a line could go from top left to the bottom right or any other pattern specified by the manufacturer. As each symbol is equally likely, there is no difficulty for the manufacturer in allowing the player to take as many of the possible lines on offer as desired – the long-term return to the player will be the same. The difference for the player is that the more lines they play, the more likely they are to get paid on a given spin (because they are betting more).\\nTo avoid seeming as if the player\\'s money is simply ebbing away (whereas a payout of 100 credits on a single-line machine would be 100 bets and the player would feel they had made a substantial win, on a 20-line machine, it would only be five bets and not seem as significant), manufacturers commonly offer bonus games, which can return many times their bet. The player is encouraged to keep playing to reach the bonus: even if they are losing, the bonus game could allow them to win back their losses.\\n\\n\\n=== Payout percentage ===\\n\\nSlot machines are typically programmed to pay out as winnings 0% to 99% of the money that is wagered by players. This is known as the \"theoretical payout percentage\" or RTP, \"return to player\". The minimum theoretical payout percentage varies among jurisdictions and is typically established by law or regulation. For example, the minimum payout in Nevada is 75%, in New Jersey 83%, and in Mississippi 80%. The winning patterns on slot machines – the amounts they pay and the frequencies of those payouts – are carefully selected to yield a certain fraction of the money paid to the \"house\" (the operator of the slot machine) while returning the rest to the players during play. Suppose that a certain slot machine costs $1 per spin and has a return to player (RTP) of 95%. It can be calculated that, over a sufficiently long period such as 1,000,000 spins, the machine will return an average of $950,000 to its players, who have inserted $1,000,000 during that time. In this (simplified) example, the slot machine is said to pay out 95%. The operator keeps the remaining $50,000. Within some EGM development organizations this concept is referred to simply as \"par\". \"Par\" also manifests itself to gamblers as promotional techniques: \"Our \\'Loose Slots\\' have a 93% payback! Play now!\"\\nA slot machine\\'s theoretical payout percentage is set at the factory when the software is written. Changing the payout percentage after a slot machine has been placed on the gaming floor requires a physical swap of the software or firmware, which is usually stored on an EPROM but may be loaded onto non-volatile random access memory (NVRAM) or even stored on CD-ROM or DVD, depending on the capabilities of the machine and the applicable regulations. Based on current technology, this is a time-consuming process and as such is done infrequently. In certain jurisdictions, such as New Jersey, the EPROM has a tamper-evident seal and can only be changed in the presence of Gaming Control Board officials. Other jurisdictions, including Nevada, randomly audit slot machines to ensure that they contain only approved software.\\nHistorically, many casinos, both online and offline, have been unwilling to publish individual game RTP figures, making it impossible for the player to know whether they are playing a \"loose\" or a \"tight\" game. Since the turn of the century, some information regarding these figures has started to come into the public domain either through various casinos releasing them—primarily this applies to online casinos—or through studies by independent gambling authorities.\\nThe return to player is not the only statistic that is of interest. The probabilities of every payout on the pay table is also critical. For example, consider a hypothetical slot machine with a dozen different values on the pay table. However, the probabilities of getting all the payouts are zero except the largest one. If the payout is 4,000 times the input amount, and it happens every 4,000 times on average, the return to player is exactly 100%, but the game would be dull to play. Also, most people would not win anything, and having entries on the paytable that have a return of zero would be deceptive. As these individual probabilities are closely guarded secrets, it is possible that the advertised machines with high return to player simply increase the probabilities of these jackpots. The casino could legally place machines of a similar style payout and advertise that some machines have 100% return to player. The added advantage is that these large jackpots increase the excitement of the other players.\\nThe table of probabilities for a specific machine is called the Probability and Accounting Report or PAR sheet, also PARS commonly understood as Paytable and Reel Strips. Mathematician Michael Shackleford revealed the PARS for one commercial slot machine, an original International Gaming Technology Red White and Blue machine. This game, in its original form, is obsolete, so these specific probabilities do not apply. He only published the odds after a fan of his sent him some information provided on a slot machine that was posted on a machine in the Netherlands. The psychology of the machine design is quickly revealed. There are 13 possible payouts ranging from 1:1 to 2,400:1. The 1:1 payout comes every 8 plays. The 5:1 payout comes every 33 plays, whereas the 2:1 payout comes every 600 plays. Most players assume the likelihood increases proportionate to the payout. The one mid-size payout that is designed to give the player a thrill is the 80:1 payout. It is programmed to occur an average of once every 219 plays. The 80:1 payout is high enough to create excitement, but not high enough that it makes it likely that the player will take their winnings and abandon the game. More than likely the player began the game with at least 80 times his bet (for instance there are 80 quarters in $20). In contrast the 150:1 payout occurs only on average of once every 6,241 plays. The highest payout of 2,400:1 occurs only on average of once every 643 = 262,144 plays since the machine has 64 virtual stops. The player who continues to feed the machine is likely to have several mid-size payouts, but unlikely to have a large payout. He quits after he is bored or has exhausted his bankroll.\\nDespite their confidentiality, occasionally a PAR sheet is posted on a website. They have limited value to the player, because usually a machine will have 8 to 12 different possible programs with varying payouts. In addition, slight variations of each machine (e.g., with double jackpots or five times play) are always being developed. The casino operator can choose which EPROM chip to install in any particular machine to select the payout desired. The result is that there is not really such a thing as a high payback type of machine, since every machine potentially has multiple settings. From October 2001 to February 2002, columnist Michael Shackleford obtained PAR sheets for five different nickel machines; four IGT games Austin Powers, Fortune Cookie, Leopard Spots and Wheel of Fortune and one game manufactured by WMS; Reel \\'em In. Without revealing the proprietary information, he developed a program that would allow him to determine with usually less than a dozen plays on each machine which EPROM chip was installed. Then he did a survey of over 400 machines in 70 different casinos in Las Vegas. He averaged the data, and assigned an average payback percentage to the machines in each casino. The resultant list was widely publicized for marketing purposes (especially by the Palms casino which had the top ranking).\\nOne reason that the slot machine is so profitable to a casino is that the player must play the high house edge and high payout wagers along with the low house edge and low payout wagers. In a more traditional wagering game like craps, the player knows that certain wagers have almost a 50/50 chance of winning or losing, but they only pay a limited multiple of the original bet (usually no higher than three times). Other bets have a higher house edge, but the player is rewarded with a bigger win (up to thirty times in craps). The player can choose what kind of wager he wants to make. A slot machine does not afford such an opportunity. Theoretically, the operator could make these probabilities available, or allow the player to choose which one so that the player is free to make a choice. However, no operator has ever enacted this strategy. Different machines have different maximum payouts, but without knowing the odds of getting the jackpot, there is no rational way to differentiate.\\nIn many markets where central monitoring and control systems are used to link machines for auditing and security purposes, usually in wide area networks of multiple venues and thousands of machines, player return must usually be changed from a central computer rather than at each machine. A range of percentages is set in the game software and selected remotely.\\nIn 2006, the Nevada Gaming Commission began working with Las Vegas casinos on technology that would allow the casino\\'s management to change the game, the odds, and the payouts remotely. The change cannot be done instantaneously, but only after the selected machine has been idle for at least four minutes. After the change is made, the machine must be locked to new players for four minutes and display an on-screen message informing potential players that a change is being made.\\n\\n\\n=== Linked machines ===\\nSome varieties of slot machines can be linked together in a setup sometimes known as a \"community\" game. The most basic form of this setup involves progressive jackpots that are shared between the bank of machines, but may include multiplayer bonuses and other features.\\nIn some cases multiple machines are linked across multiple casinos. In these cases, the machines may be owned by the manufacturer, who is responsible for paying the jackpot. The casinos lease the machines rather than owning them outright. Casinos in New Jersey, Nevada, Louisiana, Arkansas, and South Dakota now offer multi-state progressive jackpots, which now offer bigger jackpot pools.\\n\\n\\n=== Fraud ===\\nMechanical slot machines and their coin acceptors were sometimes susceptible to cheating devices and other scams. One historical example involved spinning a coin with a short length of plastic wire. The weight and size of the coin would be accepted by the machine and credits would be granted. However, the spin created by the plastic wire would cause the coin to exit through the reject chute into the payout tray. This particular scam has become obsolete due to improvements in newer slot machines. Another obsolete method of defeating slot machines was to use a light source to confuse the optical sensor used to count coins during payout.\\nModern slot machines are controlled by EPROM computer chips and, in large casinos, coin acceptors have become obsolete in favor of bill acceptors. These machines and their bill acceptors are designed with advanced anti-cheating and anti-counterfeiting measures and are difficult to defraud. Early computerized slot machines were sometimes defrauded through the use of cheating devices, such as the \"slider\", \"monkey paw\", \"lightwand\" and \"the tongue\". Many of these old cheating devices were made by the late Tommy Glenn Carmichael, a slot machine fraudster who reportedly stole over $5 million. In the modern day, computerized slot machines are fully deterministic and thus outcomes can be sometimes successfully predicted.\\n\\n\\n=== Skill stops ===\\nSkill stop buttons predated the Bally electromechanical slot machines of the 1960s and 1970s. They appeared on mechanical slot machines manufactured by Mills Novelty Co. as early as the mid 1920s. These machines had modified reel-stop arms, which allowed them to be released from the timing bar, earlier than in a normal play, simply by pressing the buttons on the front of the machine, located between each reel.\\n\"Skill stop\" buttons were added to some slot machines by Zacharias Anthony in the early 1970s. These enabled the player to stop each reel, allowing a degree of \"skill\" so as to satisfy the New Jersey gaming laws of the day which required that players were able to control the game in some way. The original conversion was applied to approximately 50 late-model Bally slot machines. Because the typical machine stopped the reels automatically in less than 10 seconds, weights were added to the mechanical timers to prolong the automatic stopping of the reels. By the time the New Jersey Alcoholic Beverages Commission (ABC) had approved the conversion for use in New Jersey arcades, the word was out and every other distributor began adding skill stops. The machines were a huge hit on the Jersey Shore and the remaining unconverted Bally machines were destroyed as they had become instantly obsolete.\\n\\n\\n== Legislation ==\\n\\n\\n=== United States ===\\nIn the United States, the public and private availability of slot machines is highly regulated by state governments. Many states have established gaming control boards to regulate the possession and use of slot machines and other form of gaming.\\nNevada is the only state that has no significant restrictions against slot machines both for public and private use. In New Jersey, slot machines are only allowed in hotel casinos operated in Atlantic City. Several states (Indiana, Louisiana and Missouri) allow slot machines (as well as any casino-style gambling) only on licensed riverboats or permanently anchored barges. Since Hurricane Katrina, Mississippi has removed the requirement that casinos on the Gulf Coast operate on barges and now allows them on land along the shoreline. Delaware allows slot machines at three horse tracks; they are regulated by the state lottery commission. In Wisconsin, bars and taverns are allowed to have up to five machines. These machines usually allow a player to either take a payout, or gamble it on a double-or-nothing \"side game\".\\nThe territory of Puerto Rico places significant restrictions on slot machine ownership, but the law is widely flouted and slot machines are common in bars and coffeeshops.\\nIn regards to tribal casinos located on Native American reservations, slot machines played against the house and operating independently from a centralized computer system are classified as \"Class III\" gaming by the Indian Gaming Regulatory Act (IGRA), and sometimes promoted as \"Vegas-style\" slot machines. In order to offer Class III gaming, tribes must enter into a compact (agreement) with the state that is approved by the Department of the Interior, which may contain restrictions on the types and quantity of such games. As a workaround, some casinos may operate slot machines as \"Class II\" games—a category that includes games where players play exclusively against at least one other opponent and not the house, such as bingo or any related games (such as pull-tabs). In these cases, the reels are an entertainment display with a pre-determined outcome based on a centralized game played against other players. Under the IGRA, Class II games are regulated by individual tribes and the National Indian Gaming Commission, and do not require any additional approval if the state already permits tribal gaming.\\nSome historical race wagering terminals operate in a similar manner, with the machines using slots as an entertainment display for outcomes paid using the parimutuel betting system, based on results of randomly-selected, previously-held horse races (with the player able to view selected details about the race and adjust their picks before playing the credit, or otherwise use an auto-bet system).\\n\\n\\n==== Private ownership ====\\n\\nAlaska, Arizona, Arkansas, Kentucky, Maine, Minnesota, Nevada, Ohio, Rhode Island, Texas, Utah, Virginia, and West Virginia place no restrictions on private ownership of slot machines. Conversely, in Connecticut, Hawaii, Nebraska, South Carolina, and Tennessee, private ownership of any slot machine is completely prohibited. The remaining states allow slot machines of a certain age (typically 25–30 years) or slot machines manufactured before a specific date.\\n\\n\\n=== Canada ===\\nThe Government of Canada has minimal involvement in gambling beyond the Canadian Criminal Code. In essence, the term \"lottery scheme\" used in the code means slot machines, bingo and table games normally associated with a casino. These fall under the jurisdiction of the province or territory without reference to the federal government; in practice, all Canadian provinces operate gaming boards that oversee lotteries, casinos and video lottery terminals under their jurisdiction.\\nOLG piloted a classification system for slot machines at the Grand River Raceway developed by University of Waterloo professor Kevin Harrigan, as part of its PlaySmart initiative for responsible gambling. Inspired by nutrition labels on foods, they displayed metrics such as volatility and frequency of payouts. OLG has also deployed electronic gaming machines with pre-determined outcomes based on a bingo or pull-tab game, initially branded as \"TapTix\", which visually resemble slot machines.\\nIn Ontario, 4 April 2022 saw the re-introduction of the online gambling market. This became possible when the Canadian Criminal Code was amended to allow single-event wagering August 2021. The province is expected to generate about $800 million in gross revenue per year.\\n\\n\\n=== Australia ===\\nIn Australia \"Poker Machines\" or \"pokies\" are officially termed \"gaming machines\". In Australia, gaming machines are a matter for state governments, so laws vary between states. Gaming machines are found in casinos (approximately one in each major city), pubs and clubs in some states (usually sports, social, or RSL clubs). The first Australian state to legalize this style of gambling was New South Wales, when in 1956 they were made legal in all registered clubs in the state. There are suggestions that the proliferation of poker machines has led to increased levels of problem gambling; however, the precise nature of this link is still open to research.\\nIn 1999 the Australian Productivity Commission reported that nearly half Australia\\'s gaming machines were in New South Wales. At the time, 21% of all the gambling machines in the world were operating in Australia and, on a per capita basis, Australia had roughly five times as many gaming machines as the United States. Australia ranks 8th in total number of gaming machines after Japan, U.S.A., Italy, U.K., Spain and Germany. This primarily is because gaming machines have been legal in the state of New South Wales since 1956; over time, the number of machines has grown to 97,103 (at December 2010, including the Australian Capital Territory). By way of comparison, the U.S. State of Nevada, which legalised gaming including slots several decades before N.S.W., had 190,135 slots operating.\\nRevenue from gaming machines in pubs and clubs accounts for more than half of the $4 billion in gambling revenue collected by state governments in fiscal year 2002–03.\\nIn Queensland, gaming machines in pubs and clubs must provide a return rate of 85%, while machines located in casinos must provide a return rate of 90%. Most other states have similar provisions. In Victoria, gaming machines must provide a minimum return rate of at least 85% (including jackpot contribution), are prohibited from accepting bills greater than $50 in denomination, and each wager must be manually initiated by the player (thus prohibiting \"autoplay\" mechanisms). \\nWestern Australia has the most restrictive regulations on electronic gaming machines (EGMs) in general. They may only be operated at the Crown Perth casino resort, which is the only casino in Western Australia, and have a return rate of 90%. Many EGMs operate games that are nearly identical to slot machines, but with modifications to comply with state law: EGMs are prohibited from using spinning reels, and must not use symbols associated with poker machines used elsewhere. Each wager must take at least three seconds to play, and each wager must be initiated by the user.\\nThis policy has an extensive political history, reaffirmed by the 1974 Royal Commission into Gambling:\\n\\nPoker machine playing is a mindless, repetitive and insidious form of gambling which has many undesirable features. It requires no thought, no skill or social contact. The odds are never about winning. Watching people playing the machines over long periods of time, the impressionistic evidence at least is that they are addictive to many people. Historically poker machines have been banned from Western Australia and we consider that, in the public interest, they should stay banned.\\nDespite the state having praised its restrictions for keeping gaming machines from being widely available to the public as in other states, the machines have faced criticism for being almost indistinguishable to a normal slot machine, and thus having the same addictive qualities. In March 2022, a royal commission found Crown Gaming to be unfit to hold a gaming license in WA, citing issues surrounding money laundering, failing to minimise harms from problem gambling, and the regulatory framework of the Gaming and Wagering Commission being considered outdated. To implement the recommendations of the Commission, EGMs were limited to maximum bets of $10 beginning in July 2023, while also requiring the implementation of weekly limits on play and losses, and the implementation of cashless machines requiring pre-loaded player cards to function.\\nNick Xenophon was elected on an independent No Pokies ticket in the South Australian Legislative Council at the 1997 South Australian state election on 2.9 percent, re-elected at the 2006 election on 20.5 percent, and elected to the Australian Senate at the 2007 federal election on 14.8 percent. Independent candidate Andrew Wilkie, an anti-pokies campaigner, was elected to the Australian House of Representatives seat of Denison at the 2010 federal election. Wilkie was one of four crossbenchers who supported the Gillard Labor government following the hung parliament result. Wilkie immediately began forging ties with Xenophon as soon as it was apparent that he was elected. In exchange for Wilkie\\'s support, the Labor government are attempting to implement precommitment technology for high-bet/high-intensity poker machines, against opposition from the Tony Abbott Coalition and Clubs Australia.\\nDuring the COVID-19 pandemic of 2020, every establishment in the country that facilitated poker machines was shut down, in an attempt to curb the spread of the virus, bringing Australia\\'s usage of poker machines effectively to zero.\\n\\n\\n=== Russia ===\\nIn Russia, \"slot clubs\" appeared quite late, only in 1992. Before 1992, slot machines were only in casinos and small shops, but later slot clubs began appearing all over the country. The most popular and numerous were \"Vulcan 777\" and \"Taj Mahal\". Since 2009, when gambling establishments were banned, almost all slot clubs disappeared and are found only in a specially authorized gambling zones.\\n\\n\\n=== United Kingdom ===\\n\\nSlot machines are covered by the Gambling Act 2005, which superseded the Gaming Act 1968.\\nSlot machines in the U.K. are categorised by definitions produced by the Gambling Commission as part of the Gambling Act of 2005.\\n\\nCasinos built under the provisions of the 1968 Act are allowed to house either up to twenty machines of categories B–D or any number of C–D machines. As defined by the 2005 Act, large casinos can have a maximum of one hundred and fifty machines in any combination of categories B–D (subject to a machine-to-table ratio of 5:1); small casinos can have a maximum of eighty machines in any combination of categories B–D (subject to a machine-to-table ratio of 2:1).\\n\\n\\n==== Category A ====\\nCategory A games were defined in preparation for the planned \"Super Casinos\". Despite a lengthy bidding process with Manchester being chosen as the single planned location, the development was cancelled soon after Gordon Brown became Prime Minister of the United Kingdom. As a result, there are no lawful Category A games in the U.K.\\n\\n\\n==== Category B ====\\nCategory B games are divided into subcategories. The differences between B1, B3 and B4 games are mainly the stake and prizes as defined in the above table. Category B2 games – Fixed odds betting terminals (FOBTs) – have quite different stake and prize rules: FOBTs are mainly found in licensed betting shops, or bookmakers, usually in the form of electronic roulette.\\nThe games are based on a random number generator; thus each game\\'s probability of getting the jackpot is independent of any other game: probabilities are all equal. If a pseudorandom number generator is used instead of a truly random one, probabilities are not independent since each number is determined at least in part by the one generated before it.\\n\\n\\n==== Category C ====\\nCategory C games are often referred to as fruit machines, one-armed bandits and AWP (amusement with prize). Fruit machines are commonly found in pubs, clubs, and arcades. Machines commonly have three but can be found with four or five reels, each with 16–24 symbols printed around them. The reels are spun each play, from which the appearance of particular combinations of symbols result in payment of their associated winnings by the machine (or alternatively initiation of a subgame). These games often have many extra features, trails and subgames with opportunities to win money; usually more than can be won from just the payouts on the reel combinations.\\nFruit machines in the U.K. almost universally have the following features, generally selected at random using a pseudorandom number generator:\\n\\nA player (known in the industry as a punter) may be given the opportunity to hold one or more reels before spinning, meaning they will not be spun but instead retain their displayed symbols yet otherwise count normally for that play. This can sometimes increase the chance of winning, especially if two or more reels are held.\\nA player may also be given a number of nudges following a spin (or, in some machines, as a result in a subgame). A nudge is a step rotation of a reel chosen by the player (the machine may not allow all reels to be nudged for a particular play).\\nCheats can also be made available on the internet or through emailed newsletters to subscribers. These cheats give the player the impression of an advantage, whereas in reality the payout percentage remains exactly the same. The most widely used cheat is known as hold after a nudge and increases the chance that the player will win following an unsuccessful nudge. Machines from the early 1990s did not advertise the concept of hold after a nudge when this feature was first introduced, it became so well known amongst players and widespread amongst new machine releases that it is now well-advertised on the machine during play. This is characterized by messages on the display such as DON\\'T HOLD ANY or LET \\'EM SPIN and is a designed feature of the machine, not a cheat at all.  Holding the same pair three times on three consecutive spins also gives a guaranteed win on most machines that offer holds.\\nIt is known for machines to pay out multiple jackpots, one after the other (this is known as a \"repeat\") but each jackpot requires a new game to be played so as not to violate the law about the maximum payout on a single play. Typically this involves the player only pressing the Start button at the \"repeat\" prompt, for which a single credit is taken, regardless of whether this causes the reels to spin or not.  Machines are also known to intentionally set aside money, which is later awarded in a series of wins, known as a \"streak\". The minimum payout percentage is 70%, with pubs often setting the payout at around 78%.\\n\\n\\n=== Japan ===\\n\\nJapanese slot machines, known as pachisuro (パチスロ) or pachislot from the words \"pachinko\" and \"slot machine\", are a descendant of the traditional Japanese pachinko game. Slot machines are a fairly new phenomenon and they can be found mostly in pachinko parlors and the adult sections of amusement arcades, known as game centers.\\n\\n\\n== Jackpot disputes ==\\n\\nElectronic slot machines can malfunction. When the displayed amount is smaller than the one it is supposed to be, the error usually goes unnoticed. When it happens the other way, disputes are likely. Below are some notable arguments caused by the owners of the machines saying that the displayed amounts were far larger than the ones patrons should get.\\n\\n\\n=== United States ===\\nTwo such cases occurred in casinos in Colorado in 2010, where software errors led to indicated jackpots of $11 million and $42 million. Analysis of machine records by the state Gaming Commission revealed faults, with the true jackpot being substantially smaller. State gaming laws did not require a casino to honour payouts in that case.\\n\\n\\n=== Vietnam ===\\nOn October 25, 2009, while a Vietnamese American man, Ly Sam, was playing a slot machine in the Palazzo Club at the Sheraton Saigon Hotel in Ho Chi Minh City, Vietnam, it displayed that he had hit a jackpot of US$55,542,296.73. The casino refused to pay, saying it was a machine error, Ly sued the casino. On January 7, 2013, the District 1 People\\'s Court in Ho Chi Minh City decided that the casino had to pay the amount Ly claimed in full, not trusting the error report from an inspection company hired by the casino. Both sides appealed thereafter, and Ly asked for interest while the casino refused to pay him. In January, 2014, the news reported that the case had been settled out of court, and Ly had received an undisclosed sum.\\n\\n\\n== Problem gambling and slot machines ==\\n\\nNatasha Dow Schüll, associate professor in New York University\\'s Department of Media, Culture and Communication, uses the term \"machine zone\" to describe the state of immersion that users of slot machines experience when gambling, where they lose a sense of time, space, bodily awareness, and monetary value.\\nMike Dixon, PhD, professor of psychology at the University of Waterloo, studies the relationship between slot players and machines. In one of Dixon\\'s studies, players were observed experiencing heightened arousal from the sensory stimulus coming from the machines. They \"sought to show that these \\'losses disguised as wins\\' (LDWs) would be as arousing as wins, and more arousing than regular losses.\"\\nPsychologists Robert Breen and Marc Zimmerman found that players of video slot machines reach a debilitating level of involvement with gambling three times as rapidly as those who play traditional casino games, even if they have engaged in other forms of gambling without problems.\\nEye-tracking research in local bookkeepers\\' offices in the UK suggested that, in slots games, the reels dominated players\\' visual attention, and that problem gamblers looked more frequently at amount-won messages than did those without gambling problems.\\nThe 2011 60 Minutes report \"Slot Machines: The Big Gamble\" focused on the link between slot machines and gambling addiction.\\n\\n\\n== See also ==\\nCasino\\nEuropean Gaming & Amusement Federation\\nList of probability topics\\nMulti-armed bandit\\nPachinko\\nProblem gambling\\nProgressive jackpot\\nQuiz machine\\nUnited States state slot machine ownership regulations\\nVideo bingo\\nVideo lottery terminal (VLT)\\nVideo poker\\n\\n\\n== References ==\\n\\n\\n== Bibliography ==\\nBrisman, Andrew. The American Mensa Guide to Casino Gambling: Winning Ways (Stirling, 1999) ISBN 0-8069-4837-X\\nGrochowski, John. The Slot Machine Answer Book: How They Work, How They\\'ve Changed, and How to Overcome the House Advantage (Bonus Books, 2005) ISBN 1-56625-235-0\\nLegato, Frank. How to Win Millions Playing Slot Machines! ...Or Lose Trying (Bonus Books, 2004) ISBN 1-56625-216-4\\n\\n\\n== External links =='],\n",
              " ['Data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from potentially noisy, structured, or unstructured data. \\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine). Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.\\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\\nA  data scientist is a professional who creates programming code and combines it with statistical knowledge to create insights from data.\\n\\n\\n== Foundations ==\\nData science is an interdisciplinary field focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains. The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business. Statistician Nathan Yau, drawing on Ben Fry, also links data science to human–computer interaction: users should be able to intuitively control and explore data. In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.\\n\\n\\n=== Relationship to statistics ===\\nMany statisticians, including Nate Silver, have argued that data science is not a new field, but rather another name for statistics. Others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data. Vasant Dhar writes that statistics emphasizes quantitative data and description. In contrast, data science deals with quantitative and qualitative data (e.g., from images, text, sensors, transactions, customer information, etc.) and emphasizes prediction and action. Andrew Gelman of Columbia University has described statistics as a non-essential part of data science.\\nStanford professor David Donoho writes that data science is not distinguished from statistics by the size of datasets or use of computing and that many graduate programs misleadingly advertise their analytics and statistics training as the essence of a data-science program. He describes data science as an applied field growing out of traditional statistics.\\n\\n\\n== Etymology ==\\n\\n\\n=== Early usage ===\\nIn 1962, John Tukey described a field he called \"data analysis\", which resembles modern data science. In 1985, in a lecture given to the Chinese Academy of Sciences in Beijing, C. F. Jeff Wu used the term \"data science\" for the first time as an alternative name for statistics. Later, attendees at a 1992 statistics symposium at the University of Montpellier  II acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.\\nThe term \"data science\" has been traced back to 1974, when Peter Naur proposed it as an alternative name to computer science. In 1996, the International Federation of Classification Societies became the first conference to specifically feature data science as a topic. However, the definition was still in flux. After the 1985 lecture at the Chinese Academy of Sciences in Beijing, in 1997 C. F. Jeff Wu again suggested that statistics should be renamed data science. He reasoned that a new name would help statistics shed inaccurate stereotypes, such as being synonymous with accounting or limited to describing data. In 1998, Hayashi Chikio argued for data science as a new, interdisciplinary concept, with three aspects: data design, collection, and analysis.\\nDuring the 1990s, popular terms for the process of finding patterns in datasets (which were increasingly large) included \"knowledge discovery\" and \"data mining\".\\n\\n\\n=== Modern usage ===\\nIn 2012, technologists Thomas H. Davenport and DJ Patil declared \"Data Scientist: The Sexiest Job of the 21st Century\", a catchphrase that was picked up even by major-city newspapers like the New York Times and the Boston Globe. A decade later, they reaffirmed it, stating that \"the job is more in demand than ever with employers\".\\nThe modern conception of data science as an independent discipline is sometimes attributed to William S. Cleveland. In a 2001 paper, he advocated an expansion of statistics beyond theory into technical areas; because this would significantly change the field, it warranted a new name. \"Data science\" became more widely used in the next few years: in 2002, the Committee on Data for Science and Technology launched the Data Science Journal. In 2003, Columbia University launched The Journal of Data Science. In 2014, the American Statistical Association\\'s Section on Statistical Learning and Data Mining changed its name to the Section on Statistical Learning and Data Science, reflecting the ascendant popularity of data science.\\nThe professional title of \"data scientist\" has been attributed to DJ Patil and Jeff Hammerbacher in 2008. Though it was used by the National Science Board in their 2005 report \"Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century\", it referred broadly to any key role in managing a digital data collection.\\nThere is still no consensus on the definition of data science, and it is considered by some to be a buzzword. Big data is a related marketing term. Data scientists are responsible for breaking down big data into usable information and creating software and algorithms that help companies and organizations determine optimal operations.\\n\\n\\n== Data science and data analysis ==\\n\\nData science and data analysis are both important disciplines in the field of data management and analysis, but they differ in several key ways. While both fields involve working with data, data science is more of an interdisciplinary field that involves the application of statistical, computational, and machine learning methods to extract insights from data and make predictions, while data analysis is more focused on the examination and interpretation of data to identify patterns and trends.\\nData analysis typically involves working with smaller, structured datasets to answer specific questions or solve specific problems. This can involve tasks such as data cleaning, data visualization, and exploratory data analysis to gain insights into the data and develop hypotheses about relationships between variables. Data analysts typically use statistical methods to test these hypotheses and draw conclusions from the data. For example, a data analyst might analyze sales data to identify trends in customer behavior and make recommendations for marketing strategies.\\nData science, on the other hand, is a more complex and iterative process that involves working with larger, more complex datasets that often require advanced computational and statistical methods to analyze. Data scientists often work with unstructured data such as text or images and use machine learning algorithms to build predictive models and make data-driven decisions. In addition to statistical analysis, data science often involves tasks such as data preprocessing, feature engineering, and model selection. For instance, a data scientist might develop a recommendation system for an e-commerce platform by analyzing user behavior patterns and using machine learning algorithms to predict user preferences.\\nWhile data analysis focuses on extracting insights from existing data, data science goes beyond that by incorporating the development and implementation of predictive models to make informed decisions. Data scientists are often responsible for collecting and cleaning data, selecting appropriate analytical techniques, and deploying models in real-world scenarios. They work at the intersection of mathematics, computer science, and domain expertise to solve complex problems and uncover hidden patterns in large datasets.\\nDespite these differences, data science and data analysis are closely related fields and often require similar skill sets. Both fields require a solid foundation in statistics, programming, and data visualization, as well as the ability to communicate findings effectively to both technical and non-technical audiences. Both fields benefit from critical thinking and domain knowledge, as understanding the context and nuances of the data is essential for accurate analysis and modeling.\\nIn summary, data analysis and data science are distinct yet interconnected disciplines within the broader field of data management and analysis. Data analysis focuses on extracting insights and drawing conclusions from structured data, while data science involves a more comprehensive approach that combines statistical analysis, computational methods, and machine learning to extract insights, build predictive models, and drive data-driven decision-making. Both fields use data to understand patterns, make informed decisions, and solve complex problems across various domains.\\n\\n\\n== Cloud Computing for Data Science ==\\n\\nCloud computing can offer access to large amounts of computational power and storage. In big data, where volumes of information are continually generated and processed, these platforms can be used to handle complex and resource-intensive analytical tasks.\\nSome distributed computing frameworks are designed to handle big data workloads. These frameworks can enable data scientists to process and analyze large datasets in parallel, which can reducing processing times.\\n\\n\\n== Ethical consideration in Data Science ==\\nData science involve collecting, processing, and analyzing data which often including personal and sensitive information. Ethical concerns include potential privacy violations, bias perpetuation, and negative societal impacts \\nMachine learning models can amplify existing biases present in training data, leading to discriminatory or unfair outcomes.\\n\\n\\n== See also ==\\nOpen Data Science Conference\\nScientific Data\\nWomen in Data\\nPython (programming language)\\nR (programming language)\\nData engineering\\nBig data\\nMachine learning\\n\\n\\n== References =='],\n",
              " ['A recurrent neural network (RNN) is one of the two broad types of artificial neural network, characterized by direction of the flow of information between its layers. In contrast to the uni-directional feedforward neural network, it is a bi-directional artificial neural network, meaning that it allows the output from some nodes to affect subsequent input to the same nodes. Their ability to use internal state (memory) to process arbitrary sequences of inputs makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition. The term \"recurrent neural network\" is used to refer to the class of networks with an infinite impulse response, whereas \"convolutional neural network\" refers to the class of finite impulse response. Both classes of networks exhibit temporal dynamic behavior. A finite impulse recurrent network is a directed acyclic graph that can be unrolled and replaced with a strictly feedforward neural network, while an infinite impulse recurrent network is a directed cyclic graph that can not be unrolled.\\nAdditional stored states and the storage under direct control by the network can be added to both infinite-impulse and finite-impulse networks. Another network or graph can also replace the storage if that incorporates time delays or has feedback loops. Such controlled states are referred to as gated states or gated memory and are part of long short-term memory networks (LSTMs) and gated recurrent units. This is also called Feedback Neural Network (FNN). Recurrent neural networks are theoretically Turing complete and can run arbitrary programs to process arbitrary sequences of inputs.\\n\\n\\n== History ==\\nThe Ising model (1925) by Wilhelm Lenz and Ernst Ising\\nwas the first RNN architecture that did not learn. Shun\\'ichi Amari made it adaptive in 1972. This was also called the Hopfield network (1982). See also David Rumelhart\\'s work in 1986.  In 1993, a neural history compressor system solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time.\\n\\n\\n=== LSTM ===\\nLong short-term memory (LSTM) networks were invented by Hochreiter and Schmidhuber in 1997 and set accuracy records in multiple applications domains.\\nAround 2007, LSTM started to revolutionize speech recognition, outperforming traditional models in certain speech applications. In 2009, a Connectionist Temporal Classification (CTC)-trained LSTM network was the first RNN to win pattern recognition contests when it won several competitions in connected handwriting recognition. In 2014, the Chinese company Baidu used CTC-trained RNNs to break the 2S09 Switchboard Hub5\\'00 speech recognition dataset benchmark without using any traditional speech processing methods.\\nLSTM also improved large-vocabulary speech recognition and text-to-speech synthesis and was used in Google Android. In 2015, Google\\'s speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM.\\nLSTM broke records for improved machine translation, Language Modeling and Multilingual Language Processing. LSTM combined with convolutional neural networks (CNNs) improved automatic image captioning.\\n\\n\\n== Architectures ==\\n\\nRNNs come in many variants.\\n\\n\\n=== Fully recurrent ===\\n\\nFully recurrent neural networks (FRNN) connect the outputs of all neurons to the inputs of all neurons.  This is the most general neural network topology because all other topologies can be represented by setting some connection weights to zero to simulate the lack of connections between those neurons. The illustration to the right may be misleading to many because practical neural network topologies are frequently organized in \"layers\" and the drawing gives that appearance. However, what appears to be layers are, in fact, different steps in time of the same fully recurrent neural network. The left-most item in the illustration shows the recurrent connections as the arc labeled \\'v\\'.  It is \"unfolded\" in time to produce the appearance of layers.\\n\\n\\n=== Elman networks and Jordan networks ===\\n\\nAn Elman network is a three-layer network (arranged horizontally as x, y, and z in the illustration) with the addition of a set of context units (u in the illustration). The middle (hidden) layer is connected to these context units fixed with a weight of one. At each time step, the input is fed forward and a learning rule is applied. The fixed back-connections save a copy of the previous values of the hidden units in the context units (since they propagate over the connections before the learning rule is applied). Thus the network can maintain a sort of state, allowing it to perform such tasks as sequence-prediction that are beyond the power of a standard multilayer perceptron.\\nJordan networks are similar to Elman networks. The context units are fed from the output layer instead of the hidden layer. The context units in a Jordan network are also called the state layer. They have a recurrent connection to themselves.\\nElman and Jordan networks are also known as \"Simple recurrent networks\" (SRN).\\n\\nElman network\\n\\n  \\n    \\n      \\n        \\n          \\n            \\n              \\n                \\n                  h\\n                  \\n                    t\\n                  \\n                \\n              \\n              \\n                \\n                =\\n                \\n                  σ\\n                  \\n                    h\\n                  \\n                \\n                (\\n                \\n                  W\\n                  \\n                    h\\n                  \\n                \\n                \\n                  x\\n                  \\n                    t\\n                  \\n                \\n                +\\n                \\n                  U\\n                  \\n                    h\\n                  \\n                \\n                \\n                  h\\n                  \\n                    t\\n                    −\\n                    1\\n                  \\n                \\n                +\\n                \\n                  b\\n                  \\n                    h\\n                  \\n                \\n                )\\n              \\n            \\n            \\n              \\n                \\n                  y\\n                  \\n                    t\\n                  \\n                \\n              \\n              \\n                \\n                =\\n                \\n                  σ\\n                  \\n                    y\\n                  \\n                \\n                (\\n                \\n                  W\\n                  \\n                    y\\n                  \\n                \\n                \\n                  h\\n                  \\n                    t\\n                  \\n                \\n                +\\n                \\n                  b\\n                  \\n                    y\\n                  \\n                \\n                )\\n              \\n            \\n          \\n        \\n      \\n    \\n    {\\\\displaystyle {\\\\begin{aligned}h_{t}&=\\\\sigma _{h}(W_{h}x_{t}+U_{h}h_{t-1}+b_{h})\\\\\\\\y_{t}&=\\\\sigma _{y}(W_{y}h_{t}+b_{y})\\\\end{aligned}}}\\n  \\n\\nJordan network\\n\\n  \\n    \\n      \\n        \\n          \\n            \\n              \\n                \\n                  h\\n                  \\n                    t\\n                  \\n                \\n              \\n              \\n                \\n                =\\n                \\n                  σ\\n                  \\n                    h\\n                  \\n                \\n                (\\n                \\n                  W\\n                  \\n                    h\\n                  \\n                \\n                \\n                  x\\n                  \\n                    t\\n                  \\n                \\n                +\\n                \\n                  U\\n                  \\n                    h\\n                  \\n                \\n                \\n                  y\\n                  \\n                    t\\n                    −\\n                    1\\n                  \\n                \\n                +\\n                \\n                  b\\n                  \\n                    h\\n                  \\n                \\n                )\\n              \\n            \\n            \\n              \\n                \\n                  y\\n                  \\n                    t\\n                  \\n                \\n              \\n              \\n                \\n                =\\n                \\n                  σ\\n                  \\n                    y\\n                  \\n                \\n                (\\n                \\n                  W\\n                  \\n                    y\\n                  \\n                \\n                \\n                  h\\n                  \\n                    t\\n                  \\n                \\n                +\\n                \\n                  b\\n                  \\n                    y\\n                  \\n                \\n                )\\n              \\n            \\n          \\n        \\n      \\n    \\n    {\\\\displaystyle {\\\\begin{aligned}h_{t}&=\\\\sigma _{h}(W_{h}x_{t}+U_{h}y_{t-1}+b_{h})\\\\\\\\y_{t}&=\\\\sigma _{y}(W_{y}h_{t}+b_{y})\\\\end{aligned}}}\\n  \\n\\nVariables and functions\\n\\n  \\n    \\n      \\n        \\n          x\\n          \\n            t\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle x_{t}}\\n  \\n: input vector\\n\\n  \\n    \\n      \\n        \\n          h\\n          \\n            t\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle h_{t}}\\n  \\n: hidden layer vector\\n\\n  \\n    \\n      \\n        \\n          y\\n          \\n            t\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle y_{t}}\\n  \\n: output vector\\n\\n  \\n    \\n      \\n        W\\n      \\n    \\n    {\\\\displaystyle W}\\n  \\n, \\n  \\n    \\n      \\n        U\\n      \\n    \\n    {\\\\displaystyle U}\\n  \\n and \\n  \\n    \\n      \\n        b\\n      \\n    \\n    {\\\\displaystyle b}\\n  \\n: parameter matrices and vector\\n\\n  \\n    \\n      \\n        \\n          σ\\n          \\n            h\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\sigma _{h}}\\n  \\n and \\n  \\n    \\n      \\n        \\n          σ\\n          \\n            y\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\sigma _{y}}\\n  \\n: Activation functions\\n\\n\\n=== Hopfield ===\\n\\nThe Hopfield network is an RNN in which all connections across layers are equally sized. It requires stationary inputs and is thus not a general RNN, as it does not process sequences of patterns. However, it guarantees that it will converge. If the connections are trained using Hebbian learning, then the Hopfield network can perform as robust content-addressable memory, resistant to connection alteration.\\n\\n\\n==== Bidirectional associative memory ====\\n\\nIntroduced by Bart Kosko, a bidirectional associative memory (BAM) network is a variant of a Hopfield network that stores associative data as a vector. The bi-directionality comes from passing information through a matrix and its transpose. Typically, bipolar encoding is preferred to binary encoding of the associative pairs. Recently, stochastic BAM models using Markov stepping were optimized for increased network stability and relevance to real-world applications.\\nA BAM network has two layers, either of which can be driven as an input to recall an association and produce an output on the other layer.\\n\\n\\n=== Echo state ===\\n\\nEcho state networks (ESN) have a sparsely connected random hidden layer. The weights of output neurons are the only part of the network that can change (be trained). ESNs are good at reproducing certain time series. A variant for spiking neurons is known as a liquid state machine.\\n\\n\\n=== Independently RNN (IndRNN) ===\\nThe independently recurrent neural network (IndRNN) addresses the gradient vanishing and exploding problems in the traditional fully connected RNN. Each neuron in one layer only receives its own past state as context information (instead of full connectivity to all other neurons in this layer) and thus neurons are independent of each other\\'s history. The gradient backpropagation can be regulated to avoid gradient vanishing and exploding in order to keep long or short-term memory. The cross-neuron information is explored in the next layers. IndRNN can be robustly trained with non-saturated nonlinear functions such as ReLU. Deep networks can be trained using skip connections.\\n\\n\\n=== Recursive ===\\n\\nA recursive neural network is created by applying the same set of weights recursively over a differentiable graph-like structure by traversing the structure in topological order. Such networks are typically also trained by the reverse mode of automatic differentiation. They can process distributed representations of structure, such as logical terms. A special case of recursive neural networks is the RNN whose structure corresponds to a linear chain. Recursive neural networks have been applied to natural language processing. The Recursive Neural Tensor Network uses a tensor-based composition function for all nodes in the tree.\\n\\n\\n=== Neural history compressor ===\\nThe neural history compressor is an unsupervised stack of RNNs. At the input level, it learns to predict its next input from the previous inputs. Only unpredictable inputs of some RNN in the hierarchy become inputs to the next higher level RNN, which therefore recomputes its internal state only rarely. Each higher level RNN thus studies a compressed representation of the information in the RNN below. This is done such that the input sequence can be precisely reconstructed from the representation at the highest level.\\nThe system effectively minimizes the description length or the negative logarithm of the probability of the data. Given a lot of learnable predictability in the incoming data sequence, the highest level RNN can use supervised learning to easily classify even deep sequences with long intervals between important events.\\nIt is possible to distill the RNN hierarchy into two RNNs: the \"conscious\" chunker (higher level) and the \"subconscious\" automatizer (lower level). Once the chunker has learned to predict and compress inputs that are unpredictable by the automatizer, then the automatizer can be forced in the next learning phase to predict or imitate through additional units the hidden units of the more slowly changing chunker. This makes it easy for the automatizer to learn appropriate, rarely changing memories across long intervals. In turn, this helps the automatizer to make many of its once unpredictable inputs predictable, such that the chunker can focus on the remaining unpredictable events.\\nA generative model partially overcame the vanishing gradient problem of automatic differentiation or backpropagation in neural networks in 1992. In 1993, such a system solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time.\\n\\n\\n=== Second order RNNs ===\\nSecond-order RNNs use higher order weights \\n  \\n    \\n      \\n        w\\n        \\n          \\n\\n          \\n          \\n            i\\n            j\\n            k\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle w{}_{ijk}}\\n  \\n instead of the standard \\n  \\n    \\n      \\n        w\\n        \\n          \\n\\n          \\n          \\n            i\\n            j\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle w{}_{ij}}\\n  \\n weights, and states can be a product. This allows a direct mapping to a finite-state machine both in training, stability, and representation. Long short-term memory is an example of this but has no such formal mappings or proof of stability.\\n\\n\\n=== Long short-term memory ===\\n\\nLong short-term memory (LSTM) is a deep learning system that avoids the vanishing gradient problem. LSTM is normally augmented by recurrent gates called \"forget gates\". LSTM prevents backpropagated errors from vanishing or exploding. Instead, errors can flow backward through unlimited numbers of virtual layers unfolded in space. That is, LSTM can learn tasks that require memories of events that happened thousands or even millions of discrete time steps earlier. Problem-specific LSTM-like topologies can be evolved. LSTM works even given long delays between significant events and can handle signals that mix low and high-frequency components.\\nMany applications use stacks of LSTM RNNs and train them by connectionist temporal classification (CTC) to find an RNN weight matrix that maximizes the probability of the label sequences in a training set, given the corresponding input sequences. CTC achieves both alignment and recognition.\\nLSTM can learn to recognize context-sensitive languages unlike previous models based on hidden Markov models (HMM) and similar concepts.\\n\\n\\n=== Gated recurrent unit ===\\n\\nGated recurrent units (GRUs) are a gating mechanism in recurrent neural networks introduced in 2014. They are used in the full form and several simplified variants. Their performance on polyphonic music modeling and speech signal modeling was found to be similar to that of long short-term memory. They have fewer parameters than LSTM, as they lack an output gate.\\n\\n\\n=== Bi-directional ===\\n\\nBi-directional RNNs use a finite sequence to predict or label each element of the sequence based on the element\\'s past and future contexts. This is done by concatenating the outputs of two RNNs, one processing the sequence from left to right, and the other one from right to left. The combined outputs are the predictions of the teacher-given target signals. This technique has been proven to be especially useful when combined with LSTM RNNs.\\n\\n\\n=== Continuous-time ===\\nA continuous-time recurrent neural network (CTRNN) uses a system of ordinary differential equations to model the effects on a neuron of the incoming inputs.\\nFor a neuron \\n  \\n    \\n      \\n        i\\n      \\n    \\n    {\\\\displaystyle i}\\n  \\n in the network with activation \\n  \\n    \\n      \\n        \\n          y\\n          \\n            i\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle y_{i}}\\n  \\n, the rate of change of activation is given by:\\n\\n  \\n    \\n      \\n        \\n          τ\\n          \\n            i\\n          \\n        \\n        \\n          \\n            \\n              \\n                y\\n                ˙\\n              \\n            \\n          \\n          \\n            i\\n          \\n        \\n        =\\n        −\\n        \\n          y\\n          \\n            i\\n          \\n        \\n        +\\n        \\n          ∑\\n          \\n            j\\n            =\\n            1\\n          \\n          \\n            n\\n          \\n        \\n        \\n          w\\n          \\n            j\\n            i\\n          \\n        \\n        σ\\n        (\\n        \\n          y\\n          \\n            j\\n          \\n        \\n        −\\n        \\n          Θ\\n          \\n            j\\n          \\n        \\n        )\\n        +\\n        \\n          I\\n          \\n            i\\n          \\n        \\n        (\\n        t\\n        )\\n      \\n    \\n    {\\\\displaystyle \\\\tau _{i}{\\\\dot {y}}_{i}=-y_{i}+\\\\sum _{j=1}^{n}w_{ji}\\\\sigma (y_{j}-\\\\Theta _{j})+I_{i}(t)}\\n  \\n\\nWhere:\\n\\n  \\n    \\n      \\n        \\n          τ\\n          \\n            i\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\tau _{i}}\\n  \\n : Time constant of postsynaptic node\\n\\n  \\n    \\n      \\n        \\n          y\\n          \\n            i\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle y_{i}}\\n  \\n : Activation of postsynaptic node\\n\\n  \\n    \\n      \\n        \\n          \\n            \\n              \\n                y\\n                ˙\\n              \\n            \\n          \\n          \\n            i\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle {\\\\dot {y}}_{i}}\\n  \\n : Rate of change of activation of postsynaptic node\\n\\n  \\n    \\n      \\n        w\\n        \\n          \\n\\n          \\n          \\n            j\\n            i\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle w{}_{ji}}\\n  \\n : Weight of connection from pre to postsynaptic node\\n\\n  \\n    \\n      \\n        σ\\n        (\\n        x\\n        )\\n      \\n    \\n    {\\\\displaystyle \\\\sigma (x)}\\n  \\n : Sigmoid of x e.g. \\n  \\n    \\n      \\n        σ\\n        (\\n        x\\n        )\\n        =\\n        1\\n        \\n          /\\n        \\n        (\\n        1\\n        +\\n        \\n          e\\n          \\n            −\\n            x\\n          \\n        \\n        )\\n      \\n    \\n    {\\\\displaystyle \\\\sigma (x)=1/(1+e^{-x})}\\n  \\n.\\n\\n  \\n    \\n      \\n        \\n          y\\n          \\n            j\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle y_{j}}\\n  \\n : Activation of presynaptic node\\n\\n  \\n    \\n      \\n        \\n          Θ\\n          \\n            j\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\Theta _{j}}\\n  \\n : Bias of presynaptic node\\n\\n  \\n    \\n      \\n        \\n          I\\n          \\n            i\\n          \\n        \\n        (\\n        t\\n        )\\n      \\n    \\n    {\\\\displaystyle I_{i}(t)}\\n  \\n : Input (if any) to node\\nCTRNNs have been applied to evolutionary robotics where they have been used to address vision, co-operation, and minimal cognitive behaviour.\\nNote that, by the Shannon sampling theorem, discrete-time recurrent neural networks can be viewed as continuous-time recurrent neural networks where the differential equations have transformed into equivalent difference equations. This transformation can be thought of as occurring after the post-synaptic node activation functions \\n  \\n    \\n      \\n        \\n          y\\n          \\n            i\\n          \\n        \\n        (\\n        t\\n        )\\n      \\n    \\n    {\\\\displaystyle y_{i}(t)}\\n  \\n have been low-pass filtered but prior to sampling.\\n\\n\\n=== Hierarchical recurrent neural network ===\\nHierarchical recurrent neural networks (HRNN) connect their neurons in various ways to decompose hierarchical behavior into useful subprograms. Such hierarchical structures of cognition are present in theories of memory presented by philosopher Henri Bergson, whose philosophical views have inspired hierarchical models.\\nHierarchical recurrent neural networks are useful in forecasting, helping to predict disaggregated inflation components of the consumer price index (CPI). The HRNN model leverages information from higher levels in the CPI hierarchy to enhance lower-level predictions. Evaluation of a substantial dataset from the US CPI-U index demonstrates the superior performance of the HRNN model compared to various established inflation prediction methods.\\n\\n\\n=== Recurrent multilayer perceptron network ===\\nGenerally, a recurrent multilayer perceptron network (RMLP network) consists of cascaded subnetworks, each containing multiple layers of nodes. Each subnetwork is feed-forward except for the last layer, which can have feedback connections. Each of these subnets is connected only by feed-forward connections.\\n\\n\\n=== Multiple timescales model ===\\nA multiple timescales recurrent neural network (MTRNN) is a neural-based computational model that can simulate the functional hierarchy of the brain through self-organization depending on the spatial connection between neurons and on distinct types of neuron activities, each with distinct time properties. With such varied neuronal activities, continuous sequences of any set of behaviors are segmented into reusable primitives, which in turn are flexibly integrated into diverse sequential behaviors. The biological approval of such a type of hierarchy was discussed in the memory-prediction theory of brain function by Hawkins in his book On Intelligence. Such a hierarchy also agrees with theories of memory posited by philosopher Henri Bergson, which have been incorporated into an MTRNN model.\\n\\n\\n=== Neural Turing machines ===\\n\\nNeural Turing machines (NTMs) are a method of extending recurrent neural networks by coupling them to external memory resources which they can interact with by attentional processes. The combined system is analogous to a Turing machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent.\\n\\n\\n=== Differentiable neural computer ===\\n\\nDifferentiable neural computers (DNCs) are an extension of Neural Turing machines, allowing for the usage of fuzzy amounts of each memory address and a record of chronology.\\n\\n\\n=== Neural network pushdown automata ===\\nNeural network pushdown automata (NNPDA) are similar to NTMs, but tapes are replaced by analog stacks that are differentiable and trained. In this way, they are similar in complexity to recognizers of context free grammars (CFGs).\\n\\n\\n=== Memristive networks ===\\nGreg Snider of HP Labs describes a system of cortical computing with memristive nanodevices. The memristors (memory resistors) are implemented by thin film materials in which the resistance is electrically tuned via the transport of ions or oxygen vacancies within the film. DARPA\\'s SyNAPSE project has funded IBM Research and HP Labs, in collaboration with the Boston University Department of Cognitive and Neural Systems (CNS), to develop neuromorphic architectures that may be based on memristive systems.\\nMemristive networks are a particular type of physical neural network that have very similar properties to (Little-)Hopfield networks, as they have continuous dynamics, a limited memory capacity and natural relaxation via the minimization of a function which is asymptotic to the Ising model. In this sense, the dynamics of a memristive circuit have the advantage compared to a Resistor-Capacitor network to have a more interesting non-linear behavior. From this point of view, engineering analog memristive networks account for a peculiar type of neuromorphic engineering in which the device behavior depends on the circuit wiring or topology.\\nThe evolution of these networks can be studied analytically using variations of the Caravelli–Traversa–Di Ventra equation.\\n\\n\\n== Pseudocode ==\\nGiven a time series x of length sequence_length.\\nIn the recurrent neural network, there is a loop that processes all entries of the time series x through the layers neural_network one after another. These have as return value in each time step i both the prediction y_pred[i] and an updated hidden state hidden, which has the length hidden_size. As a result, after the loop, the collection of all predictions y_pred is returned.\\nThe following pseudocode (based on the programming language Python) illustrates the functionality of a recurrent neural network.\\n\\nModern libraries provide runtime-optimized implementations of the above functionality or allow to speed up the slow loop by just-in-time compilation.\\n\\n\\n== Training ==\\n\\n\\n=== Gradient descent ===\\n\\nGradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. In neural networks, it can be used to minimize the error term by changing each weight in proportion to the derivative of the error with respect to that weight, provided the non-linear activation functions are differentiable. Various methods for doing so were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, Schmidhuber, Hochreiter, Pearlmutter and others.\\nThe standard method is called \"backpropagation through time\" or BPTT, and is a generalization of back-propagation for feed-forward networks. Like that method, it is an instance of automatic differentiation in the reverse accumulation mode of Pontryagin\\'s minimum principle. A more computationally expensive online variant is called \"Real-Time Recurrent Learning\" or RTRL, which is an instance of automatic differentiation in the forward accumulation mode with stacked tangent vectors. Unlike BPTT, this algorithm is local in time but not local in space.\\nIn this context, local in space means that a unit\\'s weight vector can be updated using only information stored in the connected units and the unit itself such that update complexity of a single unit is linear in the dimensionality of the weight vector. Local in time means that the updates take place continually (on-line) and depend only on the most recent time step rather than on multiple time steps within a given time horizon as in BPTT. Biological neural networks appear to be local with respect to both time and space.\\nFor recursively computing the partial derivatives, RTRL has a time-complexity of O(number of hidden x number of weights) per time step for computing the Jacobian matrices, while BPTT only takes O(number of weights) per time step, at the cost of storing all forward activations within the given time horizon. An online hybrid between BPTT and RTRL with intermediate complexity exists, along with variants for continuous time.\\nA major problem with gradient descent for standard RNN architectures is that error gradients vanish exponentially quickly with the size of the time lag between important events. LSTM combined with a BPTT/RTRL hybrid learning method attempts to overcome these problems. This problem is also solved in the independently recurrent neural network (IndRNN) by reducing the context of a neuron to its own past state and the cross-neuron information can then be explored in the following layers. Memories of different ranges including long-term memory can be learned without the gradient vanishing and exploding problem.\\nThe on-line algorithm called causal recursive backpropagation (CRBP), implements and combines BPTT and RTRL paradigms for locally recurrent networks. It works with the most general locally recurrent networks. The CRBP algorithm can minimize the global error term. This fact improves the stability of the algorithm, providing a unifying view of gradient calculation techniques for recurrent networks with local feedback.\\nOne approach to gradient information computation in RNNs with arbitrary architectures is based on signal-flow graphs diagrammatic derivation. It uses the BPTT batch algorithm, based on Lee\\'s theorem for network sensitivity calculations. It was proposed by Wan and Beaufays, while its fast online version was proposed by Campolucci, Uncini and Piazza.\\n\\n\\n=== Global optimization methods ===\\nTraining the weights in a neural network can be modeled as a non-linear global optimization problem. A target function can be formed to evaluate the fitness or error of a particular weight vector as follows: First, the weights in the network are set according to the weight vector. Next, the network is evaluated against the training sequence. Typically, the sum-squared difference between the predictions and the target values specified in the training sequence is used to represent the error of the current weight vector. Arbitrary global optimization techniques may then be used to minimize this target function.\\nThe most common global optimization method for training RNNs is genetic algorithms, especially in unstructured networks.\\nInitially, the genetic algorithm is encoded with the neural network weights in a predefined manner where one gene in the chromosome represents one weight link. The whole network is represented as a single chromosome. The fitness function is evaluated as follows:\\n\\nEach weight encoded in the chromosome is assigned to the respective weight link of the network.\\nThe training set is presented to the network which propagates the input signals forward.\\nThe mean-squared error is returned to the fitness function.\\nThis function drives the genetic selection process.\\nMany chromosomes make up the population; therefore, many different neural networks are evolved until a stopping criterion is satisfied. A common stopping scheme is: \\n\\nWhen the neural network has learned a certain percentage of the training data or\\nWhen the minimum value of the mean-squared-error is satisfied or\\nWhen the maximum number of training generations has been reached.\\nThe fitness function evaluates the stopping criterion as it receives the mean-squared error reciprocal from each network during training. Therefore, the goal of the genetic algorithm is to maximize the fitness function, reducing the mean-squared error.\\nOther global (and/or evolutionary) optimization techniques may be used to seek a good set of weights, such as simulated annealing or particle swarm optimization.\\n\\n\\n== Related fields and models ==\\nRNNs may behave chaotically. In such cases, dynamical systems theory may be used for analysis.\\nThey are in fact recursive neural networks with a particular structure: that of a linear chain. Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step.\\nIn particular, RNNs can appear as nonlinear versions of finite impulse response and infinite impulse response filters and also as a nonlinear autoregressive exogenous model (NARX).\\nThe effect of memory-based learning for the recognition of sequences can also be implemented by a more biological-based model which uses the silencing mechanism exhibited in neurons with a relatively high frequency spiking activity.\\n\\n\\n== Libraries ==\\nApache Singa\\nCaffe: Created by the Berkeley Vision and Learning Center (BVLC). It supports both CPU and GPU. Developed in C++, and has Python and MATLAB wrappers.\\nChainer: Fully in Python, production support for CPU, GPU, distributed training.\\nDeeplearning4j: Deep learning in Java and Scala on multi-GPU-enabled Spark.\\nFlux: includes interfaces for RNNs, including GRUs and LSTMs, written in Julia.\\nKeras: High-level API, providing a wrapper to many other deep learning libraries.\\nMicrosoft Cognitive Toolkit\\nMXNet: an open-source deep learning framework used to train and deploy deep neural networks.\\nPyTorch: Tensors and Dynamic neural networks in Python with GPU acceleration.\\nTensorFlow: Apache 2.0-licensed Theano-like library with support for CPU, GPU and Google\\'s proprietary TPU, mobile\\nTheano: A deep-learning library for Python with an API largely compatible with the NumPy library.\\nTorch: A scientific computing framework with support for machine learning algorithms, written in C and Lua.\\n\\n\\n== Applications ==\\nApplications of recurrent neural networks include:\\n\\nMachine translation\\nRobot control\\nTime series prediction\\nSpeech recognition\\nSpeech synthesis\\nBrain–computer interfaces\\nTime series anomaly detection\\nText-to-Video model\\nRhythm learning\\nMusic composition\\nGrammar learning\\nHandwriting recognition\\nHuman action recognition\\nProtein homology detection\\nPredicting subcellular localization of proteins\\nSeveral prediction tasks in the area of business process management\\nPrediction in medical care pathways\\nPredictions of fusion plasma disruptions in reactors (Fusion Recurrent Neural Network (FRNN) code) \\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nMandic, Danilo P.; Chambers, Jonathon A. (2001). Recurrent Neural Networks for Prediction: Learning Algorithms, Architectures and Stability. Wiley. ISBN 978-0-471-49517-8.\\n\\n\\n== External links ==\\nRecurrent Neural Networks with over 60 RNN papers by Jürgen Schmidhuber\\'s group at Dalle Molle Institute for Artificial Intelligence Research\\nElman Neural Network implementation for WEKA'],\n",
              " ['Convolutional neural network (CNN) is a regularized type of feed-forward neural network that learns feature engineering by itself via filters (or kernel) optimization. Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by using regularized weights over fewer connections. For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 × 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels,  only 25 neurons are required to process 5x5-sized tiles. Higher-layer features are extracted  from wider context windows, compared to lower-layer features.\\nThey have applications in: \\n\\nimage and video recognition,\\nrecommender systems,\\n\\nimage classification,\\n\\nimage segmentation,\\n\\nmedical image analysis,\\n\\nnatural language processing,\\n\\nbrain–computer interfaces, and\\n\\nfinancial time series.\\nCNNs are also known as Shift Invariant or Space Invariant Artificial Neural Networks (SIANN), based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are not invariant to translation, due to the downsampling operation they apply to the input.\\nFeed-forward neural networks are usually fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"full connectivity\" of these networks makes them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly-populated set.\\nConvolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\\nCNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms these filters are hand-engineered. This independence from prior knowledge and human intervention in feature extraction is a major advantage.\\n\\n\\n== Architecture ==\\n\\nA convolutional neural network consists of an input layer, hidden layers and an output layer. In a convolutional neural network, the hidden layers include one or more layers that perform convolutions. Typically this includes a layer that performs a dot product of the convolution kernel with the layer\\'s input matrix. This product is usually the Frobenius inner product, and its activation function is commonly ReLU. As the convolution kernel slides along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This is followed by other layers such as pooling layers, fully connected layers, and normalization layers.\\nHere it should be noted how close a convolutional neural network is to a matched filter.\\n\\n\\n=== Convolutional layers ===\\nIn a CNN, the input is a tensor with shape:\\n(number of inputs) × (input height) × (input width) × (input channels)\\nAfter passing through a convolutional layer, the image becomes abstracted to a feature map, also called an activation map, with shape:\\n(number of inputs) × (feature map height) × (feature map width) × (feature map channels).\\nConvolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus. Each convolutional neuron processes data only for its receptive field. \\n\\nAlthough fully connected feedforward neural networks can be used to learn features and classify data, this architecture is generally impractical for larger inputs (e.g., high-resolution images), which would require massive numbers of neurons because each pixel is a relevant input feature. A fully connected layer for an image of size 100 × 100 has 10,000 weights for each neuron in the second layer. Convolution reduces the number of free parameters, allowing the network to be deeper. For example, using a 5 × 5 tiling region, each with the same shared weights, requires only 25 neurons. Using regularized weights over fewer parameters avoids the vanishing gradients and exploding gradients problems seen during backpropagation in earlier neural networks.\\nTo speed processing, standard convolutional layers can be replaced by depthwise separable convolutional layers, which are based on a depthwise convolution followed by a pointwise convolution. The depthwise convolution is a spatial convolution applied independently over each channel of the input tensor, while the pointwise convolution is a standard convolution restricted to the use of \\n  \\n    \\n      \\n        1\\n        ×\\n        1\\n      \\n    \\n    {\\\\displaystyle 1\\\\times 1}\\n  \\n  kernels.\\n\\n\\n=== Pooling layers ===\\nConvolutional networks may include local and/or global pooling layers along with traditional convolutional layers. Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, tiling sizes such as 2 × 2 are commonly used. Global pooling acts on all the neurons of the feature map. There are two common types of pooling in popular use: max and average. Max pooling uses the maximum value of each local cluster of neurons in the feature map, while average pooling takes the average value.\\n\\n\\n=== Fully connected layers ===\\nFully connected layers connect every neuron in one layer to every neuron in another layer. It is the same as a traditional multilayer perceptron neural network (MLP). The flattened matrix goes through a fully connected layer to classify the images.\\n\\n\\n=== Receptive field ===\\nIn neural networks, each neuron receives input from some number of locations in the previous layer. In a convolutional layer, each neuron receives input from only a restricted area of the previous layer called the neuron\\'s receptive field. Typically the area is a square (e.g. 5 by 5 neurons). Whereas, in a fully connected layer, the receptive field is the entire previous layer. Thus, in each convolutional layer, each neuron takes input from a larger area in the input than previous layers. This is due to applying the convolution over and over, which takes the value of a pixel into account, as well as its surrounding pixels. When using dilated layers, the number of pixels in the receptive field remains constant, but the field is more sparsely populated as its dimensions grow when combining the effect of several layers.\\nTo manipulate the receptive field size as desired, there are some alternatives to the standard convolutional layer. For example, atrous or dilated convolution expands the receptive field size without increasing the number of parameters by interleaving visible and blind regions. Moreover, a single dilated convolutional layer can comprise filters with multiple dilation ratios, thus having a variable receptive field size.\\n\\n\\n=== Weights ===\\nEach neuron in a neural network computes an output value by applying a specific function to the input values received from the receptive field in the previous layer. The function that is applied to the input values is determined by a vector of weights and a bias (typically real numbers). Learning consists of iteratively adjusting these biases and weights.\\nThe vectors of weights and biases are called filters and represent particular features of the input (e.g., a particular shape). A distinguishing feature of CNNs is that many neurons can share the same filter. This reduces the memory footprint because a single bias and a single vector of weights are used across all receptive fields that share that filter, as opposed to each receptive field having its own bias and vector weighting.\\n\\n\\n== History ==\\nCNN are often compared to the way the brain achieves vision processing in living organisms.\\n\\n\\n=== Receptive fields in the visual cortex ===\\nWork by Hubel and Wiesel in the 1950s and 1960s showed that cat visual cortices contain neurons that individually respond to small regions of the visual field. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field. Neighboring cells have similar and overlapping receptive fields. Receptive field size and location varies systematically across the cortex to form a complete map of visual space. The cortex in each hemisphere represents the contralateral visual field.\\nTheir 1968 paper identified two basic visual cell types in the brain:\\n\\nsimple cells, whose output is maximized by straight edges having particular orientations within their receptive field\\ncomplex cells, which have larger receptive fields, whose output is insensitive to the exact position of the edges in the field.\\nHubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks.\\n\\n\\n=== Neocognitron, origin of the CNN architecture ===\\nThe \"neocognitron\" was introduced by Kunihiko Fukushima in 1980.\\nIt was inspired by the above-mentioned work of Hubel and Wiesel. The neocognitron introduced the two basic types of layers in CNNs:\\n\\nA convolutional layer which contains units whose receptive fields cover a patch of the previous layer. The weight vector (the set of adaptive parameters) of such a unit is often called a filter. Units can share filters.\\nDownsampling layers which contain units whose receptive fields cover patches of previous convolutional layers. Such a unit typically computes the average of the activations of the units in its patch. This downsampling helps to correctly classify objects in visual scenes even when the objects are shifted.\\nIn 1969, Kunihiko Fukushima also introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for CNNs and  deep neural networks in general.\\nIn a variant of the neocognitron called the cresceptron, instead of using Fukushima\\'s spatial averaging, J. Weng et al. in 1993 introduced a method called max-pooling where a downsampling unit computes the maximum of the activations of the units in its patch. Max-pooling is often used in modern CNNs.\\nSeveral supervised and unsupervised learning algorithms have been proposed over the decades to train the weights of a neocognitron. Today, however, the CNN architecture is usually trained through backpropagation.\\nThe neocognitron is the first CNN which requires units located at multiple network positions to have shared weights.\\nConvolutional neural networks were presented at the Neural Information Processing Workshop in 1987, automatically analyzing time-varying signals by replacing learned multiplication with convolution in time, and demonstrated for speech recognition.\\n\\n\\n=== Time delay neural networks ===\\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel et al. for phoneme recognition and was one of the first convolutional networks, as it achieved shift-invariance. A TDNN is a 1-D convolutional neural net where the convolution is performed along the time axis of the data. It is the first CNN utilizing weight sharing in combination with a training by gradient descent, using backpropagation. Thus, while also using a pyramidal structure as in the neocognitron, it performed a global optimization of the weights instead of a local one.\\nTDNNs are convolutional networks that share weights along the temporal dimension. They allow speech signals to be processed time-invariantly. In 1990 Hampshire and Waibel introduced a variant that performs a two-dimensional convolution. Since these TDNNs operated on spectrograms, the resulting phoneme recognition system was invariant to both time and frequency shifts. This inspired translation invariance in image processing with CNNs. The tiling of neuron outputs can cover timed stages.\\nTDNNs now  achieve the best performance in far-distance speech recognition.\\n\\n\\n==== Max pooling ====\\nIn 1990 Yamaguchi et al. introduced the concept of max pooling, a fixed filtering operation that calculates and propagates the maximum value of a given region. They did so by combining TDNNs with max pooling to realize a speaker-independent isolated word recognition system. In their system they used several TDNNs per word, one for each syllable. The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.\\n\\n\\n=== Image recognition with CNNs trained by gradient descent ===\\nDenker et al. (1989) designed a 2-D CNN system to recognize hand-written ZIP Code numbers. However, the lack of an efficient training method to determine the kernel coefficients of the involved convolutions meant that all the coefficients had to be laboriously hand-designed.\\nFollowing the advances in the training of 1-D CNNs by Waibel et al. (1987), Yann LeCun et al. (1989) used back-propagation to learn the convolution kernel coefficients directly from images of hand-written numbers. Learning was thus fully automatic, performed better than manual coefficient design, and was suited to a broader range of image recognition problems and image types. \\nWei Zhang et al. (1988) used back-propagation to train the convolution kernels of a CNN for alphabets recognition. The model was called Shift-Invariant Artificial Neural Network (SIANN) before the name CNN was coined later in the early 1990s. Wei Zhang et al. also applied the same CNN without the last fully connected layer for medical image object segmentation (1991) and breast cancer detection in mammograms (1994).\\nThis approach became a foundation of modern computer vision.\\n\\n\\n==== LeNet-5 ====\\n\\nLeNet-5, a pioneering 7-level convolutional network by LeCun et al. in 1995, that classifies digits, was applied by several banks to recognize hand-written numbers on checks (British English: cheques) digitized in 32x32 pixel images. The ability to process higher-resolution images requires larger and more layers of convolutional neural networks, so this technique is constrained by the availability of computing resources.\\n\\n\\n=== Shift-invariant neural network ===\\nA shift-invariant neural network was proposed by Wei Zhang et al. for image character recognition in 1988. It is a modified Neocognitron by keeping only the convolutional interconnections between the image feature layers and the last fully connected layer.  The model was trained with back-propagation. The training algorithm was further improved in 1991 to improve its generalization ability. The model architecture was modified by removing the last fully connected layer and applied for medical image segmentation (1991) and automatic detection of breast cancer in mammograms (1994).\\nA different convolution-based design was proposed in 1988 for application to decomposition of one-dimensional electromyography convolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.\\n\\n\\n=== Neural abstraction pyramid ===\\n\\nThe feed-forward architecture of convolutional neural networks was extended in the neural abstraction pyramid by lateral and feedback connections. The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities. In contrast to previous models, image-like outputs at the highest resolution were generated, e.g., for semantic segmentation, image reconstruction, and object localization tasks.\\n\\n\\n=== GPU implementations ===\\nAlthough CNNs were invented in the 1980s, their breakthrough in the 2000s required fast implementations on graphics processing units (GPUs).\\nIn 2004, it was shown by K. S. Oh and K. Jung that standard neural networks can be greatly accelerated on GPUs. Their implementation was 20 times faster than an equivalent implementation on CPU. In 2005, another paper also emphasised the value of GPGPU for machine learning.\\nThe first GPU-implementation of a CNN was described in 2006 by K. Chellapilla et al. Their implementation was 4 times faster than an equivalent implementation on CPU. Subsequent work also used GPUs, initially for other types of neural networks (different from CNNs), especially unsupervised neural networks.\\nIn 2010, Dan Ciresan et al. at IDSIA showed that even deep standard neural networks with many layers can be quickly trained on GPU by supervised learning through the old method known as backpropagation. Their network outperformed previous machine learning methods on the MNIST handwritten digits benchmark. In 2011, they extended this GPU approach to CNNs, achieving an acceleration factor of 60, with impressive results. In 2011, they used such CNNs on GPU to win an image recognition contest where they achieved superhuman performance for the first time. Between May 15, 2011, and September 30, 2012, their CNNs won no less than four image competitions. In 2012, they also significantly improved on the best performance in the literature for multiple image databases, including the MNIST database, the NORB database, the HWDB1.0 dataset (Chinese characters) and the CIFAR10 dataset (dataset of 60000 32x32 labeled RGB images).\\nSubsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012. A very deep CNN with over 100 layers by Microsoft won the ImageNet 2015 contest.\\n\\n\\n=== Intel Xeon Phi implementations ===\\nCompared to the training of CNNs using GPUs, not much attention was given to the Intel Xeon Phi coprocessor.\\nA notable development is a parallelization method for training convolutional neural networks on the Intel Xeon Phi, named Controlled Hogwild with Arbitrary Order of Synchronization (CHAOS).\\nCHAOS exploits both the thread- and SIMD-level parallelism that is available on the Intel Xeon Phi.\\n\\n\\n== Distinguishing features ==\\nIn the past, traditional multilayer perceptron (MLP) models were used for image recognition. However, the full connectivity between nodes caused the curse of dimensionality, and was computationally intractable with higher-resolution images. A 1000×1000-pixel image with RGB color channels has 3 million weights per fully-connected neuron, which is too high to feasibly process efficiently at scale.\\n\\nFor example, in CIFAR-10, images are only of size 32×32×3 (32 wide, 32 high, 3 color channels), so a single fully connected neuron in the first hidden layer of a regular neural network would have 32*32*3 = 3,072 weights. A 200×200 image, however, would lead to neurons that have 200*200*3 = 120,000 weights.\\nAlso, such network architecture does not take into account the spatial structure of data, treating input pixels which are far apart in the same way as pixels that are close together. This ignores locality of reference in data with a grid-topology (such as images), both computationally and semantically. Thus, full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by spatially local input patterns.\\nConvolutional neural networks are variants of multilayer perceptrons, designed to emulate the behavior of a visual cortex. These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images. As opposed to MLPs, CNNs have the following distinguishing features:\\n\\n3D volumes of neurons. The layers of a CNN have neurons arranged in 3 dimensions: width, height and depth. Where each neuron inside a convolutional layer is connected to only a small region of the layer before it, called a receptive field. Distinct types of layers, both locally and completely connected, are stacked to form a CNN architecture.\\nLocal connectivity: following the concept of receptive fields, CNNs exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers. The architecture thus ensures that the learned \"filters\" produce the strongest response to a spatially local input pattern. Stacking many such layers leads to nonlinear filters that become increasingly global (i.e. responsive to a larger region of pixel space) so that the network first creates representations of small parts of the input, then from them assembles representations of larger areas.\\nShared weights: In CNNs, each filter is replicated across the entire visual field. These replicated units share the same parameterization (weight vector and bias) and form a feature map. This means that all the neurons in a given convolutional layer respond to the same feature within their specific response field. Replicating units in this way allows for the resulting activation map to be equivariant under shifts of the locations of input features in the visual field, i.e. they grant translational equivariance - given that the layer has a stride of one.\\nPooling: In a CNN\\'s pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value. In addition to reducing the sizes of feature maps, the pooling operation grants a degree of local translational invariance to the features contained therein, allowing the CNN to be more robust to variations in their positions.\\nTogether, these properties allow CNNs to achieve better generalization on vision problems. Weight sharing dramatically reduces the number of free parameters learned, thus lowering the memory requirements for running the network and allowing the training of larger, more powerful networks.\\n\\n\\n== Building blocks ==\\n\\nA CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume (e.g. holding the class scores) through a differentiable function. A few distinct types of layers are commonly used. These are further discussed below.\\n\\n\\n=== Convolutional layer ===\\nThe convolutional layer is the core building block of a CNN. The layer\\'s parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the filter entries and the input, producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.\\nStacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input. Each entry in an activation map use the same set of parameters that define the filter.\\nSelf-supervised learning has been adapted for use in convolutional layers by using sparse patches with a high-mask ratio and a global response normalization layer.\\n\\n\\n==== Local connectivity ====\\n\\nWhen dealing with high-dimensional inputs such as images, it is impractical to connect neurons to all neurons in the previous volume because such a network architecture does not take the spatial structure of the data into account. Convolutional networks exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.\\nThe extent of this connectivity is a hyperparameter called the receptive field of the neuron. The connections are local in space (along width and height), but always extend along the entire depth of the input volume. Such an architecture ensures that the learned (British English: learnt) filters produce the strongest response to a spatially local input pattern.\\n\\n\\n==== Spatial arrangement ====\\nThree hyperparameters control the size of the output volume of the convolutional layer: the depth, stride, and padding size:\\n\\nThe depth of the output volume controls the number of neurons in a layer that connect to the same region of the input volume. These neurons learn to activate for different features in the input. For example, if the first convolutional layer takes the raw image as input, then different neurons along the depth dimension may activate in the presence of various oriented edges, or blobs of color.\\nStride controls how depth columns around the width and height are allocated. If the stride is 1, then we move the filters one pixel at a time. This leads to heavily overlapping receptive fields between the columns, and to large output volumes. For any integer \\n  \\n    \\n      \\n        S\\n        >\\n        0\\n        ,\\n      \\n    \\n    {\\\\textstyle S>0,}\\n  \\n a stride S means that the filter is translated S units at a time per output. In practice, \\n  \\n    \\n      \\n        S\\n        ≥\\n        3\\n      \\n    \\n    {\\\\textstyle S\\\\geq 3}\\n  \\n is rare. A greater stride means smaller overlap of receptive fields and smaller spatial dimensions of the output volume.\\nSometimes, it is convenient to pad the input with zeros (or other values, such as the average of the region) on the border of the input volume. The size of this padding is a third hyperparameter. Padding provides control of the output volume\\'s spatial size. In particular, sometimes it is desirable to exactly preserve the spatial size of the input volume, this is commonly referred to as \"same\" padding.\\nThe spatial size of the output volume is a function of the input volume size \\n  \\n    \\n      \\n        W\\n      \\n    \\n    {\\\\displaystyle W}\\n  \\n, the kernel field size \\n  \\n    \\n      \\n        K\\n      \\n    \\n    {\\\\displaystyle K}\\n  \\n of the convolutional layer neurons, the stride \\n  \\n    \\n      \\n        S\\n      \\n    \\n    {\\\\displaystyle S}\\n  \\n, and the amount of zero padding \\n  \\n    \\n      \\n        P\\n      \\n    \\n    {\\\\displaystyle P}\\n  \\n on the border. The number of neurons that \"fit\" in a given volume is then:\\n\\nIf this number is not an integer, then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a symmetric way. In general, setting zero padding to be \\n  \\n    \\n      \\n        P\\n        =\\n        (\\n        K\\n        −\\n        1\\n        )\\n        \\n          /\\n        \\n        2\\n      \\n    \\n    {\\\\textstyle P=(K-1)/2}\\n  \\n when the stride is \\n  \\n    \\n      \\n        S\\n        =\\n        1\\n      \\n    \\n    {\\\\displaystyle S=1}\\n  \\n ensures that the input volume and output volume will have the same size spatially. However, it is not always completely necessary to use all of the neurons of the previous layer. For example, a neural network designer may decide to use just a portion of padding.\\n\\n\\n==== Parameter sharing ====\\nA parameter sharing scheme is used in convolutional layers to control the number of free parameters. It relies on the assumption that if a patch feature is useful to compute at some spatial position, then it should also be useful to compute at other positions. Denoting a single 2-dimensional slice of depth as a depth slice, the neurons in each depth slice are constrained to use the same weights and bias.\\nSince all neurons in a single depth slice share the same parameters, the forward pass in each depth slice of the convolutional layer can be computed as a convolution of the neuron\\'s weights with the input volume. Therefore, it is common to refer to the sets of weights as a filter (or a kernel), which is convolved with the input. The result of this convolution is an activation map, and the set of activation maps for each different filter are stacked together along the depth dimension to produce the output volume. Parameter sharing contributes to the translation invariance of the CNN architecture.\\nSometimes, the parameter sharing assumption may not make sense. This is especially the case when the input images to a CNN have some specific centered structure; for which we expect completely different features to be learned on different spatial locations. One practical example is when the inputs are faces that have been centered in the image: we might expect different eye-specific or hair-specific features to be learned in different parts of the image. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a \"locally connected layer\".\\n\\n\\n=== Pooling layer ===\\n\\nAnother important concept of CNNs is pooling, which is a form of non-linear down-sampling. There are several non-linear functions to implement pooling, where max pooling is the most common. It partitions the input image into a set of rectangles and, for each such sub-region, outputs the maximum.\\nIntuitively, the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting. This is known as down-sampling. It is common to periodically insert a pooling layer between successive convolutional layers (each one typically followed by an activation function, such as a ReLU layer) in a CNN architecture.:\\u200a460–461\\u200a While pooling layers contribute to local translation invariance, they do not provide global translation invariance in a CNN, unless a form of global pooling is used. The pooling layer commonly operates independently on every depth, or slice, of the input and resizes it spatially. A very common form of max pooling is a layer with filters of size 2×2, applied with a stride of 2, which subsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations:\\nIn this case, every max operation is over 4 numbers. The depth dimension remains unchanged (this is true for other forms of pooling as well).\\nIn addition to max pooling, pooling units can use other functions, such as average pooling or ℓ2-norm pooling. Average pooling was often used historically but has recently fallen out of favor compared to max pooling, which generally performs better in practice.\\nDue to the effects of fast spatial reduction of the size of the representation, there is a recent trend towards using smaller filters or discarding pooling layers altogether.\\n\\n\"Region of Interest\" pooling (also known as RoI pooling) is a variant of max pooling, in which output size is fixed and input rectangle is a parameter.\\nPooling is a downsampling method and an important component of convolutional neural networks for object detection based on the Fast R-CNN architecture.\\n\\n\\n=== Channel Max Pooling ===\\nA CMP operation layer conducts the MP operation along the channel side among the corresponding positions of the consecutive feature maps for the purpose of redundant information elimination. The CMP makes the significant features gather together within fewer channels, which is important for fine-grained image classification that needs more discriminating features. Meanwhile, another advantage of the CMP operation is to make the channel number of feature maps smaller before it connects to the first fully connected (FC) layer. Similar to the MP operation, we denote the input feature maps and output feature maps of a CMP layer as F ∈ R(C×M×N) and C ∈ R(c×M×N), respectively, where C and c are the channel numbers of the input and output feature maps, M and N are the widths and the height of the feature maps, respectively. Note that the CMP operation only changes the channel number of the feature maps. The width and the height of the feature maps are not changed, which is different from the MP operation.\\n\\n\\n=== ReLU layer ===\\nReLU is the abbreviation of rectified linear unit introduced by Kunihiko Fukushima in 1969. ReLU applies the non-saturating activation function \\n  \\n    \\n      \\n        f\\n        (\\n        x\\n        )\\n        =\\n        max\\n        (\\n        0\\n        ,\\n        x\\n        )\\n      \\n    \\n    {\\\\textstyle f(x)=\\\\max(0,x)}\\n  \\n. It effectively removes negative values from an activation map by setting them to zero. It introduces nonlinearity to the decision function and in the overall network without affecting the receptive fields of the convolution layers.\\nIn 2011, Xavier Glorot, Antoine Bordes and Yoshua Bengio found that ReLU enables better training of deeper networks, compared to widely used activation functions prior to 2011.\\nOther functions can also be used to increase nonlinearity, for example the saturating hyperbolic tangent \\n  \\n    \\n      \\n        f\\n        (\\n        x\\n        )\\n        =\\n        tanh\\n        \\u2061\\n        (\\n        x\\n        )\\n      \\n    \\n    {\\\\displaystyle f(x)=\\\\tanh(x)}\\n  \\n, \\n  \\n    \\n      \\n        f\\n        (\\n        x\\n        )\\n        =\\n        \\n          |\\n        \\n        tanh\\n        \\u2061\\n        (\\n        x\\n        )\\n        \\n          |\\n        \\n      \\n    \\n    {\\\\displaystyle f(x)=|\\\\tanh(x)|}\\n  \\n, and the sigmoid function \\n  \\n    \\n      \\n        σ\\n        (\\n        x\\n        )\\n        =\\n        (\\n        1\\n        +\\n        \\n          e\\n          \\n            −\\n            x\\n          \\n        \\n        \\n          )\\n          \\n            −\\n            1\\n          \\n        \\n      \\n    \\n    {\\\\textstyle \\\\sigma (x)=(1+e^{-x})^{-1}}\\n  \\n. ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to generalization accuracy.\\n\\n\\n=== Fully connected layer ===\\nAfter several convolutional and max pooling layers, the final classification is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular (non-convolutional) artificial neural networks. Their activations can thus be computed as an affine transformation, with matrix multiplication followed by a bias offset (vector addition of a learned or fixed bias term).\\n\\n\\n=== Loss layer ===\\n\\nThe \"loss layer\", or \"loss function\", specifies how training penalizes the deviation between the predicted output of the network, and the true data labels (during supervised learning). Various loss functions can be used, depending on the specific task.\\nThe Softmax loss function is used for predicting a single class of K mutually exclusive classes. Sigmoid cross-entropy loss is used for predicting K independent probability values in \\n  \\n    \\n      \\n        [\\n        0\\n        ,\\n        1\\n        ]\\n      \\n    \\n    {\\\\displaystyle [0,1]}\\n  \\n. Euclidean loss is used for regressing to real-valued labels \\n  \\n    \\n      \\n        (\\n        −\\n        ∞\\n        ,\\n        ∞\\n        )\\n      \\n    \\n    {\\\\displaystyle (-\\\\infty ,\\\\infty )}\\n  \\n.\\n\\n\\n== Hyperparameters ==\\n\\nHyperparameters are various settings that are used to control the learning process. CNNs use more hyperparameters than a standard multilayer perceptron (MLP).\\n\\n\\n=== Kernel size ===\\nThe kernel is the number of pixels processed together. It is typically expressed as the kernel\\'s dimensions, e.g., 2x2, or 3x3.\\n\\n\\n=== Padding ===\\nPadding is the addition of (typically) 0-valued pixels on the borders of an image. This is done so that the border pixels are not undervalued (lost) from the output because they would ordinarily participate in only a single receptive field instance. The padding applied is typically one less than the corresponding kernel dimension. For example, a convolutional layer using 3x3 kernels would receive a 2-pixel pad, that is 1 pixel on each side of the image.\\n\\n\\n=== Stride ===\\nThe stride is the number of pixels that the analysis window moves on each iteration. A stride of 2 means that each kernel is offset by 2 pixels from its predecessor.\\n\\n\\n=== Number of filters ===\\nSince feature map size decreases with depth, layers near the input layer tend to have fewer filters while higher layers can have more. To equalize computation at each layer, the product of feature values va with pixel position is kept roughly constant across layers. Preserving more information about the input would require keeping the total number of activations (number of feature maps times number of pixel positions) non-decreasing from one layer to the next.\\nThe number of feature maps directly controls the capacity and depends on the number of available examples and task complexity.\\n\\n\\n=== Filter size ===\\nCommon filter sizes found in the literature vary greatly, and are usually chosen based on the data set.\\nThe challenge is to find the right level of granularity so as to create abstractions at the proper scale, given a particular data set, and without overfitting.\\n\\n\\n=== Pooling type and size ===\\nMax pooling is typically used, often with a 2x2 dimension. This implies that the input is drastically downsampled, reducing processing cost.\\nGreater pooling reduces the dimension of the signal, and may result in unacceptable information loss. Often, non-overlapping pooling windows perform best.\\n\\n\\n=== Dilation ===\\nDilation involves ignoring pixels within a kernel. This reduces processing/memory potentially without significant signal loss. A dilation of 2 on a 3x3 kernel expands the kernel to 5x5, while still processing 9 (evenly spaced) pixels. Accordingly, dilation of 4 expands the kernel to 7x7.\\n\\n\\n== Translation equivariance and aliasing ==\\nIt is commonly assumed that CNNs are invariant to shifts of the input. Convolution or pooling layers within a CNN that do not have a stride greater than one are indeed equivariant to translations of the input. However, layers with a stride greater than one ignore the Nyquist-Shannon sampling theorem and might lead to aliasing of the input signal While, in principle, CNNs are capable of implementing anti-aliasing filters, it has been observed that this does not happen in practice  and yield models that are not equivariant to translations.\\nFurthermore, if a CNN makes use of fully connected layers, translation equivariance does not imply translation invariance, as the fully connected layers are not invariant to shifts of the input. One solution for complete translation invariance is avoiding any down-sampling throughout the network and applying global average pooling at the last layer. Additionally, several other partial solutions have been proposed, such as anti-aliasing before downsampling operations, spatial transformer networks, data augmentation, subsampling combined with pooling, and capsule neural networks.\\n\\n\\n== Evaluation ==\\nThe accuracy of the final model is based on a sub-part of the dataset set apart at the start, often called a test-set. Other times methods such as k-fold cross-validation are applied. Other strategies include using conformal prediction.\\n\\n\\n== Regularization methods ==\\n\\nRegularization is a process of introducing additional information to solve an ill-posed problem or to prevent overfitting. CNNs use various types of regularization.\\n\\n\\n=== Empirical ===\\n\\n\\n==== Dropout ====\\nBecause a fully connected layer occupies most of the parameters, it is prone to overfitting. One method to reduce overfitting is dropout, introduced in 2014. At each training stage, individual nodes are either \"dropped out\" of the net (ignored) with probability \\n  \\n    \\n      \\n        1\\n        −\\n        p\\n      \\n    \\n    {\\\\displaystyle 1-p}\\n  \\n or kept with probability \\n  \\n    \\n      \\n        p\\n      \\n    \\n    {\\\\displaystyle p}\\n  \\n, so that a reduced network is left; incoming and outgoing edges to a dropped-out node are also removed. Only the reduced network is trained on the data in that stage. The removed nodes are then reinserted into the network with their original weights.\\nIn the training stages, \\n  \\n    \\n      \\n        p\\n      \\n    \\n    {\\\\displaystyle p}\\n  \\n is usually 0.5; for input nodes, it is typically much higher because information is directly lost when input nodes are ignored.\\nAt testing time after training has finished, we would ideally like to find a sample average of all possible \\n  \\n    \\n      \\n        \\n          2\\n          \\n            n\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle 2^{n}}\\n  \\n dropped-out networks; unfortunately this is unfeasible for large values of \\n  \\n    \\n      \\n        n\\n      \\n    \\n    {\\\\displaystyle n}\\n  \\n. However, we can find an approximation by using the full network with each node\\'s output weighted by a factor of \\n  \\n    \\n      \\n        p\\n      \\n    \\n    {\\\\displaystyle p}\\n  \\n, so the expected value of the output of any node is the same as in the training stages. This is the biggest contribution of the dropout method: although it effectively generates \\n  \\n    \\n      \\n        \\n          2\\n          \\n            n\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle 2^{n}}\\n  \\n neural nets, and as such allows for model combination, at test time only a single network needs to be tested.\\nBy avoiding training all nodes on all training data, dropout decreases overfitting. The method also significantly improves training speed. This makes the model combination practical, even for deep neural networks. The technique seems to reduce node interactions, leading them to learn more robust features that better generalize to new data.\\n\\n\\n==== DropConnect ====\\nDropConnect is the generalization of dropout in which each connection, rather than each output unit, can be dropped with probability \\n  \\n    \\n      \\n        1\\n        −\\n        p\\n      \\n    \\n    {\\\\displaystyle 1-p}\\n  \\n. Each unit thus receives input from a random subset of units in the previous layer.\\nDropConnect is similar to dropout as it introduces dynamic sparsity within the model, but differs in that the sparsity is on the weights, rather than the output vectors of a layer. In other words, the fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage.\\n\\n\\n==== Stochastic pooling ====\\nA major drawback to Dropout is that it does not have the same benefits for convolutional layers, where the neurons are not fully connected.\\nEven before Dropout, in 2013 a technique called stochastic pooling, the conventional deterministic pooling operations were replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region. This approach is free of hyperparameters and can be combined with other regularization approaches, such as dropout and data augmentation.\\nAn alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations. This is similar to explicit elastic deformations of the input images, which delivers excellent performance on the MNIST data set. Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.\\n\\n\\n==== Artificial data ====\\n\\nBecause the degree of model overfitting is determined by both its power and the amount of training it receives, providing a convolutional network with more training examples can reduce overfitting. Because there is often not enough available data to train, especially considering that some part should be spared for later testing, two approaches are to either generate new data from scratch (if possible) or perturb existing data to create new ones. The latter one is used since mid-1990s. For example, input images can be cropped, rotated, or rescaled to create new examples with the same labels as the original training set.\\n\\n\\n=== Explicit ===\\n\\n\\n==== Early stopping ====\\n\\nOne of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur. It comes with the disadvantage that the learning process is halted.\\n\\n\\n==== Number of parameters ====\\nAnother simple way to prevent overfitting is to limit the number of parameters, typically by limiting the number of hidden units in each layer or limiting network depth. For convolutional networks, the filter size also affects the number of parameters. Limiting the number of parameters restricts the predictive power of the network directly, reducing the complexity of the function that it can perform on the data, and thus limits the amount of overfitting. This is equivalent to a \"zero norm\".\\n\\n\\n==== Weight decay ====\\nA simple form of added regularizer is weight decay, which simply adds an additional error, proportional to the sum of weights (L1 norm) or squared magnitude (L2 norm) of the weight vector, to the error at each node. The level of acceptable model complexity can be reduced by increasing the proportionality constant(\\'alpha\\' hyperparameter), thus increasing the penalty for large weight vectors.\\nL2 regularization is the most common form of regularization. It can be implemented by penalizing the squared magnitude of all parameters directly in the objective. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. Due to multiplicative interactions between weights and inputs this has the useful property of encouraging the network to use all of its inputs a little rather than some of its inputs a lot.\\nL1 regularization is also common. It makes the weight vectors sparse during optimization. In other words, neurons with L1 regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the noisy inputs. L1 with L2 regularization can be combined; this is called elastic net regularization.\\n\\n\\n==== Max norm constraints ====\\nAnother form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint. In practice, this corresponds to performing the parameter update as normal, and then enforcing the constraint by clamping the weight vector \\n  \\n    \\n      \\n        \\n          \\n            \\n              w\\n              →\\n            \\n          \\n        \\n      \\n    \\n    {\\\\displaystyle {\\\\vec {w}}}\\n  \\n of every neuron to satisfy \\n  \\n    \\n      \\n        ‖\\n        \\n          \\n            \\n              w\\n              →\\n            \\n          \\n        \\n        \\n          ‖\\n          \\n            2\\n          \\n        \\n        <\\n        c\\n      \\n    \\n    {\\\\displaystyle \\\\|{\\\\vec {w}}\\\\|_{2}<c}\\n  \\n. Typical values of \\n  \\n    \\n      \\n        c\\n      \\n    \\n    {\\\\displaystyle c}\\n  \\n are order of 3–4. Some papers report improvements when using this form of regularization.\\n\\n\\n== Hierarchical coordinate frames ==\\nPooling loses the precise spatial relationships between high-level parts (such as nose and mouth in a face image). These relationships are needed for identity recognition. Overlapping the pools so that each feature occurs in multiple pools, helps retain the information. Translation alone cannot extrapolate the understanding of geometric relationships to a radically new viewpoint, such as a different orientation or scale. On the other hand, people are very good at extrapolating; after seeing a new shape once they can recognize it from a different viewpoint.\\nAn earlier common way to deal with this problem is to train the network on transformed data in different orientations, scales, lighting, etc. so that the network can cope with these variations. This is computationally intensive for large data-sets. The alternative is to use a hierarchy of coordinate frames and use a group of neurons to represent a conjunction of the shape of the feature and its pose relative to the retina. The pose relative to the retina is the relationship between the coordinate frame of the retina and the intrinsic features\\' coordinate frame.\\nThus, one way to represent something is to embed the coordinate frame within it. This allows large features to be recognized by using the consistency of the poses of their parts (e.g. nose and mouth poses make a consistent prediction of the pose of the whole face). This approach ensures that the higher-level entity (e.g. face) is present when the lower-level (e.g. nose and mouth) agree on its prediction of the pose. The vectors of neuronal activity that represent pose (\"pose vectors\") allow spatial transformations modeled as linear operations that make it easier for the network to learn the hierarchy of visual entities and generalize across viewpoints. This is similar to the way the human visual system imposes coordinate frames in order to represent shapes.\\n\\n\\n== Applications ==\\n\\n\\n=== Image recognition ===\\nCNNs are often used in image recognition systems. In 2012, an error rate of 0.23% on the MNIST database was reported. Another paper on using CNN for image classification reported that the learning process was \"surprisingly fast\"; in the same paper, the best published results as of 2011 were achieved in the MNIST database and the NORB database. Subsequently, a similar CNN called\\nAlexNet won the ImageNet Large Scale Visual Recognition Challenge 2012.\\nWhen applied to facial recognition, CNNs achieved a large decrease in error rate. Another paper reported a 97.6% recognition rate on \"5,600 still images of more than 10 subjects\". CNNs were used to assess video quality in an objective way after manual training; the resulting system had a very low root mean square error.\\nThe ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes. In the ILSVRC 2014, a large-scale visual recognition challenge, almost every highly ranked team used CNN as their basic framework. The winner GoogLeNet (the foundation of DeepDream) increased the mean average precision of object detection to 0.439329, and reduced classification error to 0.06656, the best result to date. Its network applied more than 30 layers. That performance of convolutional neural networks on the ImageNet tests was close to that of humans. The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters, an increasingly common phenomenon with modern digital cameras. By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained categories such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this.\\nIn 2015, a many-layered CNN demonstrated the ability to spot faces from a wide range of angles, including upside down, even when partially occluded, with competitive performance. The network was trained on a database of 200,000 images that included faces at various angles and orientations and a further 20 million images without faces. They used batches of 128 images over 50,000 iterations.\\n\\n\\n=== Video analysis ===\\nCompared to image data domains, there is relatively little work on applying CNNs to video classification. Video is more complex than images since it has another (temporal) dimension. However, some extensions of CNNs into the video domain have been explored. One approach is to treat space and time as equivalent dimensions of the input and perform convolutions in both time and space. Another way is to fuse the features of two convolutional neural networks, one for the spatial and one for the temporal stream. Long short-term memory (LSTM) recurrent units are typically incorporated after the CNN to account for inter-frame or inter-clip dependencies. Unsupervised learning schemes for training spatio-temporal features have been introduced, based on Convolutional Gated Restricted Boltzmann Machines and Independent Subspace Analysis. Its Application can be seen in Text-to-Video model.\\n\\n\\n=== Natural language processing ===\\nCNNs have also been explored for natural language processing. CNN models are effective for various NLP problems and achieved excellent results in semantic parsing, search query retrieval, sentence modeling, classification, prediction and other traditional NLP tasks.\\nCompared to traditional language processing methods such as recurrent neural networks, CNNs can represent different contextual realities of language that do not rely on a series-sequence assumption, while RNNs are better suitable when classical time series modeling is required.\\n\\n\\n=== Anomaly Detection ===\\nA CNN with 1-D convolutions was used on time series in the frequency domain (spectral residual) by an unsupervised model to detect anomalies in the time domain.\\n\\n\\n=== Drug discovery ===\\nCNNs have been used in drug discovery. Predicting the interaction between molecules and biological proteins can identify potential treatments. In 2015, Atomwise introduced AtomNet, the first deep learning neural network for structure-based drug design. The system trains directly on 3-dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller, spatially proximate features into larger, complex structures, AtomNet discovers chemical features, such as aromaticity, sp3 carbons, and hydrogen bonding. Subsequently, AtomNet was used to predict novel candidate biomolecules for multiple disease targets, most notably treatments for the Ebola virus and multiple sclerosis.\\n\\n\\n=== Checkers game ===\\nCNNs have been used in the game of checkers. From 1999 to 2001, Fogel and Chellapilla published papers showing how a convolutional neural network could learn to play checker using co-evolution. The learning process did not use prior human professional games, but rather focused on a minimal set of information contained in the checkerboard: the location and type of pieces, and the difference in number of pieces between the two sides. Ultimately, the program (Blondie24) was tested on 165 games against players and ranked in the highest 0.4%. It also earned a win against the program Chinook at its \"expert\" level of play.\\n\\n\\n=== Go ===\\nCNNs have been used in computer Go. In December 2014, Clark and Storkey published a paper showing that a CNN trained by supervised learning from a database of human professional games could outperform GNU Go and win some games against Monte Carlo tree search Fuego 1.1 in a fraction of the time it took Fuego to play. Later it was announced that a large 12-layer convolutional neural network had correctly predicted the professional move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GNU Go in 97% of games, and matched the performance of the Monte Carlo tree search program Fuego simulating ten thousand playouts (about a million positions) per move.\\nA couple of CNNs for choosing moves to try (\"policy network\") and evaluating positions (\"value network\") driving MCTS were used by AlphaGo, the first to beat the best human player at the time.\\n\\n\\n=== Time series forecasting ===\\nRecurrent neural networks are generally considered the best neural network architectures for time series forecasting (and sequence modeling in general), but recent studies show that convolutional networks can perform comparably or even better. Dilated convolutions might enable one-dimensional convolutional neural networks to effectively learn time series dependences. Convolutions can be implemented more efficiently than RNN-based solutions, and they do not suffer from vanishing (or exploding) gradients. Convolutional networks can provide an improved forecasting performance when there are multiple similar time series to learn from. CNNs can also be applied to further tasks in time series analysis (e.g., time series classification or quantile forecasting).\\n\\n\\n=== Cultural Heritage and 3D-datasets ===\\nAs archaeological findings like clay tablets with cuneiform writing are increasingly acquired using 3D scanners first benchmark datasets are becoming available like HeiCuBeDa providing almost 2.000 normalized 2D- and 3D-datasets prepared with the GigaMesh Software Framework. So curvature-based measures are used in conjunction with Geometric Neural Networks (GNNs) e.g. for period classification of those clay tablets being among the oldest documents of human history.\\n\\n\\n== Fine-tuning ==\\nFor many applications, the training data is less available. Convolutional neural networks usually require a large amount of training data in order to avoid overfitting. A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the in-domain data to fine-tune the network weights, this is known as transfer learning. Furthermore, this technique allows convolutional network architectures to successfully be applied to problems with tiny training sets.\\n\\n\\n== Human interpretable explanations ==\\nEnd-to-end training and prediction are common practice in computer vision. However, human interpretable explanations are required for critical systems such as a self-driving cars. With recent advances in visual salience, spatial attention, and temporal attention, the most critical spatial regions/temporal instants could be visualized to justify the CNN predictions.\\n\\n\\n== Related architectures ==\\n\\n\\n=== Deep Q-networks ===\\nA deep Q-network (DQN) is a type of deep learning model that combines a deep neural network with Q-learning, a form of reinforcement learning. Unlike earlier reinforcement learning agents, DQNs that utilize CNNs can learn directly from high-dimensional sensory inputs via reinforcement learning.\\nPreliminary results were presented in 2014, with an accompanying paper in February 2015. The research described an application to Atari 2600 gaming. Other deep reinforcement learning models preceded it.\\n\\n\\n=== Deep belief networks ===\\n\\nConvolutional deep belief networks (CDBN) have structure very similar to convolutional neural networks and are trained similarly to deep belief networks. Therefore, they exploit the 2D structure of images, like CNNs do, and make use of pre-training like deep belief networks. They provide a generic structure that can be used in many image and signal processing tasks. Benchmark results on standard image datasets like CIFAR have been obtained using CDBNs.\\n\\n\\n== Notable libraries ==\\nCaffe: A library for convolutional neural networks. Created by the Berkeley Vision and Learning Center (BVLC). It supports both CPU and GPU. Developed in C++, and has Python and MATLAB wrappers.\\nDeeplearning4j: Deep learning in Java and Scala on multi-GPU-enabled Spark. A general-purpose deep learning library for the JVM production stack running on a C++ scientific computing engine. Allows the creation of custom layers. Integrates with Hadoop and Kafka.\\nDlib: A toolkit for making real world machine learning and data analysis applications in C++.\\nMicrosoft Cognitive Toolkit: A deep learning toolkit written by Microsoft with several unique features enhancing scalability over multiple nodes. It supports full-fledged interfaces for training in C++ and Python and with additional support for model inference in C# and Java.\\nTensorFlow: Apache 2.0-licensed Theano-like library with support for CPU, GPU, Google\\'s proprietary tensor processing unit (TPU), and mobile devices.\\nTheano: The reference deep-learning library for Python with an API largely compatible with the popular NumPy library. Allows user to write symbolic mathematical expressions, then automatically generates their derivatives, saving the user from having to code gradients or backpropagation. These symbolic expressions are automatically compiled to CUDA code for a fast, on-the-GPU implementation.\\nTorch: A scientific computing framework with wide support for machine learning algorithms, written in C and Lua.\\n\\n\\n== See also ==\\nAttention (machine learning)\\nConvolution\\nDeep learning\\nNatural-language processing\\nNeocognitron\\nScale-invariant feature transform\\nTime delay neural network\\nVision processing unit\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nCS231n: Convolutional Neural Networks for Visual Recognition — Andrej Karpathy\\'s Stanford computer science course on CNNs in computer vision']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(documents):\n",
        "    processed_documents = []\n",
        "    for document in documents:\n",
        "        processed_doc = str(document)\n",
        "        processed_doc = re.sub(r'[^a-zA-Z\\s]', '', processed_doc)\n",
        "        processed_doc = processed_doc.lower()\n",
        "\n",
        "        sentaces_minus_sw = []\n",
        "        # stop_words = stopwords.words('english')\n",
        "        processed_doc = processed_doc.split()\n",
        "        processed_doc = [sentaces_minus_sw.append(word) for word in processed_doc]\n",
        "        processed_doc = ' '.join(sentaces_minus_sw)\n",
        "\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        processed_doc = processed_doc.split()\n",
        "        processed_doc = [lemmatizer.lemmatize(w) for w in processed_doc]\n",
        "        processed_doc = ' '.join(processed_doc)\n",
        "\n",
        "        processed_documents.append(processed_doc)\n",
        "\n",
        "    return processed_documents"
      ],
      "metadata": {
        "id": "e5KztxT5KK4J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs = preprocess(documents)"
      ],
      "metadata": {
        "id": "ypo4ACcWL0lh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpMBlisIL0oa",
        "outputId": "6f5f4481-01b0-42eb-b552-1757fe507a2a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial intelligence ai in it broadest sense is intelligence exhibited by machine particularly computer system it is a field of research in computer science that develops and study method and software that enable machine to perceive their environment and us learning and intelligence to take action that maximize their chance of achieving defined goal such machine may be called aisnai technology is widely used throughout industry government and science some highprofile application include advanced web search engine eg google search recommendation system used by youtube amazon and netflix interacting via human speech eg google assistant siri and alexa autonomous vehicle eg waymo generative and creative tool eg chatgpt and ai art and superhuman play and analysis in strategy game eg chess and go however many ai application are not perceived a ai a lot of cutting edge ai ha filtered into general application often without being called ai because once something becomes useful enough and common enough it not labeled ai anymorenalan turing wa the first person to conduct substantial research in the field that he called machine intelligence artificial intelligence wa founded a an academic discipline in the field went through multiple cycle of optimism followed by period of disappointment and loss of funding known a ai winter funding and interest vastly increased after when deep learning surpassed all previous ai technique and after with the transformer architecture this led to the ai boom of the early s with company university and laboratory overwhelmingly based in the united state pioneering significant advance in artificial intelligencenthe growing use of artificial intelligence in the st century is influencing a societal and economic shift towards increased automation datadriven decisionmaking and the integration of ai system into various economic sector and area of life impacting job market healthcare government industry and education this raise question about the longterm effect ethical implication and risk of ai prompting discussion about regulatory policy to ensure the safety and benefit of the technology nthe various subfields of ai research are centered around particular goal and the use of particular tool the traditional goal of ai research include reasoning knowledge representation planning learning natural language processing perception and support for robotics general intelligencethe ability to complete any task performable by a human on an at least equal levelis among the field longterm goalsnto reach these goal ai researcher have adapted and integrated a wide range of technique including search and mathematical optimization formal logic artificial neural network and method based on statistic operation research and economics ai also draw upon psychology linguistics philosophy neuroscience and other fieldsnnn goal nthe general problem of simulating or creating intelligence ha been broken into subproblems these consist of particular trait or capability that researcher expect an intelligent system to display the trait described below have received the most attention and cover the scope of ai researchnnn reasoning and problemsolving nearly researcher developed algorithm that imitated stepbystep reasoning that human use when they solve puzzle or make logical deduction by the late s and s method were developed for dealing with uncertain or incomplete information employing concept from probability and economicsnmany of these algorithm are insufficient for solving large reasoning problem because they experience a combinatorial explosion they become exponentially slower a the problem grow even human rarely use the stepbystep deduction that early ai research could model they solve most of their problem using fast intuitive judgment accurate and efficient reasoning is an unsolved problemnnn knowledge representation nnknowledge representation and knowledge engineering allow ai program to answer question intelligently and make deduction about realworld fact formal knowledge representation are used in contentbased indexing and retrieval scene interpretation clinical decision support knowledge discovery mining interesting and actionable inference from large database and other areasna knowledge base is a body of knowledge represented in a form that can be used by a program an ontology is the set of object relation concept and property used by a particular domain of knowledge knowledge base need to represent thing such a object property category and relation between object situation event state and time cause and effect knowledge about knowledge what we know about what other people know default reasoning thing that human assume are true until they are told differently and will remain true even when other fact are changing and many other aspect and domain of knowledgenamong the most difficult problem in knowledge representation are the breadth of commonsense knowledge the set of atomic fact that the average person know is enormous and the subsymbolic form of most commonsense knowledge much of what people know is not represented a fact or statement that they could express verbally there is also the difficulty of knowledge acquisition the problem of obtaining knowledge for ai applicationsnnn planning and decisionmaking nan agent is anything that perceives and take action in the world a rational agent ha goal or preference and take action to make them happen in automated planning the agent ha a specific goal in automated decisionmaking the agent ha preferencesthere are some situation it would prefer to be in and some situation it is trying to avoid the decisionmaking agent assigns a number to each situation called the utility that measure how much the agent prefers it for each possible action it can calculate the expected utility the utility of all possible outcome of the action weighted by the probability that the outcome will occur it can then choose the action with the maximum expected utilitynin classical planning the agent know exactly what the effect of any action will be in most realworld problem however the agent may not be certain about the situation they are in it is unknown or unobservable and it may not know for certain what will happen after each possible action it is not deterministic it must choose an action by making a probabilistic guess and then reassess the situation to see if the action workednin some problem the agent preference may be uncertain especially if there are other agent or human involved these can be learned eg with inverse reinforcement learning or the agent can seek information to improve it preference information value theory can be used to weigh the value of exploratory or experimental action the space of possible future action and situation is typically intractably large so the agent must take action and evaluate situation while being uncertain of what the outcome will bena markov decision process ha a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supply the utility of each state and the cost of each action a policy associate a decision with each possible state the policy could be calculated eg by iteration be heuristic or it can be learnedngame theory describes the rational behavior of multiple interacting agent and is used in ai program that make decision that involve other agentsnnn learning nmachine learning is the study of program that can improve their performance on a given task automatically it ha been a part of ai from the beginningnthere are several kind of machine learning unsupervised learning analyzes a stream of data and find pattern and make prediction without any other guidance supervised learning requires a human to label the input data first and come in two main variety classification where the program must learn to predict what category the input belongs in and regression where the program must deduce a numeric function based on numeric inputnin reinforcement learning the agent is rewarded for good response and punished for bad one the agent learns to choose response that are classified a good transfer learning is when the knowledge gained from one problem is applied to a new problem deep learning is a type of machine learning that run input through biologically inspired artificial neural network for all of these type of learningncomputational learning theory can ass learner by computational complexity by sample complexity how much data is required or by other notion of optimizationnnn natural language processing nnatural language processing nlp allows program to read write and communicate in human language such a english specific problem include speech recognition speech synthesis machine translation information extraction information retrieval and question answeringnearly work based on noam chomsky generative grammar and semantic network had difficulty with wordsense disambiguation unless restricted to small domain called microworlds due to the common sense knowledge problem margaret masterman believed that it wa meaning and not grammar that wa the key to understanding language and that thesaurus and not dictionary should be the basis of computational language structurenmodern deep learning technique for nlp include word embedding representing word typically a vector encoding their meaning transformer a deep learning architecture using an attention mechanism and others in generative pretrained transformer or gpt language model began to generate coherent text and by these model were able to get humanlevel score on the bar exam sat test gre test and many other realworld applicationsnnn perception nmachine perception is the ability to use input from sensor such a camera microphone wireless signal active lidar sonar radar and tactile sensor to deduce aspect of the world computer vision is the ability to analyze visual inputnthe field includes speech recognition image classification facial recognition object recognition and robotic perceptionnnn social intelligence nnaffective computing is an interdisciplinary umbrella that comprises system that recognize interpret process or simulate human feeling emotion and mood for example some virtual assistant are programmed to speak conversationally or even to banter humorously it make them appear more sensitive to the emotional dynamic of human interaction or to otherwise facilitate humancomputer interactionnhowever this tends to give nave user an unrealistic conception of the intelligence of existing computer agent moderate success related to affective computing include textual sentiment analysis and more recently multimodal sentiment analysis wherein ai classifies the affect displayed by a videotaped subjectnnn general intelligence na machine with artificial general intelligence should be able to solve a wide variety of problem with breadth and versatility similar to human intelligencennn technique nai research us a wide variety of technique to accomplish the goal abovennn search and optimization nai can solve many problem by intelligently searching through many possible solution there are two very different kind of search used in ai state space search and local searchnnn state space search nstate space search search through a tree of possible state to try to find a goal state for example planning algorithm search through tree of goal and subgoals attempting to find a path to a target goal a process called meansends analysisnsimple exhaustive search are rarely sufficient for most realworld problem the search space the number of place to search quickly grows to astronomical number the result is a search that is too slow or never completes heuristic or rule of thumb can help prioritize choice that are more likely to reach a goalnadversarial search is used for gameplaying program such a chess or go it search through a tree of possible move and countermove looking for a winning positionnnn local search nlocal search us mathematical optimization to find a solution to a problem it begin with some form of guess and refines it incrementallyngradient descent is a type of local search that optimizes a set of numerical parameter by incrementally adjusting them to minimize a loss function variant of gradient descent are commonly used to train neural networksnanother type of local search is evolutionary computation which aim to iteratively improve a set of candidate solution by mutating and recombining them selecting only the fittest to survive each generationndistributed search process can coordinate via swarm intelligence algorithm two popular swarm algorithm used in search are particle swarm optimization inspired by bird flocking and ant colony optimization inspired by ant trailsnnn logic nformal logic is used for reasoning and knowledge representationnformal logic come in two main form propositional logic which operates on statement that are true or false and us logical connective such a and or not and implies and predicate logic which also operates on object predicate and relation and us quantifier such a every x is a y and there are some x that are ysndeductive reasoning in logic is the process of proving a new statement conclusion from other statement that are given and assumed to be true the premise proof can be structured a proof tree in which node are labelled by sentence and child node are connected to parent node by inference rulesngiven a problem and a set of premise problemsolving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf node are labelled by premise or axiom in the case of horn clause problemsolving search can be performed by reasoning forward from the premise or backwards from the problem in the more general case of the clausal form of firstorder logic resolution is a single axiomfree rule of inference in which a problem is solved by proving a contradiction from premise that include the negation of the problem to be solvedninference in both horn clause logic and firstorder logic is undecidable and therefore intractable however backward reasoning with horn clause which underpins computation in the logic programming language prolog is turing complete moreover it efficiency is competitive with computation in other symbolic programming languagesnfuzzy logic assigns a degree of truth between and it can therefore handle proposition that are vague and partially truennonmonotonic logic including logic programming with negation a failure are designed to handle default reasoningnother specialized version of logic have been developed to describe many complex domainsnnn probabilistic method for uncertain reasoning nnmany problem in ai including in reasoning planning learning perception and robotics require the agent to operate with incomplete or uncertain information ai researcher have devised a number of tool to solve these problem using method from probability theory and economics precise mathematical tool have been developed that analyze how an agent can make choice and plan using decision theory decision analysis and information value theory these tool include model such a markov decision process dynamic decision network game theory and mechanism designnbayesian network are a tool that can be used for reasoning using the bayesian inference algorithm learning using the expectationmaximization algorithm planning using decision network and perception using dynamic bayesian networksnnprobabilistic algorithm can also be used for filtering prediction smoothing and finding explanation for stream of data thus helping perception system analyze process that occur over time eg hidden markov model or kalman filtersnnn classifier and statistical learning method nthe simplest ai application can be divided into two type classifier eg if shiny then diamond on one hand and controller eg if diamond then pick up on the other hand classifier are function that use pattern matching to determine the closest match they can be finetuned based on chosen example using supervised learning each pattern also called an observation is labeled with a certain predefined class all the observation combined with their class label are known a a data set when a new observation is received that observation is classified based on previous experiencenthere are many kind of classifier in use the decision tree is the simplest and most widely used symbolic machine learning algorithm knearest neighbor algorithm wa the most widely used analogical ai until the mids and kernel method such a the support vector machine svm displaced knearest neighbor in the snthe naive bayes classifier is reportedly the most widely used learner at google due in part to it scalabilitynneural network are also used a classifiersnnn artificial neural network nnan artificial neural network is based on a collection of node also known a artificial neuron which loosely model the neuron in a biological brain it is trained to recognise pattern once trained it can recognise those pattern in fresh data there is an input at least one hidden layer of node and an output each node applies a function and once the weight cross it specified threshold the data is transmitted to the next layer a network is typically called a deep neural network if it ha at least hidden layersnlearning algorithm for neural network use local search to choose the weight that will get the right output for each input during training the most common training technique is the backpropagation algorithmnneural network learn to model complex relationship between input and output and find pattern in data in theory a neural network can learn any functionnin feedforward neural network the signal pass in only one direction recurrent neural network feed the output signal back into the input which allows shortterm memory of previous input event long short term memory is the most successful network architecture for recurrent networksnperceptronsnuse only a single layer of neuron deep learning us multiple layersnconvolutional neural network strengthen the connection between neuron that are close to each otherthis is especially important in image processing where a local set of neuron must identify an edge before the network can identify an objectnnn deep learning nndeep learningnuses several layer of neuron between the network input and output the multiple layer can progressively extract higherlevel feature from the raw input for example in image processing lower layer may identify edge while higher layer may identify the concept relevant to a human such a digit letter or facesndeep learning ha profoundly improved the performance of program in many important subfields of artificial intelligence including computer vision speech recognition natural language processing image classification and others the reason that deep learning performs so well in so many application is not known a of nthe sudden success of deep learning in did not occur because of some new discovery or theoretical breakthrough deep neural network and backpropagation had been described by many people a far back a the snbut because of two factor the incredible increase in computer power including the hundredfold increase in speed by switching to gpus and the availability of vast amount of training data especially the giant curated datasets used for benchmark testing such a imagenetnnn gpt ngenerative pretrained transformer gpt are large language model that are based on the semantic relationship between word in sentence natural language processing textbased gpt model are pretrained on a large corpus of text which can be from the internet the pretraining consists in predicting the next token a token being usually a word subword or punctuation throughout this pretraining gpt model accumulate knowledge about the world and can then generate humanlike text by repeatedly predicting the next token typically a subsequent training phase make the model more truthful useful and harmless usually with a technique called reinforcement learning from human feedback rlhf current gpt model are still prone to generating falsehood called hallucination although this can be reduced with rlhf and quality data they are used in chatbots which allow you to ask a question or request a task in simple textncurrent model and service include gemini formerly bard chatgpt grok claude copilot and llama multimodal gpt model can process different type of data modality such a image video sound and textnnn specialized hardware and software nnin the late s graphic processing unit gpus that were increasingly designed with aispecific enhancement and used with specialized tensorflow software had replaced previously used central processing unit cpu a the dominant mean for largescale commercial and academic machine learning model training historically specialized language such a lisp prolog python and others had been usednnn application nai and machine learning technology is used in most of the essential application of the s including search engine such a google search targeting online advertisement recommendation system offered by netflix youtube or amazon driving internet traffic targeted advertising adsense facebook virtual assistant such a siri or alexa autonomous vehicle including drone ada and selfdriving car automatic language translation microsoft translator google translate facial recognition apple face id or microsofts deepface and google facenet and image labeling used by facebook apple iphoto and tiktoknnn health and medicine nnthe application of ai in medicine and medical research ha the potential to increase patient care and quality of life through the lens of the hippocratic oath medical professional are ethically compelled to use ai if application can more accurately diagnose and treat patientsnfor medical research ai is an important tool for processing and integrating big data this is particularly important for organoid and tissue engineering development which use microscopy imaging a a key technique in fabrication it ha been suggested that ai can overcome discrepancy in funding allocated to different field of research new ai tool can deepen the understanding of biomedically relevant pathway for example alphafold demonstrated the ability to approximate in hour rather than month the d structure of a protein in it wa reported that aiguided drug discovery helped find a class of antibiotic capable of killing two different type of drugresistant bacteria in researcher used machine learning to accelerate the search for parkinson disease drug treatment their aim wa to identify compound that block the clumping or aggregation of alphasynuclein the protein that characterises parkinson disease they were able to speed up the initial screening process tenfold and reduce the cost by a thousandfoldnnn game nngame playing program have been used since the s to demonstrate and test ai most advanced technique deep blue became the first computer chessplaying system to beat a reigning world chess champion garry kasparov on may in in a jeopardy quiz show exhibition match ibms question answering system watson defeated the two greatest jeopardy champion brad rutter and ken jennings by a significant margin in march alphago won out of game of go in a match with go champion lee sedol becoming the first computer goplaying system to beat a professional go player without handicap then in it defeated ke jie who wa the best go player in the world other program handle imperfectinformation game such a the pokerplaying program pluribus deepmind developed increasingly generalistic reinforcement learning model such a with muzero which could be trained to play chess go or atari game in deepminds alphastar achieved grandmaster level in starcraft ii a particularly challenging realtime strategy game that involves incomplete knowledge of what happens on the map in an ai agent competed in a playstation gran turismo competition winning against four of the world best gran turismo driver using deep reinforcement learningnnn military nnvarious country are deploying ai military application the main application enhance command and control communication sensor integration and interoperability research is targeting intelligence collection and analysis logistics cyber operation information operation and semiautonomous and autonomous vehicle ai technology enable coordination of sensor and effector threat detection and identification marking of enemy position target acquisition coordination and deconfliction of distributed joint fire between networked combat vehicle involving manned and unmanned team ai wa incorporated into military operation in iraq and syrianin november u vice president kamala harris disclosed a declaration signed by nation to set guardrail for the military use of ai the commitment include using legal review to ensure the compliance of military ai with international law and being cautious and transparent in the development of this technologynnn generative ai nnin the early s generative ai gained widespread prominence in march of u adult had heard about chatgpt and had tried it the increasing realism and easeofuse of aibased texttoimage generator such a midjourney dalle and stable diffusion sparked a trend of viral aigenerated photo widespread attention wa gained by a fake photo of pope francis wearing a white puffer coat the fictional arrest of donald trump and a hoax of an attack on the pentagon a well a the usage in professional creative artsnnn industryspecific task nthere are also thousand of successful ai application used to solve specific problem for specific industry or institution in a survey one in five company reported having incorporated ai in some offering or process a few example are energy storage medical diagnosis military logistics application that predict the result of judicial decision foreign policy or supply chain managementnin agriculture ai ha helped farmer identify area that need irrigation fertilization pesticide treatment or increasing yield agronomist use ai to conduct research and development ai ha been used to predict the ripening time for crop such a tomato monitor soil moisture operate agricultural robot conduct predictive analytics classify livestock pig call emotion automate greenhouse detect disease and pest and save waternartificial intelligence is used in astronomy to analyze increasing amount of available data and application mainly for classification regression clustering forecasting generation discovery and the development of new scientific insight for example for discovering exoplanets forecasting solar activity and distinguishing between signal and instrumental effect in gravitational wave astronomy it could also be used for activity in space such a space exploration including analysis of data from space mission realtime science decision of spacecraft space debris avoidance and more autonomous operationnnn ethic nnai ha potential benefit and potential risk ai may be able to advance science and find solution for serious problem demis hassabis of deep mind hope to solve intelligence and then use that to solve everything else however a the use of ai ha become widespread several unintended consequence and risk have been identified inproduction system can sometimes not factor ethic and bias into their ai training process especially when the ai algorithm are inherently unexplainable in deep learningnnn risk and harm nnn privacy and copyright nnmachinelearning algorithm require large amount of data the technique used to acquire this data have raised concern about privacy surveillance and copyrightntechnology company collect a wide range of data from their user including online activity geolocation data video and audionfor example in order to build speech recognition algorithm amazon ha recorded million of private conversation and allowed temporary worker to listen to and transcribe some of them opinion about this widespread surveillance range from those who see it a a necessary evil to those for whom it is clearly unethical and a violation of the right to privacynai developer argue that this is the only way to deliver valuable application and have developed several technique that attempt to preserve privacy while still obtaining the data such a data aggregation deidentification and differential privacy since some privacy expert such a cynthia dwork have begun to view privacy in term of fairness brian christian wrote that expert have pivoted from the question of what they know to the question of what theyre doing with itngenerative ai is often trained on unlicensed copyrighted work including in domain such a image or computer code the output is then used under the rationale of fair use expert disagree about how well and under what circumstance this rationale will hold up in court of law relevant factor may include the purpose and character of the use of the copyrighted work and the effect upon the potential market for the copyrighted work website owner who do not wish to have their content scraped can indicate it in a robotstxt file in leading author including john grisham and jonathan franzen sued ai company for using their work to train generative ai another discussed approach is to envision a separate sui generis system of protection for creation generated by ai to ensure fair attribution and compensation for human authorsnnn misinformation nnyoutube facebook and others use recommender system to guide user to more content these ai program were given the goal of maximizing user engagement that is the only goal wa to keep people watching the ai learned that user tended to choose misinformation conspiracy theory and extreme partisan content and to keep them watching the ai recommended more of it user also tended to watch more content on the same subject so the ai led people into filter bubble where they received multiple version of the same misinformation this convinced many user that the misinformation wa true and ultimately undermined trust in institution the medium and the government the ai program had correctly learned to maximize it goal but the result wa harmful to society after the u election in major technology company took step to mitigate the problemnin generative ai began to create image audio video and text that are indistinguishable from real photograph recording film or human writing it is possible for bad actor to use this technology to create massive amount of misinformation or propaganda ai pioneer geoffrey hinton expressed concern about ai enabling authoritarian leader to manipulate their electorate on a large scale among other risksnnn algorithmic bias and fairness nnmachine learning application will be biased if they learn from biased data the developer may not be aware that the bias existsnbias can be introduced by the way training data is selected and by the way a model is deployed if a biased algorithm is used to make decision that can seriously harm people a it can in medicine finance recruitment housing or policing then the algorithm may cause discriminationnfairness in machine learning is the study of how to prevent the harm caused by algorithmic bias it ha become serious area of academic study within ai researcher have discovered it is not always possible to define fairness in a way that satisfies all stakeholdersnon june google photo new image labeling feature mistakenly identified jacky alcine and a friend a gorilla because they were black the system wa trained on a dataset that contained very few image of black people a problem called sample size disparity google fixed this problem by preventing the system from labelling anything a a gorilla eight year later in google photo still could not identify a gorilla and neither could similar product from apple facebook microsoft and amazonncompas is a commercial program widely used by u court to ass the likelihood of a defendant becoming a recidivistnin julia angwin at propublica discovered that compas exhibited racial bias despite the fact that the program wa not told the race of the defendant although the error rate for both white and black wa calibrated equal at exactly the error for each race were differentthe system consistently overestimated the chance that a black person would reoffend and would underestimate the chance that a white person would not reoffend in several researcher showed that it wa mathematically impossible for compas to accommodate all possible measure of fairness when the base rate of reoffense were different for white and black in the datana program can make biased decision even if the data doe not explicitly mention a problematic feature such a race or gender the feature will correlate with other feature like address shopping history or first name and the program will make the same decision based on these feature a it would on race or gendernmoritz hardt said the most robust fact in this research area is that fairness through blindness doesnt workncriticism of compas highlighted that machine learning model are designed to make prediction that are only valid if we assume that the future will resemble the past if they are trained on data that includes the result of racist decision in the past machine learning model must predict that racist decision will be made in the future if an application then us these prediction a recommendation some of these recommendation will likely be racist thus machine learning is not well suited to help make decision in area where there is hope that the future will be better than the past it is necessarily descriptive and not proscriptivenbias and unfairness may go undetected because the developer are overwhelmingly white and male among ai engineer about are black and are womennat it conference on fairness accountability and transparency acm facct the association for computing machinery in seoul south korea presented and published finding that recommend that until ai and robotics system are demonstrated to be free of bias mistake they are unsafe and the use of selflearning neural network trained on vast unregulated source of flawed internet data should be curtailednnn lack of transparency nnmany ai system are so complex that their designer cannot explain how they reach their decision particularly with deep neural network in which there are a large amount of nonlinear relationship between input and output but some popular explainability technique existnit is impossible to be certain that a program is operating correctly if no one know how exactly it work there have been many case where a machine learning program passed rigorous test but nevertheless learned something different than what the programmer intended for example a system that could identify skin disease better than medical professional wa found to actually have a strong tendency to classify image with a ruler a cancerous because picture of malignancy typically include a ruler to show the scale another machine learning system designed to help effectively allocate medical resource wa found to classify patient with asthma a being at low risk of dying from pneumonia having asthma is actually a severe risk factor but since the patient having asthma would usually get much more medical care they were relatively unlikely to die according to the training data the correlation between asthma and low risk of dying from pneumonia wa real but misleadingnpeople who have been harmed by an algorithm decision have a right to an explanation doctor for example are expected to clearly and completely explain to their colleague the reasoning behind any decision they make early draft of the european union general data protection regulation in included an explicit statement that this right exists industry expert noted that this is an unsolved problem with no solution in sight regulator argued that nevertheless the harm is real if the problem ha no solution the tool should not be usedndarpa established the xai explainable artificial intelligence program in to try and solve these problem nthere are several possible solution to the transparency problem shap tried to solve the transparency problem by visualising the contribution of each feature to the output lime can locally approximate a model with a simpler interpretable model multitask learning provides a large number of output in addition to the target classification these other output can help developer deduce what the network ha learned deconvolution deepdream and other generative method can allow developer to see what different layer of a deep network have learned and produce output that can suggest what the network is learningnnn bad actor and weaponized ai nnartificial intelligence provides a number of tool that are useful to bad actor such a authoritarian government terrorist criminal or rogue statesna lethal autonomous weapon is a machine that locates selects and engages human target without human supervision widely available ai tool can be used by bad actor to develop inexpensive autonomous weapon and if produced at scale they are potentially weapon of mass destruction even when used in conventional warfare it is unlikely that they will be unable to reliably choose target and could potentially kill an innocent person in nation including china supported a ban on autonomous weapon under the united nation convention on certain conventional weapon however the united state and others disagreed by over fifty country were reported to be researching battlefield robotsnai tool make it easier for authoritarian government to efficiently control their citizen in several way face and voice recognition allow widespread surveillance machine learning operating this data can classify potential enemy of the state and prevent them from hiding recommendation system can precisely target propaganda and misinformation for maximum effect deepfakes and generative ai aid in producing misinformation advanced ai can make authoritarian centralized decision making more competitive than liberal and decentralized system such a market it lower the cost and difficulty of digital warfare and advanced spyware all these technology have been available since or earlierai facial recognition system are already being used for mass surveillance in chinanthere many other way that ai is expected to help bad actor some of which can not be foreseen for example machinelearning ai is able to design ten of thousand of toxic molecule in a matter of hoursnnn reliance on industry giant ntraining ai system requires an enormous amount of computing power usually only big tech company have the financial resource to make such investment smaller startup such a cohere and openai end up buying access to data center from google and microsoft respectivelynnn technological unemployment nneconomists have frequently highlighted the risk of redundancy from ai and speculated about unemployment if there is no adequate social policy for full employmentnin the past technology ha tended to increase rather than reduce total employment but economist acknowledge that were in uncharted territory with ai a survey of economist showed disagreement about whether the increasing use of robot and ai will cause a substantial increase in longterm unemployment but they generally agree that it could be a net benefit if productivity gain are redistributed risk estimate vary for example in the s michael osborne and carl benedikt frey estimated of u job are at high risk of potential automation while an oecd report classified only of u job a high risk the methodology of speculating about future employment level ha been criticised a lacking evidential foundation and for implying that technology rather than social policy creates unemployment a opposed to redundancy in april it wa reported that of the job for chinese video game illustrator had been eliminated by generative artificial intelligencenunlike previous wave of automation many middleclass job may be eliminated by artificial intelligence the economist stated in that the worry that ai could do to whitecollar job what steam power did to bluecollar one during the industrial revolution is worth taking seriously job at extreme risk range from paralegal to fast food cook while job demand is likely to increase for carerelated profession ranging from personal healthcare to the clergynfrom the early day of the development of artificial intelligence there have been argument for example those put forward by joseph weizenbaum about whether task that can be done by computer actually should be done by them given the difference between computer and human and between quantitative calculation and qualitative valuebased judgementnnn existential risk nnit ha been argued ai will become so powerful that humanity may irreversibly lose control of it this could a physicist stephen hawking stated spell the end of the human race this scenario ha been common in science fiction when a computer or robot suddenly develops a humanlike selfawareness or sentience or consciousness and becomes a malevolent character these scifi scenario are misleading in several waysnfirst ai doe not require humanlike sentience to be an existential risk modern ai program are given specific goal and use learning and intelligence to achieve them philosopher nick bostrom argued that if one give almost any goal to a sufficiently powerful ai it may choose to destroy humanity to achieve it he used the example of a paperclip factory manager stuart russell give the example of household robot that try to find a way to kill it owner to prevent it from being unplugged reasoning that you cant fetch the coffee if youre dead in order to be safe for humanity a superintelligence would have to be genuinely aligned with humanity morality and value so that it is fundamentally on our sidensecond yuval noah harari argues that ai doe not require a robot body or physical control to pose an existential risk the essential part of civilization are not physical thing like ideology law government money and the economy are made of language they exist because there are story that billion of people believe the current prevalence of misinformation suggests that an ai could use language to convince people to believe anything even to take action that are destructiventhe opinion amongst expert and industry insider are mixed with sizable fraction both concerned and unconcerned by risk from eventual superintelligent ai personality such a stephen hawking bill gate and elon musk have expressed concern about existential risk from ainai pioneer including feifei li geoffrey hinton yoshua bengio cynthia breazeal rana el kaliouby demis hassabis joy buolamwini and sam altman have expressed concern about the risk of ai in many leading ai expert issued the joint statement that mitigating the risk of extinction from ai should be a global priority alongside other societalscale risk such a pandemic and nuclear warnother researcher however spoke in favor of a le dystopian view ai pioneer juergen schmidhuber did not sign the joint statement emphasising that in of all case ai research is about making human life longer and healthier and easier while the tool that are now being used to improve life can also be used by bad actor they can also be used against the bad actor andrew ng also argued that it a mistake to fall for the doomsday hype on aiand that regulator who do will only benefit vested interest yann lecun scoff at his peer dystopian scenario of supercharged misinformation and even eventually human extinction in the early s expert argued that the risk are too distant in the future to warrant research or that human will be valuable from the perspective of a superintelligent machine however after the study of current and future risk and possible solution became a serious area of researchnnn ethical machine and alignment nnfriendly ai are machine that have been designed from the beginning to minimize risk and to make choice that benefit human eliezer yudkowsky who coined the term argues that developing friendly ai should be a higher research priority it may require a large investment and it must be completed before ai becomes an existential risknmachines with intelligence have the potential to use their intelligence to make ethical decision the field of machine ethic provides machine with ethical principle and procedure for resolving ethical dilemmasnthe field of machine ethic is also called computational moralitynand wa founded at an aaai symposium in nother approach include wendell wallachs artificial moral agent and stuart j russell three principle for developing provably beneficial machinesnnn open source nactive organization in the ai opensource community include hugging face google eleutherai and meta various ai model such a llama mistral or stable diffusion have been made openweight meaning that their architecture and trained parameter the weight are publicly available openweight model can be freely finetuned which allows company to specialize them with their own data and for their own usecase openweight model are useful for research and innovation but can also be misused since they can be finetuned any builtin security measure such a objecting to harmful request can be trained away until it becomes ineffective some researcher warn that future ai model may develop dangerous capability such a the potential to drastically facilitate bioterrorism and that once released on the internet they cant be deleted everywhere if needed they recommend prerelease audit and costbenefit analysesnnn framework nartificial intelligence project can have their ethical permissibility tested while designing developing and implementing an ai system an ai framework such a the care and act framework containing the sum valuesdeveloped by the alan turing institute test project in four main areasnnrespect the dignity of individual peoplenconnect with other people sincerely openly and inclusivelyncare for the wellbeing of everyonenprotect social value justice and the public interestnother development in ethical framework include those decided upon during the asilomar conference the montreal declaration for responsible ai and the ieees ethic of autonomous system initiative among others however these principle do not go without their criticism especially regard to the people chosen contributes to these frameworksnpromotion of the wellbeing of the people and community that these technology affect requires consideration of the social and ethical implication at all stage of ai system design development and implementation and collaboration between job role such a data scientist product manager data engineer domain expert and delivery managersnthe ai safety institute in the uk ha released a testing toolset called inspect for ai safety evaluation available under a mit opensource licence which is freely available on github and can be improved with thirdparty package it can be used to evaluate ai model in a range of area including core knowledge ability to reason and autonomous capabilitiesnnn regulation nnthe regulation of artificial intelligence is the development of public sector policy and law for promoting and regulating artificial intelligence ai it is therefore related to the broader regulation of algorithm the regulatory and policy landscape for ai is an emerging issue in jurisdiction globally according to ai index at stanford the annual number of airelated law passed in the survey country jumped from one passed in to passed in alone between and more than country adopted dedicated strategy for ai most eu member state had released national ai strategy a had canada china india japan mauritius the russian federation saudi arabia united arab emirate u and vietnam others were in the process of elaborating their own ai strategy including bangladesh malaysia and tunisia the global partnership on artificial intelligence wa launched in june stating a need for ai to be developed in accordance with human right and democratic value to ensure public confidence and trust in the technology henry kissinger eric schmidt and daniel huttenlocher published a joint statement in november calling for a government commission to regulate ai in openai leader published recommendation for the governance of superintelligence which they believe may happen in le than year in the united nation also launched an advisory body to provide recommendation on ai governance the body comprises technology company executive government official and academicsnin a ipsos survey attitude towards ai varied greatly by country of chinese citizen but only of american agreed that product and service using ai have more benefit than drawback a reutersipsos poll found that of american agree and disagree that ai pose risk to humanity in a fox news poll of american thought it very important and an additional thought it somewhat important for the federal government to regulate ai versus responding not very important and responding not at all importantnin november the first global ai safety summit wa held in bletchley park in the uk to discus the near and far term risk of ai and the possibility of mandatory and voluntary regulatory framework country including the united state china and the european union issued a declaration at the start of the summit calling for international cooperation to manage the challenge and risk of artificial intelligencennn history nnthe study of mechanical or formal reasoning began with philosopher and mathematician in antiquity the study of logic led directly to alan turing theory of computation which suggested that a machine by shuffling symbol a simple a and could simulate any conceivable form of mathematical reasoning this along with concurrent discovery in cybernetics information theory and neurobiology led researcher to consider the possibility of building an electronic brain nthey developed several area of research that would become part of ainsuch a mccullouch and pitt design for artificial neuron in and turing influential paper computing machinery and intelligence which introduced the turing test and showed that machine intelligence wa plausiblenthe field of ai research wa founded at a workshop at dartmouth college in the attendee became the leader of ai research in the s they and their student produced program that the press described a astonishing computer were learning checker strategy solving word problem in algebra proving logical theorem and speaking english artificial intelligence laboratory were set up at a number of british and u university in the latter s and early snresearchers in the s and the s were convinced that their method would eventually succeed in creating a machine with general intelligence and considered this the goal of their field herbert simon predicted machine will be capable within twenty year of doing any work a man can do marvin minsky agreed writing within a generation the problem of creating artificial intelligence will substantially be solved they had however underestimated the difficulty of the problem in both the u and british government cut off exploratory research in response to the criticism of sir james lighthill and ongoing pressure from the u congress to fund more productive project minskys and paperts book perceptrons wa understood a proving that artificial neural network would never be useful for solving realworld task thus discrediting the approach altogether the ai winter a period when obtaining funding for ai project wa difficult followednin the early s ai research wa revived by the commercial success of expert system a form of ai program that simulated the knowledge and analytical skill of human expert by the market for ai had reached over a billion dollar at the same time japan fifth generation computer project inspired the u and british government to restore funding for academic research however beginning with the collapse of the lisp machine market in ai once again fell into disrepute and a second longerlasting winter begannup to this point most of ai funding had gone to project that used highlevel symbol to represent mental object like plan goal belief and known fact in the s some researcher began to doubt that this approach would be able to imitate all the process of human cognition especially perception robotics learning and pattern recognition and began to look into subsymbolic approach rodney brook rejected representation in general and focussed directly on engineering machine that move and survive judea pearl lofti zadeh and others developed method that handled incomplete and uncertain information by making reasonable guess rather than precise logic but the most important development wa the revival of connectionism including neural network research by geoffrey hinton and others in yann lecun successfully showed that convolutional neural network can recognize handwritten digit the first of many successful application of neural networksnai gradually restored it reputation in the late s and early st century by exploiting formal mathematical method and by finding specific solution to specific problem this narrow and formal focus allowed researcher to produce verifiable result and collaborate with other field such a statistic economics and mathematics by solution developed by ai researcher were being widely used although in the s they were rarely described a artificial intelligencenhowever several academic researcher became concerned that ai wa no longer pursuing it original goal of creating versatile fully intelligent machine beginning around they founded the subfield of artificial general intelligence or agi which had several wellfunded institution by the sndeep learning began to dominate industry benchmark in and wa adopted throughout the fieldnfor many specific task other method were abandonedndeep learning success wa based on both hardware improvement faster computer graphic processing unit cloud computing and access to large amount of data including curated datasets such a imagenet deep learning success led to an enormous increase in interest and funding in ai the amount of machine learning research measured by total publication increased by in the year nin issue of fairness and the misuse of technology were catapulted into center stage at machine learning conference publication vastly increased funding became available and many researcher refocussed their career on these issue the alignment problem became a serious field of academic studynin the late teen and early s agi company began to deliver program that created enormous interest in alphago developed by deepmind beat the world champion go player the program wa taught only the rule of the game and developed strategy by itself gpt is a large language model that wa released in by openai and is capable of generating highquality humanlike text these program and others inspired an aggressive ai boom where large company began investing billion in ai research according to ai impact about billion annually wa invested in ai around in the u alone and about of the new u computer science phd graduate have specialized in ainabout airelated u job opening existed in nnn philosophy nnn defining artificial intelligence nnalan turing wrote in i propose to consider the question can machine think he advised changing the question from whether a machine think to whether or not it is possible for machinery to show intelligent behaviour he devised the turing test which measure the ability of a machine to simulate human conversation since we can only observe the behavior of the machine it doe not matter if it is actually thinking or literally ha a mind turing note that we can not determine these thing about other people but it is usual to have a polite convention that everyone thinksnrussell and norvig agree with turing that intelligence must be defined in term of external behavior not internal structure however they are critical that the test requires the machine to imitate human aeronautical engineering text they wrote do not define the goal of their field a making machine that fly so exactly like pigeon that they can fool other pigeon ai founder john mccarthy agreed writing that artificial intelligence is not by definition simulation of human intelligencenmccarthy defines intelligence a the computational part of the ability to achieve goal in the world another ai founder marvin minsky similarly describes it a the ability to solve hard problem the leading ai textbook defines it a the study of agent that perceive their environment and take action that maximize their chance of achieving defined goal these definition view intelligence in term of welldefined problem with welldefined solution where both the difficulty of the problem and the performance of the program are direct measure of the intelligence of the machineand no other philosophical discussion is required or may not even be possiblenanother definition ha been adopted by google a major practitioner in the field of ai this definition stipulates the ability of system to synthesize information a the manifestation of intelligence similar to the way it is defined in biological intelligencennn evaluating approach to ai nno established unifying theory or paradigm ha guided ai research for most of it history the unprecedented success of statistical machine learning in the s eclipsed all other approach so much so that some source especially in the business world use the term artificial intelligence to mean machine learning with neural network this approach is mostly subsymbolic soft and narrow critic argue that these question may have to be revisited by future generation of ai researchersnnn symbolic ai and it limit nsymbolic ai or gofai simulated the highlevel conscious reasoning that people use when they solve puzzle express legal reasoning and do mathematics they were highly successful at intelligent task such a algebra or iq test in the s newell and simon proposed the physical symbol system hypothesis a physical symbol system ha the necessary and sufficient mean of general intelligent actionnhowever the symbolic approach failed on many task that human solve easily such a learning recognizing an object or commonsense reasoning moravecs paradox is the discovery that highlevel intelligent task were easy for ai but low level instinctive task were extremely difficult philosopher hubert dreyfus had argued since the s that human expertise depends on unconscious instinct rather than conscious symbol manipulation and on having a feel for the situation rather than explicit symbolic knowledge although his argument had been ridiculed and ignored when they were first presented eventually ai research came to agree with himnthe issue is not resolved subsymbolic reasoning can make many of the same inscrutable mistake that human intuition doe such a algorithmic bias critic such a noam chomsky argue continuing research into symbolic ai will still be necessary to attain general intelligence in part because subsymbolic ai is a move away from explainable ai it can be difficult or impossible to understand why a modern statistical ai program made a particular decision the emerging field of neurosymbolic artificial intelligence attempt to bridge the two approachesnnn neat v scruffy nnneats hope that intelligent behavior is described using simple elegant principle such a logic optimization or neural network scruffies expect that it necessarily requires solving a large number of unrelated problem neats defend their program with theoretical rigor scruffies rely mainly on incremental testing to see if they work this issue wa actively discussed in the s and s but eventually wa seen a irrelevant modern ai ha element of bothnnn soft v hard computing nnfinding a provably correct or optimal solution is intractable for many important problem soft computing is a set of technique including genetic algorithm fuzzy logic and neural network that are tolerant of imprecision uncertainty partial truth and approximation soft computing wa introduced in the late s and most successful ai program in the st century are example of soft computing with neural networksnnn narrow v general ai nnai researcher are divided a to whether to pursue the goal of artificial general intelligence and superintelligence directly or to solve a many specific problem a possible narrow ai in hope these solution will lead indirectly to the field longterm goal general intelligence is difficult to define and difficult to measure and modern ai ha had more verifiable success by focusing on specific problem with specific solution the experimental subfield of artificial general intelligence study this area exclusivelynnn machine consciousness sentience and mind nnthe philosophy of mind doe not know whether a machine can have a mind consciousness and mental state in the same sense that human being do this issue considers the internal experience of the machine rather than it external behavior mainstream ai research considers this issue irrelevant because it doe not affect the goal of the field to build machine that can solve problem using intelligence russell and norvig add that the additional project of making a machine conscious in exactly the way human are is not one that we are equipped to take on however the question ha become central to the philosophy of mind it is also typically the central question at issue in artificial intelligence in fictionnnn consciousness nndavid chalmers identified two problem in understanding the mind which he named the hard and easy problem of consciousness the easy problem is understanding how the brain process signal make plan and control behavior the hard problem is explaining how this feel or why it should feel like anything at all assuming we are right in thinking that it truly doe feel like something dennetts consciousness illusionism say this is an illusion while human information processing is easy to explain human subjective experience is difficult to explain for example it is easy to imagine a colorblind person who ha learned to identify which object in their field of view are red but it is not clear what would be required for the person to know what red look likennn computationalism and functionalism nncomputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mindbody problem this philosophical position wa inspired by the work of ai researcher and cognitive scientist in the s and wa originally proposed by philosopher jerry fodor and hilary putnamnphilosopher john searle characterized this position a strong ai the appropriately programmed computer with the right input and output would thereby have a mind in exactly the same sense human being have mind searle counter this assertion with his chinese room argument which attempt to show that even if a machine perfectly simulates human behavior there is still no reason to suppose it also ha a mindnnn ai welfare and right nit is difficult or impossible to reliably evaluate whether an advanced ai is sentient ha the ability to feel and if so to what degree but if there is a significant chance that a given machine can feel and suffer then it may be entitled to certain right or welfare protection measure similarly to animal sapience a set of capacity related to high intelligence such a discernment or selfawareness may provide another moral basis for ai right robot right are also sometimes proposed a a practical way to integrate autonomous agent into societynin the european union considered granting electronic personhood to some of the most capable ai system similarly to the legal status of company it would have conferred right but also responsibility critic argued in that granting right to ai system would downplay the importance of human right and that legislation should focus on user need rather than speculative futuristic scenario they also noted that robot lacked the autonomy to take part to society on their ownnprogress in ai increased interest in the topic proponent of ai welfare and right often argue that ai sentience if it emerges would be particularly easy to deny they warn that this may be a moral blind spot analogous to slavery or factory farming which could lead to largescale suffering if sentient ai is created and carelessly exploitednnn future nnn superintelligence and the singularity na superintelligence is a hypothetical agent that would posse intelligence far surpassing that of the brightest and most gifted human mindnif research into artificial general intelligence produced sufficiently intelligent software it might be able to reprogram and improve itself the improved software would be even better at improving itself leading to what i j good called an intelligence explosion and vernor vinge called a singularitynhowever technology cannot improve exponentially indefinitely and typically follow an sshaped curve slowing when they reach the physical limit of what the technology can donnn transhumanism nrobot designer han moravec cyberneticist kevin warwick and inventor ray kurzweil have predicted that human and machine will merge in the future into cyborg that are more capable and powerful than either this idea called transhumanism ha root in aldous huxley and robert ettingernedward fredkin argues that artificial intelligence is the next stage in evolution an idea first proposed by samuel butler darwin among the machine a far back a and expanded upon by george dyson in his book of the same name in nnn in fiction nnthoughtcapable artificial being have appeared a storytelling device since antiquity and have been a persistent theme in science fictionna common trope in these work began with mary shelley frankenstein where a human creation becomes a threat to it master this includes such work a arthur c clarkes and stanley kubrick a space odyssey both with hal the murderous computer in charge of the discovery one spaceship a well a the terminator and the matrix in contrast the rare loyal robot such a gort from the day the earth stood still and bishop from alien are le prominent in popular culturenisaac asimov introduced the three law of robotics in many book and story most notably the multivac series about a superintelligent computer of the same name asimov law are often brought up during lay discussion of machine ethic while almost all artificial intelligence researcher are familiar with asimov law through popular culture they generally consider the law useless for many reason one of which is their ambiguitynseveral work use ai to force u to confront the fundamental question of what make u human showing u artificial being that have the ability to feel and thus to suffer this appears in karel apeks rur the film ai artificial intelligence and ex machina a well a the novel do android dream of electric sheep by philip k dick dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligencennn see also nartificial intelligence detection software software to detect aigenerated contentpages displaying short description of redirect targetsnbehavior selection algorithm algorithm that selects action for intelligent agentsnbusiness process automation technologyenabled automation of complex business processesncasebased reasoning process of solving new problem based on the solution of similar past problemsncomputational intelligence ability of a computer to learn a specific task from data or experimental observationndigital immortality hypothetical concept of storing a personality in digital formnemergent algorithm algorithm exhibiting emergent behaviornfemale gendering of ai technology gender bias in digital technologypages displaying short description of redirect targetsnglossary of artificial intelligence list of definition of term and concept commonly used in the study of artificial intelligencenintelligence amplification use of information technology to augment human intelligencenmind uploading hypothetical process of digitally emulating a brainnrobotic process automation form of business process automation technologynweak artificial intelligence form of artificial intelligencenwetware computer computer composed of organic materialnnn explanatory note nnn reference nnn ai textbook nthe two most widely used textbook in see the open syllabusnnrussell stuart j norvig peter artificial intelligence a modern approach th ed hoboken pearson isbn lccn nrich elaine knight kevin nair shivashankar b artificial intelligence rd ed new delhi tata mcgraw hill india isbn nthese were the four of the most widely used ai textbook in nnn history of ai nnn other source nnn further reading nnn external link nnartificial intelligence internet encyclopedia of philosophynthomason richmond logic and artificial intelligence in zalta edward n ed stanford encyclopedia of philosophynartificial intelligence bbc radio discussion with john agar alison adam igor aleksander in our time december ntheranostics and ai the next advance in cancer precision medicine',\n",
              " 'a neural network is a group of interconnected unit called neuron that send signal to one another neuron can be either biological cell or mathematical model while individual neuron are simple many of them together in a network can perform complex task there are two main type of neural networknnin neuroscience a biological neural network is a physical structure found in brain and complex nervous system a population of nerve cell connected by synapsesnin machine learning an artificial neural network is a mathematical model used to approximate nonlinear function artificial neural network are used to solve artificial intelligence problemsnnn in biology nnin the context of biology a neural network is a population of biological neuron chemically connected to each other by synapsis a given neuron can be connected to hundred of thousand of synapsesneach neuron sends and receives electrochemical signal called action potential to it connected neighbor a neuron can serve an excitatory role amplifying and propagating signal it receives or an inhibitory role suppressing signal insteadnpopulations of interconnected neuron that are smaller than neural network are called neural circuit very large interconnected network are called large scale brain network and many of these together form brain and nervous systemsnsignals generated by neural network in the brain eventually travel through the nervous system and across neuromuscular junction to muscle cell where they cause contraction and thereby motionnnn in machine learning nnin the context of machine learning a neural network is an artificial mathematical model used to approximate nonlinear function while early artificial neural network were physical machine today they are almost always implemented in softwarenneurons in an artificial neural network are usually arranged into layer with information passing from the first layer the input layer through one or more intermediate layer hidden layer to the final layer the output layernthe signal input to each neuron is a number specifically a linear combination of the output of the connected neuron in the previous layer the signal each neuron output is calculated from this number according to it activation function the behavior of the network depends on the strength or weight of the connection between neuron a network is trained by modifying these weight through empirical risk minimization or backpropagation in order to fit some preexisting datasetnneural network are used to solve problem in artificial intelligence and have thereby found application in many discipline including predictive modeling adaptive control facial recognition handwriting recognition general game playing and generative ainnn history nnthe theoretical base for contemporary neural network wa independently proposed by alexander bain in and william james in both posited that human thought emerged from interaction among large number of neuron inside the brain in donald hebb described hebbian learning the idea that neural network can change and learn over time by strengthening a synapse every time a signal travel along itnartificial neural network were originally used to model biological neural network starting in the s under the approach of connectionism however starting with the invention of the perceptron a simple artificial neural network by warren mcculloch and walter pitt in followed by the implementation of one in hardware by frank rosenblatt in nartificial neural network became increasingly used for machine learning application instead and increasingly different from their biological counterpartsnnn see also nemergencenbiological cyberneticsnbiologicallyinspired computingnnn reference',\n",
              " 'deep learning is the subset of machine learning method based on neural network with representation learning the adjective deep refers to the use of multiple layer in the network method used can be either supervised semisupervised or unsupervisedndeeplearning architecture such a deep neural network deep belief network recurrent neural network convolutional neural network and transformer have been applied to field including computer vision speech recognition natural language processing machine translation bioinformatics drug design medical image analysis climate science material inspection and board game program where they have produced result comparable to and in some case surpassing human expert performancenearly form of neural network were inspired by information processing and distributed communication node in biological system in particular the human brain however current neural network do not intend to model the brain function of organism and are generally seen a low quality model for that purposennn overview nmost modern deep learning model are based on multilayered neural network such a convolutional neural network and transformer although they can also include propositional formula or latent variable organized layerwise in deep generative model such a the node in deep belief network and deep boltzmann machinesnfundamentally deep learning refers to a class of machine learning algorithm in which a hierarchy of layer is used to transform input data into a slightly more abstract and composite representation for example in an image recognition model the raw input may be an image represented a a tensor of pixel the first representational layer may attempt to identify basic shape such a line and circle the second layer may compose and encode arrangement of edge the third layer may encode a nose and eye and the fourth layer may recognize that the image contains a facenimportantly a deep learning process can learn which feature to optimally place in which level on it own prior to deep learning machine learning technique often involved handcrafted feature engineering to transform the data into a more suitable representation for a classification algorithm to operate upon in the deep learning approach feature are not handcrafted and the model discovers useful feature representation from the data automatically this doe not eliminate the need for handtuning for example varying number of layer and layer size can provide different degree of abstractionnthe word deep in deep learning refers to the number of layer through which the data is transformed more precisely deep learning system have a substantial credit assignment path cap depth the cap is the chain of transformation from input to output cap describe potentially causal connection between input and output for a feedforward neural network the depth of the cap is that of the network and is the number of hidden layer plus one a the output layer is also parameterized for recurrent neural network in which a signal may propagate through a layer more than once the cap depth is potentially unlimited no universally agreedupon threshold of depth divide shallow learning from deep learning but most researcher agree that deep learning involves cap depth higher than cap of depth ha been shown to be a universal approximator in the sense that it can emulate any function beyond that more layer do not add to the function approximator ability of the network deep model cap are able to extract better feature than shallow model and hence extra layer help in learning the feature effectivelyndeep learning architecture can be constructed with a greedy layerbylayer method deep learning help to disentangle these abstraction and pick out which feature improve performancendeep learning algorithm can be applied to unsupervised learning task this is an important benefit because unlabeled data are more abundant than the labeled data example of deep structure that can be trained in an unsupervised manner are deep belief networksnnn interpretation ndeep neural network are generally interpreted in term of the universal approximation theorem or probabilistic inferencenthe classic universal approximation theorem concern the capacity of feedforward neural network with a single hidden layer of finite size to approximate continuous function in the first proof wa published by george cybenko for sigmoid activation function and wa generalised to feedforward multilayer architecture in by kurt hornik recent work also showed that universal approximation also hold for nonbounded activation function such a kunihiko fukushimas rectified linear unitnthe universal approximation theorem for deep neural network concern the capacity of network with bounded width but the depth is allowed to grow lu et al proved that if the width of a deep neural network with relu activation is strictly larger than the input dimension then the network can approximate any lebesgue integrable function if the width is smaller or equal to the input dimension then a deep neural network is not a universal approximatornthe probabilistic interpretation derives from the field of machine learning it feature inference a well a the optimization concept of training and testing related to fitting and generalization respectively more specifically the probabilistic interpretation considers the activation nonlinearity a a cumulative distribution function the probabilistic interpretation led to the introduction of dropout a regularizer in neural network the probabilistic interpretation wa introduced by researcher including hopfield widrow and narendra and popularized in survey such a the one by bishopnnn history nthere were two type of artificial neural network ann feedforward neural network fnns and recurrent neural network rnns rnns have cycle in their connectivity structure fnns dont in the s wilhelm lenz and ernst ising created and analyzed the ising model which is essentially a nonlearning rnn architecture consisting of neuronlike threshold element in shunichi amari made this architecture adaptive his learning rnn wa popularised by john hopfield in ncharles tappert writes that frank rosenblatt developed and explored all of the basic ingredient of the deep learning system of today referring to rosenblatts book which introduced multilayer perceptron mlp with layer an input layer a hidden layer with randomized weight that did not learn and an output layer it also introduced variant including a version with fourlayer perceptrons where the last two layer have learned weight and thus a proper multilayer perceptronuasection ua in addition term deep learning wa proposed in by rina dechter although the history of it appearance is apparently more complicatednthe first general working learning algorithm for supervised deep feedforward multilayer perceptrons wa published by alexey ivakhnenko and lapa in a paper described a deep network with eight layer trained by the group method of data handlingnthe first deep learning multilayer perceptron trained by stochastic gradient descent wa published in by shunichi amari in computer experiment conducted by amaris student saito a five layer mlp with two modifiable layer learned internal representation to classify nonlinearily separable pattern class in matthew brand reported that wide layer nonlinear perceptrons could be fully endtoend trained to reproduce logic function of nontrivial circuit depth via gradient descent on small batch of random inputoutput sample but concluded that training time on contemporary hardware submegaflop computer made the technique impractical and proposed using fixed random early layer a an input hash for a single modifiable layer instead subsequent development in hardware and hyperparameter tuning have made endtoend stochastic gradient descent the currently dominant training techniquenin seppo linnainmaa published the reverse mode of automatic differentiation of discrete connected network of nested differentiable function this became known a backpropagation it is an efficient application of the chain rule derived by gottfried wilhelm leibniz in to network of differentiable node nthe terminology backpropagating error wa actually introduced in by rosenblatt but he did not know how to implement this although henry j kelley had a continuous precursor of backpropagation already in in the context of control theory in paul werbos applied backpropagation to mlps in the way that ha become standard in david e rumelhart et al published an experimental analysis of the techniquendeep learning architecture for convolutional neural network cnns with convolutional layer and downsampling layer began with the neocognitron introduced by kunihiko fukushima in in he also introduced the relu rectified linear unit activation function the rectifier ha become the most popular activation function for cnns and deep learning in general cnns have become an essential tool for computer visionnthe term deep learning wa introduced to the machine learning community by rina dechter in and to artificial neural network by igor aizenberg and colleague in in the context of boolean threshold neuronsnin wei zhang et al applied the backpropagation algorithm nto a convolutional neural network a simplified neocognitron with convolutional interconnection between the image feature layer and the last fully connected layer for alphabet recognition they also proposed an implementation of the cnn with an optical computing system nin yann lecun et al applied backpropagation to a cnn with the purpose of recognizing handwritten zip code on mail while the algorithm worked training required day subsequently wei zhang et al modified their model by removing the last fully connected layer and applied it for medical image object segmentation in and breast cancer detection in mammogram in lenet a level cnn by yann lecun et al that classifies digit wa applied by several bank to recognize handwritten number on check digitized in x pixel imagesnin the s backpropagation did not work well for deep learning with long credit assignment path to overcome this problem jrgen schmidhuber proposed a hierarchy of rnns pretrained one level at a time by selfsupervised learning it us predictive coding to learn internal representation at multiple selforganizing time scale this can substantially facilitate downstream deep learning the rnn hierarchy can be collapsed into a single rnn by distilling a higher level chunker network into a lower level automatizer network in a chunker solved a deep learning task whose depth exceeded nin jrgen schmidhuber also published an alternative to rnns which is now called a linear transformer or a transformer with linearized selfattention save for a normalization operator it learns internal spotlight of attention a slow feedforward neural network learns by gradient descent to control the fast weight of another neural network through outer product of selfgenerated activation pattern from and to which are now called key and value for selfattention this fast weight attention mapping is applied to a query patternnthe modern transformer wa introduced by ashish vaswani et al in their paper attention is all you need nit combine this with a softmax operator and a projection matrixntransformers have increasingly become the model of choice for natural language processing many modern large language model such a chatgpt gpt and bert use it transformer are also increasingly being used in computer visionnin jrgen schmidhuber also published adversarial neural network that contest with each other in the form of a zerosum game where one network gain is the other network loss the first network is a generative model that model a probability distribution over output pattern the second network learns by gradient descent to predict the reaction of the environment to these pattern this wa called artificial curiosity in this principle wa used in a generative adversarial network gan by ian goodfellow et al here the environmental reaction is or depending on whether the first network output is in a given set this can be used to create realistic deepfakes excellent image quality is achieved by nvidias stylegan based on the progressive gan by tero karras et al here the gan generator is grown from small to large scale in a pyramidal fashionnsepp hochreiters diploma thesis wa called one of the most important document in the history of machine learning by his supervisor schmidhuber it not only tested the neural history compressor but also identified and analyzed the vanishing gradient problem hochreiter proposed recurrent residual connection to solve this problem this led to the deep learning method called long shortterm memory lstm published in lstm recurrent neural network can learn very deep learning task with long credit assignment path that require memory of event that happened thousand of discrete time step before the vanilla lstm with forget gate wa introduced in by felix gers schmidhuber and fred cummins lstm ha become the most cited neural network of the th centurynin rupesh kumar srivastava klaus greff and schmidhuber used lstm principle to create the highway network a feedforward neural network with hundred of layer much deeper than previous network month later kaiming he xiangyu zhang shaoqing ren and jian sun won the imagenet competition with an opengated or gateless highway network variant called residual neural network this ha become the most cited neural network of the st centurynin andr de carvalho together with mike fairhurst and david bisset published experimental result of a multilayer boolean neural network also known a a weightless neural network composed of a layer selforganising feature extraction neural network module soft followed by a multilayer classification neural network module gsn which were independently trained each layer in the feature extraction module extracted feature with growing complexity regarding the previous layernin brendan frey demonstrated that it wa possible to train over two day a network containing six fully connected layer and several hundred hidden unit using the wakesleep algorithm codeveloped with peter dayan and hintonnsince sven behnke extended the feedforward hierarchical convolutional approach in the neural abstraction pyramid by lateral and backward connection in order to flexibly incorporate context into decision and iteratively resolve local ambiguitiesnsimpler model that use taskspecific handcrafted feature such a gabor filter and support vector machine svms were a popular choice in the s and s because of artificial neural network computational cost and a lack of understanding of how the brain wire it biological networksnboth shallow and deep learning eg recurrent net of anns for speech recognition have been explored for many year these method never outperformed nonuniform internalhandcrafting gaussian mixture modelhidden markov model gmmhmm technology based on generative model of speech trained discriminatively key difficulty have been analyzed including gradient diminishing and weak temporal correlation structure in neural predictive model additional difficulty were the lack of training data and limited computing power most speech recognition researcher moved away from neural net to pursue generative modeling an exception wa at sri international in the late s funded by the u government nsa and darpa sri studied deep neural network dnns in speech and speaker recognition the speaker recognition team led by larry heck reported significant success with deep neural network in speech processing in the national institute of standard and technology speaker recognition evaluation the sri deep neural network wa then deployed in the nuance verifier representing the first major industrial application of deep learning the principle of elevating raw feature over handcrafted optimization wa first explored successfully in the architecture of deep autoencoder on the raw spectrogram or linear filterbank feature in the late s showing it superiority over the melcepstral feature that contain stage of fixed transformation from spectrogram the raw feature of speech waveform later produced excellent largerscale resultsnspeech recognition wa taken over by lstm in lstm started to become competitive with traditional speech recognizers on certain task in alex graf santiago fernndez faustino gomez and schmidhuber combined it with connectionist temporal classification ctc in stack of lstm rnns in google speech recognition reportedly experienced a dramatic performance jump of through ctctrained lstm which they made available through google voice searchnthe impact of deep learning in industry began in the early s when cnns already processed an estimated to of all the check written in the u according to yann lecun industrial application of deep learning to largescale speech recognition started around nin publication by geoff hinton ruslan salakhutdinov osindero and teh showed how a manylayered feedforward neural network could be effectively pretrained one layer at a time treating each layer in turn a an unsupervised restricted boltzmann machine then finetuning it using supervised backpropagation the paper referred to learning for deep belief netsnthe nip workshop on deep learning for speech recognition wa motivated by the limitation of deep generative model of speech and the possibility that given more capable hardware and largescale data set that deep neural net might become practical it wa believed that pretraining dnns using generative model of deep belief net dbn would overcome the main difficulty of neural net however it wa discovered that replacing pretraining with large amount of training data for straightforward backpropagation when using dnns with large contextdependent output layer produced error rate dramatically lower than thenstateoftheart gaussian mixture model gmmhidden markov model hmm and also than moreadvanced generative modelbased system the nature of the recognition error produced by the two type of system wa characteristically different offering technical insight into how to integrate deep learning into the existing highly efficient runtime speech decoding system deployed by all major speech recognition system analysis around contrasting the gmm and other generative speech model v dnn model stimulated early industrial investment in deep learning for speech recognition that analysis wa done with comparable performance le than in error rate between discriminative dnns and generative modelsnin researcher extended deep learning from timit to large vocabulary speech recognition by adopting large output layer of the dnn based on contextdependent hmm state constructed by decision treesndeep learning is part of stateoftheart system in various discipline particularly computer vision and automatic speech recognition asr result on commonly used evaluation set such a timit asr and mnist image classification a well a a range of largevocabulary speech recognition task have steadily improved convolutional neural network were superseded for asr by ctc for lstm but are more successful in computer visionnadvances in hardware have driven renewed interest in deep learning in nvidia wa involved in what wa called the big bang of deep learning a deeplearning neural network were trained with nvidia graphic processing unit gpus that year andrew ng determined that gpus could increase the speed of deeplearning system by about time in particular gpus are wellsuited for the matrixvector computation involved in machine learning gpus speed up training algorithm by order of magnitude reducing running time from week to day further specialized hardware and algorithm optimization can be used for efficient processing of deep learning modelsnnn deep learning revolution nnin the late s deep learning started to outperform other method in machine learning competitionsnin a long shortterm memory trained by connectionist temporal classification alex graf santiago fernndez faustino gomez and jrgen schmidhuber wa the first rnn to win pattern recognition contest winning three competition in connected handwriting recognition google later used ctctrained lstm for speech recognition on the smartphonensignificant impact in image or object recognition were felt from to although cnns trained by backpropagation had been around for decade and gpu implementation of nns for year including cnns faster implementation of cnns on gpus were needed to progress on computer vision in the dannet by dan ciresan ueli meier jonathan masci luca maria gambardella and jrgen schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest outperforming traditional method by a factor of also in dannet won the icdar chinese handwriting contest and in may it won the isbi image segmentation contest until cnns did not play a major role at computer vision conference but in june a paper by ciresan et al at the leading conference cvpr showed how maxpooling cnns on gpu can dramatically improve many vision benchmark record in september dannet also won the icpr contest on analysis of large medical image for cancer detection and in the following year also the miccai grand challenge on the same topic in october the similar alexnet by alex krizhevsky ilya sutskever and geoffrey hinton won the largescale imagenet competition by a significant margin over shallow machine learning method nthe vgg network by karen simonyan and andrew zisserman further reduced the error rate andnwon the imagenet competition following a similar trend in largescale speech recognitionnimage classification wa then extended to the more challenging task of generating description caption for image often a a combination of cnns and lstmsnin a team led by george e dahl won the merck molecular activity challenge using multitask deep neural network to predict the biomolecular target of one drug in sepp hochreiters group used deep learning to detect offtarget and toxic effect of environmental chemical in nutrient household product and drug and won the tox data challenge of nih fda and ncatsnin roger parloff mentioned a deep learning revolution that ha transformed the ai industrynin march yoshua bengio geoffrey hinton and yann lecun were awarded the turing award for conceptual and engineering breakthrough that have made deep neural network a critical component of computingnnn neural network nnartificial neural network anns or connectionist system are computing system inspired by the biological neural network that constitute animal brain such system learn progressively improve their ability to do task by considering example generally without taskspecific programming for example in image recognition they might learn to identify image that contain cat by analyzing example image that have been manually labeled a cat or no cat and using the analytic result to identify cat in other image they have found most use in application difficult to express with a traditional computer algorithm using rulebased programmingnan ann is based on a collection of connected unit called artificial neuron analogous to biological neuron in a biological brain each connection synapse between neuron can transmit a signal to another neuron the receiving postsynaptic neuron can process the signal and then signal downstream neuron connected to it neuron may have state generally represented by real number typically between and neuron and synapsis may also have a weight that varies a learning proceeds which can increase or decrease the strength of the signal that it sends downstreamntypically neuron are organized in layer different layer may perform different kind of transformation on their input signal travel from the first input to the last output layer possibly after traversing the layer multiple timesnthe original goal of the neural network approach wa to solve problem in the same way that a human brain would over time attention focused on matching specific mental ability leading to deviation from biology such a backpropagation or passing information in the reverse direction and adjusting the network to reflect that informationnneural network have been used on a variety of task including computer vision speech recognition machine translation social network filtering playing board and video game and medical diagnosisnas of neural network typically have a few thousand to a few million unit and million of connection despite this number being several order of magnitude le than the number of neuron on a human brain these network can perform many task at a level beyond that of human eg recognizing face or playing gonnn deep neural network na deep neural network dnn is an artificial neural network with multiple layer between the input and output layer there are different type of neural network but they always consist of the same component neuron synapsis weight bias and function these component a a whole function in a way that mimic function of the human brain and can be trained like any other ml algorithmnfor example a dnn that is trained to recognize dog breed will go over the given image and calculate the probability that the dog in the image is a certain breed the user can review the result and select which probability the network should display above a certain threshold etc and return the proposed label each mathematical manipulation a such is considered a layer and complex dnn have many layer hence the name deep networksndnns can model complex nonlinear relationship dnn architecture generate compositional model where the object is expressed a a layered composition of primitive the extra layer enable composition of feature from lower layer potentially modeling complex data with fewer unit than a similarly performing shallow network for instance it wa proved that sparse multivariate polynomial are exponentially easier to approximate with dnns than with shallow networksndeep architecture include many variant of a few basic approach each architecture ha found success in specific domain it is not always possible to compare the performance of multiple architecture unless they have been evaluated on the same data setsndnns are typically feedforward network in which data flow from the input layer to the output layer without looping back at first the dnn creates a map of virtual neuron and assigns random numerical value or weight to connection between them the weight and input are multiplied and return an output between and if the network did not accurately recognize a particular pattern an algorithm would adjust the weight that way the algorithm can make certain parameter more influential until it determines the correct mathematical manipulation to fully process the datanrecurrent neural network in which data can flow in any direction are used for application such a language modeling long shortterm memory is particularly effective for this usenconvolutional neural network cnns are used in computer vision cnns also have been applied to acoustic modeling for automatic speech recognition asrnnn challenge na with anns many issue can arise with naively trained dnns two common issue are overfitting and computation timendnns are prone to overfitting because of the added layer of abstraction which allow them to model rare dependency in the training data regularization method such a ivakhnenkos unit pruning or weight decay n n n n n n n n n n n n displaystyle ell n nregularization or sparsity n n n n n n n n n n n n displaystyle ell n nregularization can be applied during training to combat overfitting alternatively dropout regularization randomly omits unit from the hidden layer during training this help to exclude rare dependency finally data can be augmented via method such a cropping and rotating such that smaller training set can be increased in size to reduce the chance of overfittingndnns must consider many training parameter such a the size number of layer and number of unit per layer the learning rate and initial weight sweeping through the parameter space for optimal parameter may not be feasible due to the cost in time and computational resource various trick such a batching computing the gradient on several training example at once rather than individual example speed up computation large processing capability of manycore architecture such a gpus or the intel xeon phi have produced significant speedup in training because of the suitability of such processing architecture for the matrix and vector computationsnalternatively engineer may look for other type of neural network with more straightforward and convergent training algorithm cmac cerebellar model articulation controller is one such kind of neural network it doesnt require learning rate or randomized initial weight the training process can be guaranteed to converge in one step with a new batch of data and the computational complexity of the training algorithm is linear with respect to the number of neuron involvednnn hardware nsince the s advance in both machine learning algorithm and computer hardware have led to more efficient method for training deep neural network that contain many layer of nonlinear hidden unit and a very large output layer by graphic processing unit gpus often with aispecific enhancement had displaced cpu a the dominant method of training largescale commercial cloud ai openai estimated the hardware computation used in the largest deep learning project from alexnet to alphazero and found a fold increase in the amount of computation required with a doublingtime trendline of monthsnspecial electronic circuit called deep learning processor were designed to speed up deep learning algorithm deep learning processor include neural processing unit npus in huawei cellphone and cloud computing server such a tensor processing unit tpu in the google cloud platform cerebras system ha also built a dedicated system to handle large deep learning model the c based on the largest processor in the industry the secondgeneration wafer scale engine wsenatomically thin semiconductor are considered promising for energyefficient deep learning hardware where the same basic device structure is used for both logic operation and data storagenin marega et al published experiment with a largearea active channel material for developing logicinmemory device and circuit based on floatinggate fieldeffect transistor fgfetsnin j feldmann et al proposed an integrated photonic hardware accelerator for parallel convolutional processing the author identify two key advantage of integrated photonics over it electronic counterpart massively parallel data transfer through wavelength division multiplexing in conjunction with frequency comb and extremely high data modulation speed their system can execute trillion of multiplyaccumulate operation per second indicating the potential of integrated photonics in dataheavy ai applicationsnnn application nnn automatic speech recognition nnlargescale automatic speech recognition is the first and most convincing successful case of deep learning lstm rnns can learn very deep learning task that involve multisecond interval containing speech event separated by thousand of discrete time step where one time step corresponds to about m lstm with forget gate is competitive with traditional speech recognizers on certain tasksnthe initial success in speech recognition wa based on smallscale recognition task based on timit the data set contains speaker from eight major dialect of american english where each speaker read sentence it small size let many configuration be tried more importantly the timit task concern phonesequence recognition which unlike wordsequence recognition allows weak phone bigram language model this let the strength of the acoustic modeling aspect of speech recognition be more easily analyzed the error rate listed below including these early result and measured a percent phone error rate per have been summarized since nnthe debut of dnns for speaker recognition in the late s and speech recognition around and of lstm around accelerated progress in eight major areasnnscaleupout and accelerated dnn training and decodingnsequence discriminative trainingnfeature processing by deep model with solid understanding of the underlying mechanismsnadaptation of dnns and related deep modelsnmultitask and transfer learning by dnns and related deep modelsncnns and how to design them to best exploit domain knowledge of speechnrnn and it rich lstm variantsnother type of deep model including tensorbased model and integrated deep generativediscriminative modelsnall major commercial speech recognition system eg microsoft cortana xbox skype translator amazon alexa google now apple siri baidu and iflytek voice search and a range of nuance speech product etc are based on deep learningnnn image recognition nna common evaluation set for image classification is the mnist database data set mnist is composed of handwritten digit and includes training example and test example a with timit it small size let user test multiple configuration a comprehensive list of result on this set is availablendeep learningbased image recognition ha become superhuman producing more accurate result than human contestant this first occurred in in recognition of traffic sign and in with recognition of human facesndeep learningtrained vehicle now interpret camera view another example is facial dysmorphology novel analysis fdna used to analyze case of human malformation connected to a large database of genetic syndromesnnn visual art processing nnclosely related to the progress that ha been made in image recognition is the increasing application of deep learning technique to various visual art task dnns have proven themselves capable for example ofnnidentifying the style period of a given paintingnneural style transfer capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or videongenerating striking imagery based on random visual input fieldsnnn natural language processing nnneural network have been used for implementing language model since the early s lstm helped to improve machine translation and language modelingnother key technique in this field are negative sampling and word embedding word embedding such a wordvec can be thought of a a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other word in the dataset the position is represented a a point in a vector space using word embedding a an rnn input layer allows the network to parse sentence and phrase using an effective compositional vector grammar a compositional vector grammar can be thought of a probabilistic context free grammar pcfg implemented by an rnn recursive autoencoders built atop word embeddings can ass sentence similarity and detect paraphrasing deep neural architecture provide the best result for constituency parsing sentiment analysis information retrieval spoken language understanding machine translation contextual entity linking writing style recognition namedentity recognition token classification text classification and othersnrecent development generalize word embedding to sentence embeddingngoogle translate gt us a large endtoend long shortterm memory lstm network google neural machine translation gnmt us an examplebased machine translation method in which the system learns from million of example it translates whole sentence at a time rather than piece google translate support over one hundred language the network encodes the semantics of the sentence rather than simply memorizing phrasetophrase translation gt us english a an intermediate between most language pairsnnn drug discovery and toxicology nna large percentage of candidate drug fail to win regulatory approval these failure are caused by insufficient efficacy ontarget effect undesired interaction offtarget effect or unanticipated toxic effect research ha explored use of deep learning to predict the biomolecular target offtargets and toxic effect of environmental chemical in nutrient household product and drugsnatomnet is a deep learning system for structurebased rational drug design atomnet wa used to predict novel candidate biomolecules for disease target such a the ebola virus and multiple sclerosisnin graph neural network were used for the first time to predict various property of molecule in a large toxicology data set in generative neural network were used to produce molecule that were validated experimentally all the way into micennn customer relationship management nndeep reinforcement learning ha been used to approximate the value of possible direct marketing action defined in term of rfm variable the estimated value function wa shown to have a natural interpretation a customer lifetime valuennn recommendation system nnrecommendation system have used deep learning to extract meaningful feature for a latent factor model for contentbased music and journal recommendation multiview deep learning ha been applied for learning user preference from multiple domain the model us a hybrid collaborative and contentbased approach and enhances recommendation in multiple tasksnnn bioinformatics nnan autoencoder ann wa used in bioinformatics to predict gene ontology annotation and genefunction relationshipsnin medical informatics deep learning wa used to predict sleep quality based on data from wearable and prediction of health complication from electronic health record datandeep neural network have shown unparalleled performance in predicting protein structure according to the sequence of the amino acid that make it up in alphafold a deeplearning based system achieved a level of accuracy significantly higher than all previous computational methodsnnn deep neural network estimation ndeep neural network can be used to estimate the entropy of a stochastic process and called neural joint entropy estimator njee such an estimation provides insight on the effect of input random variable on an independent random variable practically the dnn is trained a a classifier that map an input vector or matrix x to an output probability distribution over the possible class of random variable y given input x for example in image classification task the njee map a vector of pixel color value to probability over possible image class in practice the probability distribution of y is obtained by a softmax layer with number of node that is equal to the alphabet size of y njee us continuously differentiable activation function such that the condition for the universal approximation theorem hold it is shown that this method provides a strongly consistent estimator and outperforms other method in case of large alphabet sizesnnn medical image analysis ndeep learning ha been shown to produce competitive result in medical application such a cancer cell classification lesion detection organ segmentation and image enhancement modern deep learning tool demonstrate the high accuracy of detecting various disease and the helpfulness of their use by specialist to improve the diagnosis efficiencynnn mobile advertising nfinding the appropriate mobile audience for mobile advertising is always challenging since many data point must be considered and analyzed before a target segment can be created and used in ad serving by any ad server deep learning ha been used to interpret large manydimensioned advertising datasets many data point are collected during the requestserveclick internet advertising cycle this information can form the basis of machine learning to improve ad selectionnnn image restoration ndeep learning ha been successfully applied to inverse problem such a denoising superresolution inpainting and film colorization these application include learning method such a shrinkage field for effective image restoration which train on an image dataset and deep image prior which train on the image that need restorationnnn financial fraud detection ndeep learning is being successfully applied to financial fraud detection tax evasion detection and antimoney launderingnnn material science nin november researcher at google deepmind and lawrence berkeley national laboratory announced that they had developed an ai system known a gnome this system ha contributed to material science by discovering over million new material within a relatively short timeframe gnome employ deep learning technique to efficiently explore potential material structure achieving a significant increase in the identification of stable inorganic crystal structure the system prediction were validated through autonomous robotic experiment demonstrating a noteworthy success rate of the data of newly discovered material is publicly available through the material project database offering researcher the opportunity to identify material with desired property for various application this development ha implication for the future of scientific discovery and the integration of ai in material science research potentially expediting material innovation and reducing cost in product development the use of ai and deep learning suggests the possibility of minimizing or eliminating manual lab experiment and allowing scientist to focus more on the design and analysis of unique compoundsnnn military nthe united state department of defense applied deep learning to train robot in new task through observationnnn partial differential equation nphysics informed neural network have been used to solve partial differential equation in both forward and inverse problem in a data driven manner one example is the reconstructing fluid flow governed by the navierstokes equation using physic informed neural network doe not require the often expensive mesh generation that conventional cfd method relies onnnn image reconstruction nimage reconstruction is the reconstruction of the underlying image from the imagerelated measurement several work showed the better and superior performance of the deep learning method compared to analytical method for various application eg spectral imaging and ultrasound imagingnnn epigenetic clock nnan epigenetic clock is a biochemical test that can be used to measure age galkin et al used deep neural network to train an epigenetic aging clock of unprecedented accuracy using blood sample the clock us information from cpg site and predicts people with certain condition older than healthy control ibd frontotemporal dementia ovarian cancer obesity the aging clock wa planned to be released for public use in by an insilico medicine spinoff company deep longevitynnn relation to human cognitive and brain development ndeep learning is closely related to a class of theory of brain development specifically neocortical development proposed by cognitive neuroscientist in the early s these developmental theory were instantiated in computational model making them predecessor of deep learning system these developmental model share the property that various proposed learning dynamic in the brain eg a wave of nerve growth factor support the selforganization somewhat analogous to the neural network utilized in deep learning model like the neocortex neural network employ a hierarchy of layered filter in which each layer considers information from a prior layer or the operating environment and then pass it output and possibly the original input to other layer this process yield a selforganizing stack of transducer welltuned to their operating environment a description stated the infant brain seems to organize itself under the influence of wave of socalled trophicfactors different region of the brain become connected sequentially with one layer of tissue maturing before another and so on until the whole brain is maturena variety of approach have been used to investigate the plausibility of deep learning model from a neurobiological perspective on the one hand several variant of the backpropagation algorithm have been proposed in order to increase it processing realism other researcher have argued that unsupervised form of deep learning such a those based on hierarchical generative model and deep belief network may be closer to biological reality in this respect generative neural network model have been related to neurobiological evidence about samplingbased processing in the cerebral cortexnalthough a systematic comparison between the human brain organization and the neuronal encoding in deep network ha not yet been established several analogy have been reported for example the computation performed by deep learning unit could be similar to those of actual neuron and neural population similarly the representation developed by deep learning model are similar to those measured in the primate visual system both at the singleunit and at the population levelsnnn commercial activity nfacebooks ai lab performs task such a automatically tagging uploaded picture with the name of the people in themngoogles deepmind technology developed a system capable of learning how to play atari video game using only pixel a data input in they demonstrated their alphago system which learned the game of go well enough to beat a professional go player google translate us a neural network to translate between more than languagesnin covariantai wa launched which focus on integrating deep learning into factoriesnas of researcher at the university of texas at austin ut developed a machine learning framework called training an agent manually via evaluative reinforcement or tamer which proposed new method for robot or computer program to learn how to perform task by interacting with a human instructor first developed a tamer a new algorithm called deep tamer wa later introduced in during a collaboration between u army research laboratory arl and ut researcher deep tamer used deep learning to provide a robot with the ability to learn new task through observation using deep tamer a robot learned a task with a human trainer watching video stream or observing a human perform a task inperson the robot later practiced the task with the help of some coaching from the trainer who provided feedback such a good job and bad jobnnn criticism and comment ndeep learning ha attracted both criticism and comment in some case from outside the field of computer sciencennn theory nna main criticism concern the lack of theory surrounding some method learning in the most common deep architecture is implemented using wellunderstood gradient descent however the theory surrounding other algorithm such a contrastive divergence is le clear eg doe it converge if so how fast what is it approximating deep learning method are often looked at a a black box with most confirmation done empirically rather than theoreticallynothers point out that deep learning should be looked at a a step towards realizing strong ai not a an allencompassing solution despite the power of deep learning method they still lack much of the functionality needed to realize this goal entirely research psychologist gary marcus notednnrealistically deep learning is only part of the larger challenge of building intelligent machine such technique lack way of representing causal relationship have no obvious way of performing logical inference and they are also still a long way from integrating abstract knowledge such a information about what object are what they are for and how they are typically used the most powerful ai system like watson use technique like deep learning a just one element in a very complicated ensemble of technique ranging from the statistical technique of bayesian inference to deductive reasoningnnin further reference to the idea that artistic sensitivity might be inherent in relatively low level of the cognitive hierarchy a published series of graphic representation of the internal state of deep layer neural network attempting to discern within essentially random data the image on which they were trained demonstrate a visual appeal the original research notice received well over comment and wa the subject of what wa for a time the most frequently accessed article on the guardian websitennn error nsome deep learning architecture display problematic behavior such a confidently classifying unrecognizable image a belonging to a familiar category of ordinary image and misclassifying minuscule perturbation of correctly classified image goertzel hypothesized that these behavior are due to limitation in their internal representation and that these limitation would inhibit integration into heterogeneous multicomponent artificial general intelligence agi architecture these issue may possibly be addressed by deep learning architecture that internally form state homologous to imagegrammar decomposition of observed entity and event learning a grammar visual or linguistic from training data would be equivalent to restricting the system to commonsense reasoning that operates on concept in term of grammatical production rule and is a basic goal of both human language acquisition and artificial intelligence ainnn cyber threat na deep learning move from the lab into the world research and experience show that artificial neural network are vulnerable to hack and deception by identifying pattern that these system use to function attacker can modify input to anns in such a way that the ann find a match that human observer would not recognize for example an attacker can make subtle change to an image such that the ann find a match even though the image look to a human nothing like the search target such manipulation is termed an adversarial attacknin researcher used one ann to doctor image in trial and error fashion identify anothers focal point and thereby generate image that deceived it the modified image looked no different to human eye another group showed that printout of doctored image then photographed successfully tricked an image classification system one defense is reverse image search in which a possible fake image is submitted to a site such a tineye that can then find other instance of it a refinement is to search using only part of the image to identify image from which that piece may have been takennanother group showed that certain psychedelic spectacle could fool a facial recognition system into thinking ordinary people were celebrity potentially allowing one person to impersonate another in researcher added sticker to stop sign and caused an ann to misclassify themnanns can however be further trained to detect attempt at deception potentially leading attacker and defender into an arm race similar to the kind that already defines the malware defense industry anns have been trained to defeat annbased antimalware software by repeatedly attacking a defense with malware that wa continually altered by a genetic algorithm until it tricked the antimalware while retaining it ability to damage the targetnin another group demonstrated that certain sound could make the google now voice command system open a particular web address and hypothesized that this could serve a a stepping stone for further attack eg opening a web page hosting driveby malwarenin data poisoning false data is continually smuggled into a machine learning system training set to prevent it from achieving masterynnn data collection ethic nnmost deep learning system rely on training and verification data that is generated andor annotated by human it ha been argued in medium philosophy that not only lowpaid clickwork eg on amazon mechanical turk is regularly deployed for this purpose but also implicit form of human microwork that are often not recognized a such the philosopher rainer mhlhoff distinguishes five type of machinic capture of human microwork to generate training data gamification the embedding of annotation or computation task in the flow of a game trapping and tracking eg captchas for image recognition or clicktracking on google search result page exploitation of social motivation eg tagging face on facebook to obtain labeled facial image information mining eg by leveraging quantifiedself device such a activity tracker and clickworknmhlhoff argues that in most commercial enduser application of deep learning such a facebooks face recognition system the need for training data doe not stop once an ann is trained rather there is a continued demand for humangenerated verification data to constantly calibrate and update the ann for this purpose facebook introduced the feature that once a user is automatically recognized in an image they receive a notification they can choose whether or not they like to be publicly labeled on the image or tell facebook that it is not them in the picture this user interface is a mechanism to generate a constant stream of verification data to further train the network in realtime a mhlhoff argues the involvement of human user to generate training and verification data is so typical for most commercial enduser application of deep learning that such system may be referred to a humanaided artificial intelligencennn see also napplications of artificial intelligencencomparison of deep learning softwarencompressed sensingndifferentiable programmingnecho state networknlist of artificial intelligence projectsnliquid state machinenlist of datasets for machinelearning researchnreservoir computingnscale space and deep learningnsparse codingnstochastic parrotntopological deep learningnnn reference nnn further reading',\n",
              " 'a slot machine fruit machine british english poker machine or poky australian english and new zealand english is a gambling machine that creates a game of chance for it customersna slot machine standard layout feature a screen displaying three or more reel that spin when the game is activated some modern slot machine still include a lever a a skeuomorphic design trait to trigger play however the mechanical operation of early machine have been superseded by random number generator and most are now operated using button and touchscreensnslot machine include one or more currency detector that validate the form of payment whether coin banknote voucher or token the machine pay out according to the pattern of symbol displayed when the reel stop spinning slot machine are the most popular gambling method in casino and contribute about of the average u casino incomendigital technology ha resulted in variation in the original slot machine concept a the player is essentially playing a video game manufacturer can offer more interactive element such a advanced bonus round and more varied video graphicsnnn term and their source nthe slot machine term derives from the slot on the machine for inserting and retrieving coin fruit machine come from the traditional fruit image on the spinning reel such a lemon and cherry slot machine are also known pejoratively a onearmed bandit alluding to the large mechanical lever affixed to the side of early mechanical machine and to the game ability to empty player pocket and wallet a thief wouldnnn history nnsittman and pitt of brooklyn new york developed a gambling machine in that wa a precursor to the modern slot machine it contained five drum holding a total of card face and wa based on poker the machine proved extremely popular and soon many bar in the city had one or more of them player would insert a nickel and pull a lever which would spin the drum and the card that they held the player hoping for a good poker hand there wa no direct payout mechanism so a pair of king might get the player a free beer whereas a royal flush could pay out cigar or drink the prize were wholly dependent upon what the establishment would offer to improve the odds for the house two card were typically removed from the deck the ten of spade and the jack of heart doubling the odds against winning a royal flush the drum could also be rearranged to further reduce a player chance of winningnbecause of the vast number of possible win in the original pokerbased game it proved practically impossible to make a machine capable of awarding an automatic payout for all possible winning combination at some time between and charles fey of san francisco california devised a much simpler automatic mechanism with three spinning reel containing a total of five symbol horseshoe diamond spade heart and a liberty bell the bell gave the machine it name by replacing ten card with five symbol and using three reel instead of five drum the complexity of reading a win wa considerably reduced allowing fey to design an effective automatic payout mechanism three bell in a row produced the biggest payoff ten nickel liberty bell wa a huge success and spawned a thriving mechanical gaming device industry after a few year the device were banned in california but fey still could not keep up with the demand for them elsewhere the liberty bell machine wa so popular that it wa copied by many slot machine manufacturer the first of these also called the liberty bell wa produced by the manufacturer herbert mill in by bell machine had been installed in cigar store brothel and barber shop early machine including an liberty bell are now part of the nevada state museum fey collectionnthe first liberty bell machine produced by mill used the same symbol on the reel a did charles feys original soon afterward another version wa produced with patriotic symbol such a flag and wreath on the wheel later a similar machine called the operator bell wa produced that included the option of adding a gumvending attachment a the gum offered wa fruitflavored fruit symbol were placed on the reel lemon cherry orange and plum a bell wa retained and a picture of a stick of bellfruit gum the origin of the bar symbol wa also present this set of symbol proved highly popular and wa used by other company that began to make their own slot machine caille watling jennings and pacena commonly used technique to avoid gambling law in several state wa to award food prize for this reason several gumball and other vending machine were regarded with mistrust by the court the two iowa case of state v elli and state v striggles are both used in criminal law class to illustrate the concept of reliance upon authority a it relates to the axiomatic ignorantia juris non excusat ignorance of the law is no excuse in these case a mint vending machine wa declared to be a gambling device because the machine would by internally manufactured chance occasionally give the next user several token exchangeable for more candy despite the display of the result of the next use on the machine the court ruled that the machine appealed to the player propensity to gamble and that is a vicenin bally developed the first fully electromechanical slot machine called money honey although earlier machine such a ballys high hand drawpoker machine had exhibited the basic of electromechanical construction a early a it electromechanical working made money honey the first slot machine with a bottomless hopper and automatic payout of up to coin without the help of an attendant the popularity of this machine led to the increasing predominance of electronic game with the side lever soon becoming vestigialnthe first video slot machine wa developed in in kearny mesa california by the la vegasbased fortune coin co this machine used a modified inch cm sony trinitron color receiver for the display and logic board for all slotmachine function the prototype wa mounted in a fullsize showready slotmachine cabinet the first production unit went on trial at the la vega hilton hotel after some modification to defeat cheating attempt the video slot machine wa approved by the nevada state gaming commission and eventually found popularity on the la vega strip and in downtown casino fortune coin co and it video slotmachine technology were purchased by igt international gaming technology in nthe first american video slot machine to offer a second screen bonus round wa reel em in developed by wms industry in this type of machine had appeared in australia from at least with the three bag full game with this type of machine the display change to provide a different game in which an additional payout may be awardednnn operation nndepending on the machine the player can insert cash or in ticketin ticketout machine a paper ticket with a barcode into a designated slot on the machine the machine is then activated by mean of a lever or button either physical or on a touchscreen which activates reel that spin and stop to rearrange the symbol if a player match a winning combination of symbol the player earns credit based on the paytable symbol vary depending on the theme of the machine classic symbol include object such a fruit bell and stylized lucky seven most slot game have a theme such a a specific style location or character symbol and other bonus feature of the game are typically aligned with the theme some theme are licensed from popular medium franchise including film television series including game show such a wheel of fortune which ha been one of the most popular line of slot machine entertainer and musiciansnmultiline slot machine have become more popular since the s these machine have more than one payline meaning that visible symbol that are not aligned on the main horizontal may be considered a winning combination traditional threereel slot machine commonly have one three or five paylines while video slot machine may have or a many a different paylines most accept variable number of credit to play with to credit per line being typical the higher the amount bet the higher the payout will be if the player winsnone of the main difference between video slot machine and reel machine is in the way payouts are calculated with reel machine the only way to win the maximum jackpot is to play the maximum number of coin usually three sometimes four or even five coin per spin with video machine the fixed payout value are multiplied by the number of coin per line that is being bet in other word on a reel machine the odds are more favorable if the gambler play with the maximum number of coin available however depending on the structure of the game and it bonus feature some video slot may still include feature that improve chance at payouts by making increased wagersnnmultiway game eschew fixed paylines in favor of allowing symbol to pay anywhere a long a there is at least one in at least three consecutive reel from left to right multiway game may be configured to allow player to bet byreel for example on a game with a x pattern often referred to a a way game playing one reel allows all three symbol in the first reel to potentially pay but only the center row pay on the remaining reel often designated by darkening the unused portion of the reel other multiway game use a x or x pattern where there are up to five symbol in each reel allowing for up to and way to win respectively the australian manufacturer aristocrat leisure brand game featuring this system a reel power xtra reel power and super reel power respectively a variation involves pattern where symbol are adjacent to one another most of these game have a hexagonal reel formation and much like multiway game any pattern not played are darkened out of usendenominations can range from cent penny slot all the way up to or more per credit the latter are typically known a high limit machine and machine configured to allow for such wager are often located in dedicated area which may have a separate team of attendant to cater to the need of those who play there the machine automatically calculates the number of credit the player receives in exchange for the cash inserted newer machine often allow player to choose from a selection of denomination on a splash screen or menunnn terminology na bonus is a special feature of the particular game theme which is activated when certain symbol appear in a winning combination bonus and the number of bonus feature vary depending upon the game some bonus round are a special session of free spin the number of which is often based on the winning combination that trigger the bonus often with a different or modified set of winning combination a the main game andor other multiplier or increased frequency of symbol or a hold and respin mechanic in which specific symbol usually marked with value of credit or other prize are collected and locked in place over a finite number of spin in other bonus round the player is presented with several item on a screen from which to choose a the player chooses item a number of credit is revealed and awarded some bonus use a mechanical device such a a spinning wheel that work in conjunction with the bonus to display the amount wonna candle is a light on top of the slot machine it flash to alert the operator that change is needed hand pay is requested or a potential problem with the machine it can be lit by the player by pressing the service or help buttonncarousel refers to a grouping of slot machine usually in a circle or oval formationna coin hopper is a container where the coin that are immediately available for payouts are held the hopper is a mechanical device that rotates coin into the coin tray when a player collect creditscoins by pressing a cash out button when a certain preset coin capacity is reached a coin diverter automatically redirects or drop excess coin into a drop bucket or drop box unused coin hopper can still be found even on game that exclusively employ ticketin ticketout technology a a vestigenthe credit meter is a display of the amount of money or number of credit on the machine on mechanical slot machine this is usually a sevensegment display but video slot machine typically use stylized text that suit the game theme and user interfacenthe drop bucket or drop box is a container located in a slot machine base where excess coin are diverted from the hopper typically a drop bucket is used for lowdenomination slot machine and a drop box is used for highdenomination slot machine a drop box contains a hinged lid with one or more lock whereas a drop bucket doe not contain a lid the content of drop bucket and drop box are collected and counted by the casino on a scheduled basisnegm is short for electronic gaming machinenfree spin are a common form of bonus where a series of spin are automatically played at no charge at the player current wager free spin are usually triggered via a scatter of at least three designated symbol with the number of spin dependent on the number of symbol that land some game allow the free spin bonus to retrigger which add additional spin on top of those already awarded there is no theoretical limit to the number of free spin obtainable some game may have other feature that can also trigger over the course of free spinsna hand pay refers to a payout made by an attendant or at an exchange point cage rather than by the slot machine itself a hand pay occurs when the amount of the payout exceeds the maximum amount that wa preset by the slot machine operator usually the maximum amount is set at the level where the operator must begin to deduct tax a hand pay could also be necessary a a result of a short paynhopper fill slip is a document used to record the replenishment of the coin in the coin hopper after it becomes depleted a a result of making payouts to player the slip indicates the amount of coin placed into the hopper a well a the signature of the employee involved in the transaction the slot machine number and the location and the datenmeal book machine entry authorization log is a log of the employee entry into the machinenlowlevel or slanttop slot machine include a stool so the player may sit down standup or upright slot machine are played while standingnoptimal play is a payback percentage based on a gambler using the optimal strategy in a skillbased slot machine gamenpayline is a line that cross through one symbol on each reel along which a winning combination is evaluated classic spinning reel machine usually have up to nine paylines while video slot machine may have a many a one hundred paylines could be of various shape horizontal vertical oblique triangular zigzag etcnpersistent state refers to passive feature on some slot machine some of which able to trigger bonus payouts or other special feature if certain condition are met over time by player on that machinenrollup is the process of dramatizing a win by playing sound while the meter count up to the amount that ha been wonnshort pay refers to a partial payout made by a slot machine which is le than the amount due to the player this occurs if the coin hopper ha been depleted a a result of making earlier payouts to player the remaining amount due to the player is either paid a a hand pay or an attendant will come and refill the machinena scatter is a pay combination based on occurrence of a designated symbol landing anywhere on the reel rather than falling in sequence on the same payline a scatter pay usually requires a minimum of three symbol to land and the machine may offer increased prize or jackpot depending on the number that land scatter are frequently used to trigger bonus game such a free spin with the number of spin multiplying based on the number of scatter symbol that land the scatter symbol usually cannot be matched using wild and some game may require the scatter symbol to appear on consecutive reel in order to pay on some multiway game scatter symbol still pay in unused areasntaste is a reference to the small amount often paid out to keep a player seated and continuously betting only rarely will machine fail to pay even the minimum out over the course of several pullsnntilt is a term derived from electromechanical slot machine tilt switch which would make or break a circuit when they were tilted or otherwise tampered with that triggered an alarm while modern machine no longer have tilt switch any kind of technical fault door switch in the wrong state reel motor failure out of paper etc is still called a tiltna theoretical hold worksheet is a document provided by the manufacturer for every slot machine that indicates the theoretical percentage the machine should hold based on the amount paid in the worksheet also indicates the reel strip setting number of coin that may be played the payout schedule the number of reel and other information descriptive of the particular type of slot machinenvolatility or variance refers to the measure of risk associated with playing a slot machine a lowvolatility slot machine ha regular but smaller win while a highvariance slot machine ha fewer but bigger winsnweight count is an american term referring to the total value of coin or token removed from a slot machine drop bucket or drop box for counting by the casino hard count team through the use of a weigh scalenwild symbol substitute for most other symbol in the game similarly to a joker card usually excluding scatter and jackpot symbol or offering a lower prize on nonnatural combination that include wild how joker behave are dependent on the specific game and whether the player is in a bonus or free game mode sometimes wild symbol may only appear on certain reel or have a chance to stack across the entire reelnnn pay table nneach machine ha a table that list the number of credit the player will receive if the symbol listed on the pay table line up on the pay line of the machine some symbol are wild and can represent many or all of the other symbol to complete a winning line especially on older machine the pay table is listed on the face of the machine usually above and below the area containing the wheel on video slot machine they are usually contained within a help menu along with information on other featuresnnn technology nnn reel nhistorically all slot machine used revolving mechanical reel to display and determine result although the original slot machine used five reel simpler and therefore more reliable three reel machine quickly became the standardna problem with three reel machine is that the number of combination is only cubic the original slot machine with three physical reel and symbol on each reel had only possible combination this limited the manufacturer ability to offer large jackpot since even the rarest event had a likelihood of the maximum theoretical payout assuming return to player would be time the bet but that would leave no room for other pay making the machine very high risk and also quite boringnalthough the number of symbol eventually increased to about allowing combination this still limited jackpot size a well a the number of possible outcomesnin the s however slot machine manufacturer incorporated electronics into their product and programmed them to weight particular symbol thus the odds of losing symbol appearing on the payline became disproportionate to their actual frequency on the physical reel a symbol would only appear once on the reel displayed to the player but could in fact occupy several stop on the multiple reelnin inge telnaes received a patent for a device titled electronic gaming device utilizing a random number generator for selecting the reel stop position u patent which state it is important to make a machine that is perceived to present greater chance of payoff than it actually ha within the legal limitation that game of chance must operate the patent wa later bought by international game technology and ha since expiredna virtual reel that ha virtual stop per reel would allow up to final position the manufacturer could choose to offer a million jackpot on a bet confident that it will only happen over the long term once every million playsnnn computerization nwith microprocessor now ubiquitous the computer inside modern slot machine allow manufacturer to assign a different probability to every symbol on every reel to the player it might appear that a winning symbol wa so close whereas in fact the probability is much lowernin the s in the uk machine embodying microprocessor became common these used a number of feature to ensure the payout wa controlled within the limit of the gambling legislation a a coin wa inserted into the machine it could go either directly into the cashbox for the benefit of the owner or into a channel that formed the payout reservoir with the microprocessor monitoring the number of coin in this channel the drum themselves were driven by stepper motor controlled by the processor and with proximity sensor monitoring the position of the drum a lookup table within the software allows the processor to know what symbol were being displayed on the drum to the gambler this allowed the system to control the level of payout by stopping the drum at position it had determined if the payout channel had filled up the payout became more generous if nearly empty the payout became le so thus giving good control of the oddsnnn video slot machine nvideo slot machine do not use mechanical reel but use graphical reel on a computerized display a there are no mechanical constraint on the design of video slot machine game often use at least five reel and may also use nonstandard layout this greatly expands the number of possibility a machine can have or more symbol on a reel giving odds a high a million to against enough for even the largest jackpot a there are so many combination possible with five reel manufacturer do not need to weight the payout symbol although some may still do so instead higher paying symbol will typically appear only once or twice on each reel while more common symbol earning a more frequent payout will appear many time video slot machine usually make more extensive use of multimedia and can feature more elaborate minigames a bonus modern cabinet typically use flatpanel display but cabinet using larger curved screen which can provide a more immersive experience for the player are not uncommonnvideo slot machine typically encourage the player to play multiple line rather than simply taking the middle of the three symbol displayed on each reel a line could go from top left to the bottom right or any other pattern specified by the manufacturer a each symbol is equally likely there is no difficulty for the manufacturer in allowing the player to take a many of the possible line on offer a desired the longterm return to the player will be the same the difference for the player is that the more line they play the more likely they are to get paid on a given spin because they are betting morento avoid seeming a if the player money is simply ebbing away whereas a payout of credit on a singleline machine would be bet and the player would feel they had made a substantial win on a line machine it would only be five bet and not seem a significant manufacturer commonly offer bonus game which can return many time their bet the player is encouraged to keep playing to reach the bonus even if they are losing the bonus game could allow them to win back their lossesnnn payout percentage nnslot machine are typically programmed to pay out a winning to of the money that is wagered by player this is known a the theoretical payout percentage or rtp return to player the minimum theoretical payout percentage varies among jurisdiction and is typically established by law or regulation for example the minimum payout in nevada is in new jersey and in mississippi the winning pattern on slot machine the amount they pay and the frequency of those payouts are carefully selected to yield a certain fraction of the money paid to the house the operator of the slot machine while returning the rest to the player during play suppose that a certain slot machine cost per spin and ha a return to player rtp of it can be calculated that over a sufficiently long period such a spin the machine will return an average of to it player who have inserted during that time in this simplified example the slot machine is said to pay out the operator keep the remaining within some egm development organization this concept is referred to simply a par par also manifest itself to gambler a promotional technique our loose slot have a payback play nowna slot machine theoretical payout percentage is set at the factory when the software is written changing the payout percentage after a slot machine ha been placed on the gaming floor requires a physical swap of the software or firmware which is usually stored on an eprom but may be loaded onto nonvolatile random access memory nvram or even stored on cdrom or dvd depending on the capability of the machine and the applicable regulation based on current technology this is a timeconsuming process and a such is done infrequently in certain jurisdiction such a new jersey the eprom ha a tamperevident seal and can only be changed in the presence of gaming control board official other jurisdiction including nevada randomly audit slot machine to ensure that they contain only approved softwarenhistorically many casino both online and offline have been unwilling to publish individual game rtp figure making it impossible for the player to know whether they are playing a loose or a tight game since the turn of the century some information regarding these figure ha started to come into the public domain either through various casino releasing themprimarily this applies to online casinosor through study by independent gambling authoritiesnthe return to player is not the only statistic that is of interest the probability of every payout on the pay table is also critical for example consider a hypothetical slot machine with a dozen different value on the pay table however the probability of getting all the payouts are zero except the largest one if the payout is time the input amount and it happens every time on average the return to player is exactly but the game would be dull to play also most people would not win anything and having entry on the paytable that have a return of zero would be deceptive a these individual probability are closely guarded secret it is possible that the advertised machine with high return to player simply increase the probability of these jackpot the casino could legally place machine of a similar style payout and advertise that some machine have return to player the added advantage is that these large jackpot increase the excitement of the other playersnthe table of probability for a specific machine is called the probability and accounting report or par sheet also par commonly understood a paytable and reel strip mathematician michael shackleford revealed the par for one commercial slot machine an original international gaming technology red white and blue machine this game in it original form is obsolete so these specific probability do not apply he only published the odds after a fan of his sent him some information provided on a slot machine that wa posted on a machine in the netherlands the psychology of the machine design is quickly revealed there are possible payouts ranging from to the payout come every play the payout come every play whereas the payout come every play most player assume the likelihood increase proportionate to the payout the one midsize payout that is designed to give the player a thrill is the payout it is programmed to occur an average of once every play the payout is high enough to create excitement but not high enough that it make it likely that the player will take their winning and abandon the game more than likely the player began the game with at least time his bet for instance there are quarter in in contrast the payout occurs only on average of once every play the highest payout of occurs only on average of once every play since the machine ha virtual stop the player who continues to feed the machine is likely to have several midsize payouts but unlikely to have a large payout he quits after he is bored or ha exhausted his bankrollndespite their confidentiality occasionally a par sheet is posted on a website they have limited value to the player because usually a machine will have to different possible program with varying payouts in addition slight variation of each machine eg with double jackpot or five time play are always being developed the casino operator can choose which eprom chip to install in any particular machine to select the payout desired the result is that there is not really such a thing a a high payback type of machine since every machine potentially ha multiple setting from october to february columnist michael shackleford obtained par sheet for five different nickel machine four igt game austin power fortune cookie leopard spot and wheel of fortune and one game manufactured by wms reel em in without revealing the proprietary information he developed a program that would allow him to determine with usually le than a dozen play on each machine which eprom chip wa installed then he did a survey of over machine in different casino in la vega he averaged the data and assigned an average payback percentage to the machine in each casino the resultant list wa widely publicized for marketing purpose especially by the palm casino which had the top rankingnone reason that the slot machine is so profitable to a casino is that the player must play the high house edge and high payout wager along with the low house edge and low payout wager in a more traditional wagering game like crap the player know that certain wager have almost a chance of winning or losing but they only pay a limited multiple of the original bet usually no higher than three time other bet have a higher house edge but the player is rewarded with a bigger win up to thirty time in crap the player can choose what kind of wager he want to make a slot machine doe not afford such an opportunity theoretically the operator could make these probability available or allow the player to choose which one so that the player is free to make a choice however no operator ha ever enacted this strategy different machine have different maximum payouts but without knowing the odds of getting the jackpot there is no rational way to differentiatenin many market where central monitoring and control system are used to link machine for auditing and security purpose usually in wide area network of multiple venue and thousand of machine player return must usually be changed from a central computer rather than at each machine a range of percentage is set in the game software and selected remotelynin the nevada gaming commission began working with la vega casino on technology that would allow the casino management to change the game the odds and the payouts remotely the change cannot be done instantaneously but only after the selected machine ha been idle for at least four minute after the change is made the machine must be locked to new player for four minute and display an onscreen message informing potential player that a change is being madennn linked machine nsome variety of slot machine can be linked together in a setup sometimes known a a community game the most basic form of this setup involves progressive jackpot that are shared between the bank of machine but may include multiplayer bonus and other featuresnin some case multiple machine are linked across multiple casino in these case the machine may be owned by the manufacturer who is responsible for paying the jackpot the casino lease the machine rather than owning them outright casino in new jersey nevada louisiana arkansas and south dakota now offer multistate progressive jackpot which now offer bigger jackpot poolsnnn fraud nmechanical slot machine and their coin acceptor were sometimes susceptible to cheating device and other scam one historical example involved spinning a coin with a short length of plastic wire the weight and size of the coin would be accepted by the machine and credit would be granted however the spin created by the plastic wire would cause the coin to exit through the reject chute into the payout tray this particular scam ha become obsolete due to improvement in newer slot machine another obsolete method of defeating slot machine wa to use a light source to confuse the optical sensor used to count coin during payoutnmodern slot machine are controlled by eprom computer chip and in large casino coin acceptor have become obsolete in favor of bill acceptor these machine and their bill acceptor are designed with advanced anticheating and anticounterfeiting measure and are difficult to defraud early computerized slot machine were sometimes defrauded through the use of cheating device such a the slider monkey paw lightwand and the tongue many of these old cheating device were made by the late tommy glenn carmichael a slot machine fraudster who reportedly stole over million in the modern day computerized slot machine are fully deterministic and thus outcome can be sometimes successfully predictednnn skill stop nskill stop button predated the bally electromechanical slot machine of the s and s they appeared on mechanical slot machine manufactured by mill novelty co a early a the mid s these machine had modified reelstop arm which allowed them to be released from the timing bar earlier than in a normal play simply by pressing the button on the front of the machine located between each reelnskill stop button were added to some slot machine by zacharias anthony in the early s these enabled the player to stop each reel allowing a degree of skill so a to satisfy the new jersey gaming law of the day which required that player were able to control the game in some way the original conversion wa applied to approximately latemodel bally slot machine because the typical machine stopped the reel automatically in le than second weight were added to the mechanical timer to prolong the automatic stopping of the reel by the time the new jersey alcoholic beverage commission abc had approved the conversion for use in new jersey arcade the word wa out and every other distributor began adding skill stop the machine were a huge hit on the jersey shore and the remaining unconverted bally machine were destroyed a they had become instantly obsoletennn legislation nnn united state nin the united state the public and private availability of slot machine is highly regulated by state government many state have established gaming control board to regulate the possession and use of slot machine and other form of gamingnnevada is the only state that ha no significant restriction against slot machine both for public and private use in new jersey slot machine are only allowed in hotel casino operated in atlantic city several state indiana louisiana and missouri allow slot machine a well a any casinostyle gambling only on licensed riverboats or permanently anchored barge since hurricane katrina mississippi ha removed the requirement that casino on the gulf coast operate on barge and now allows them on land along the shoreline delaware allows slot machine at three horse track they are regulated by the state lottery commission in wisconsin bar and tavern are allowed to have up to five machine these machine usually allow a player to either take a payout or gamble it on a doubleornothing side gamenthe territory of puerto rico place significant restriction on slot machine ownership but the law is widely flouted and slot machine are common in bar and coffeeshopsnin regard to tribal casino located on native american reservation slot machine played against the house and operating independently from a centralized computer system are classified a class iii gaming by the indian gaming regulatory act igra and sometimes promoted a vegasstyle slot machine in order to offer class iii gaming tribe must enter into a compact agreement with the state that is approved by the department of the interior which may contain restriction on the type and quantity of such game a a workaround some casino may operate slot machine a class ii gamesa category that includes game where player play exclusively against at least one other opponent and not the house such a bingo or any related game such a pulltabs in these case the reel are an entertainment display with a predetermined outcome based on a centralized game played against other player under the igra class ii game are regulated by individual tribe and the national indian gaming commission and do not require any additional approval if the state already permit tribal gamingnsome historical race wagering terminal operate in a similar manner with the machine using slot a an entertainment display for outcome paid using the parimutuel betting system based on result of randomlyselected previouslyheld horse race with the player able to view selected detail about the race and adjust their pick before playing the credit or otherwise use an autobet systemnnn private ownership nnalaska arizona arkansas kentucky maine minnesota nevada ohio rhode island texas utah virginia and west virginia place no restriction on private ownership of slot machine conversely in connecticut hawaii nebraska south carolina and tennessee private ownership of any slot machine is completely prohibited the remaining state allow slot machine of a certain age typically year or slot machine manufactured before a specific datennn canada nthe government of canada ha minimal involvement in gambling beyond the canadian criminal code in essence the term lottery scheme used in the code mean slot machine bingo and table game normally associated with a casino these fall under the jurisdiction of the province or territory without reference to the federal government in practice all canadian province operate gaming board that oversee lottery casino and video lottery terminal under their jurisdictionnolg piloted a classification system for slot machine at the grand river raceway developed by university of waterloo professor kevin harrigan a part of it playsmart initiative for responsible gambling inspired by nutrition label on food they displayed metric such a volatility and frequency of payouts olg ha also deployed electronic gaming machine with predetermined outcome based on a bingo or pulltab game initially branded a taptix which visually resemble slot machinesnin ontario april saw the reintroduction of the online gambling market this became possible when the canadian criminal code wa amended to allow singleevent wagering august the province is expected to generate about million in gross revenue per yearnnn australia nin australia poker machine or poky are officially termed gaming machine in australia gaming machine are a matter for state government so law vary between state gaming machine are found in casino approximately one in each major city pub and club in some state usually sport social or rsl club the first australian state to legalize this style of gambling wa new south wale when in they were made legal in all registered club in the state there are suggestion that the proliferation of poker machine ha led to increased level of problem gambling however the precise nature of this link is still open to researchnin the australian productivity commission reported that nearly half australia gaming machine were in new south wale at the time of all the gambling machine in the world were operating in australia and on a per caput basis australia had roughly five time a many gaming machine a the united state australia rank th in total number of gaming machine after japan usa italy uk spain and germany this primarily is because gaming machine have been legal in the state of new south wale since over time the number of machine ha grown to at december including the australian capital territory by way of comparison the u state of nevada which legalised gaming including slot several decade before nsw had slot operatingnrevenue from gaming machine in pub and club account for more than half of the billion in gambling revenue collected by state government in fiscal year nin queensland gaming machine in pub and club must provide a return rate of while machine located in casino must provide a return rate of most other state have similar provision in victoria gaming machine must provide a minimum return rate of at least including jackpot contribution are prohibited from accepting bill greater than in denomination and each wager must be manually initiated by the player thus prohibiting autoplay mechanism nwestern australia ha the most restrictive regulation on electronic gaming machine egms in general they may only be operated at the crown perth casino resort which is the only casino in western australia and have a return rate of many egms operate game that are nearly identical to slot machine but with modification to comply with state law egms are prohibited from using spinning reel and must not use symbol associated with poker machine used elsewhere each wager must take at least three second to play and each wager must be initiated by the usernthis policy ha an extensive political history reaffirmed by the royal commission into gamblingnnpoker machine playing is a mindless repetitive and insidious form of gambling which ha many undesirable feature it requires no thought no skill or social contact the odds are never about winning watching people playing the machine over long period of time the impressionistic evidence at least is that they are addictive to many people historically poker machine have been banned from western australia and we consider that in the public interest they should stay bannedndespite the state having praised it restriction for keeping gaming machine from being widely available to the public a in other state the machine have faced criticism for being almost indistinguishable to a normal slot machine and thus having the same addictive quality in march a royal commission found crown gaming to be unfit to hold a gaming license in wa citing issue surrounding money laundering failing to minimise harm from problem gambling and the regulatory framework of the gaming and wagering commission being considered outdated to implement the recommendation of the commission egms were limited to maximum bet of beginning in july while also requiring the implementation of weekly limit on play and loss and the implementation of cashless machine requiring preloaded player card to functionnnick xenophon wa elected on an independent no poky ticket in the south australian legislative council at the south australian state election on percent reelected at the election on percent and elected to the australian senate at the federal election on percent independent candidate andrew wilkie an antipokies campaigner wa elected to the australian house of representative seat of denison at the federal election wilkie wa one of four crossbencher who supported the gillard labor government following the hung parliament result wilkie immediately began forging tie with xenophon a soon a it wa apparent that he wa elected in exchange for wilkies support the labor government are attempting to implement precommitment technology for highbethighintensity poker machine against opposition from the tony abbott coalition and club australianduring the covid pandemic of every establishment in the country that facilitated poker machine wa shut down in an attempt to curb the spread of the virus bringing australia usage of poker machine effectively to zeronnn russia nin russia slot club appeared quite late only in before slot machine were only in casino and small shop but later slot club began appearing all over the country the most popular and numerous were vulcan and taj mahal since when gambling establishment were banned almost all slot club disappeared and are found only in a specially authorized gambling zonesnnn united kingdom nnslot machine are covered by the gambling act which superseded the gaming act nslot machine in the uk are categorised by definition produced by the gambling commission a part of the gambling act of nncasinos built under the provision of the act are allowed to house either up to twenty machine of category bd or any number of cd machine a defined by the act large casino can have a maximum of one hundred and fifty machine in any combination of category bd subject to a machinetotable ratio of small casino can have a maximum of eighty machine in any combination of category bd subject to a machinetotable ratio of nnn category a ncategory a game were defined in preparation for the planned super casino despite a lengthy bidding process with manchester being chosen a the single planned location the development wa cancelled soon after gordon brown became prime minister of the united kingdom a a result there are no lawful category a game in the uknnn category b ncategory b game are divided into subcategories the difference between b b and b game are mainly the stake and prize a defined in the above table category b game fixed odds betting terminal fobts have quite different stake and prize rule fobts are mainly found in licensed betting shop or bookmaker usually in the form of electronic roulettenthe game are based on a random number generator thus each game probability of getting the jackpot is independent of any other game probability are all equal if a pseudorandom number generator is used instead of a truly random one probability are not independent since each number is determined at least in part by the one generated before itnnn category c ncategory c game are often referred to a fruit machine onearmed bandit and awp amusement with prize fruit machine are commonly found in pub club and arcade machine commonly have three but can be found with four or five reel each with symbol printed around them the reel are spun each play from which the appearance of particular combination of symbol result in payment of their associated winning by the machine or alternatively initiation of a subgame these game often have many extra feature trail and subgames with opportunity to win money usually more than can be won from just the payouts on the reel combinationsnfruit machine in the uk almost universally have the following feature generally selected at random using a pseudorandom number generatornna player known in the industry a a punter may be given the opportunity to hold one or more reel before spinning meaning they will not be spun but instead retain their displayed symbol yet otherwise count normally for that play this can sometimes increase the chance of winning especially if two or more reel are heldna player may also be given a number of nudge following a spin or in some machine a a result in a subgame a nudge is a step rotation of a reel chosen by the player the machine may not allow all reel to be nudged for a particular playncheats can also be made available on the internet or through emailed newsletter to subscriber these cheat give the player the impression of an advantage whereas in reality the payout percentage remains exactly the same the most widely used cheat is known a hold after a nudge and increase the chance that the player will win following an unsuccessful nudge machine from the early s did not advertise the concept of hold after a nudge when this feature wa first introduced it became so well known amongst player and widespread amongst new machine release that it is now welladvertised on the machine during play this is characterized by message on the display such a dont hold any or let em spin and is a designed feature of the machine not a cheat at all holding the same pair three time on three consecutive spin also give a guaranteed win on most machine that offer holdsnit is known for machine to pay out multiple jackpot one after the other this is known a a repeat but each jackpot requires a new game to be played so a not to violate the law about the maximum payout on a single play typically this involves the player only pressing the start button at the repeat prompt for which a single credit is taken regardless of whether this cause the reel to spin or not machine are also known to intentionally set aside money which is later awarded in a series of win known a a streak the minimum payout percentage is with pub often setting the payout at around nnn japan nnjapanese slot machine known a pachisuro or pachislot from the word pachinko and slot machine are a descendant of the traditional japanese pachinko game slot machine are a fairly new phenomenon and they can be found mostly in pachinko parlor and the adult section of amusement arcade known a game centersnnn jackpot dispute nnelectronic slot machine can malfunction when the displayed amount is smaller than the one it is supposed to be the error usually go unnoticed when it happens the other way dispute are likely below are some notable argument caused by the owner of the machine saying that the displayed amount were far larger than the one patron should getnnn united state ntwo such case occurred in casino in colorado in where software error led to indicated jackpot of million and million analysis of machine record by the state gaming commission revealed fault with the true jackpot being substantially smaller state gaming law did not require a casino to honour payouts in that casennn vietnam non october while a vietnamese american man ly sam wa playing a slot machine in the palazzo club at the sheraton saigon hotel in ho chi minh city vietnam it displayed that he had hit a jackpot of u the casino refused to pay saying it wa a machine error ly sued the casino on january the district people court in ho chi minh city decided that the casino had to pay the amount ly claimed in full not trusting the error report from an inspection company hired by the casino both side appealed thereafter and ly asked for interest while the casino refused to pay him in january the news reported that the case had been settled out of court and ly had received an undisclosed sumnnn problem gambling and slot machine nnnatasha dow schll associate professor in new york university department of medium culture and communication us the term machine zone to describe the state of immersion that user of slot machine experience when gambling where they lose a sense of time space bodily awareness and monetary valuenmike dixon phd professor of psychology at the university of waterloo study the relationship between slot player and machine in one of dixons study player were observed experiencing heightened arousal from the sensory stimulus coming from the machine they sought to show that these loss disguised a win ldws would be a arousing a win and more arousing than regular lossesnpsychologists robert breen and marc zimmerman found that player of video slot machine reach a debilitating level of involvement with gambling three time a rapidly a those who play traditional casino game even if they have engaged in other form of gambling without problemsneyetracking research in local bookkeeper office in the uk suggested that in slot game the reel dominated player visual attention and that problem gambler looked more frequently at amountwon message than did those without gambling problemsnthe minute report slot machine the big gamble focused on the link between slot machine and gambling addictionnnn see also ncasinoneuropean gaming amusement federationnlist of probability topicsnmultiarmed banditnpachinkonproblem gamblingnprogressive jackpotnquiz machinenunited state state slot machine ownership regulationsnvideo bingonvideo lottery terminal vltnvideo pokernnn reference nnn bibliography nbrisman andrew the american mensa guide to casino gambling winning way stirling isbn xngrochowski john the slot machine answer book how they work how theyve changed and how to overcome the house advantage bonus book isbn nlegato frank how to win million playing slot machine or lose trying bonus book isbn nnn external link',\n",
              " 'data science is an interdisciplinary academic field that us statistic scientific computing scientific method process algorithm and system to extract or extrapolate knowledge and insight from potentially noisy structured or unstructured data ndata science also integrates domain knowledge from the underlying application domain eg natural science information technology and medicine data science is multifaceted and can be described a a science a research paradigm a research method a discipline a workflow and a professionndata science is a concept to unify statistic data analysis informatics and their related method to understand and analyze actual phenomenon with data it us technique and theory drawn from many field within the context of mathematics statistic computer science information science and domain knowledge however data science is different from computer science and information science turing award winner jim gray imagined data science a a fourth paradigm of science empirical theoretical computational and now datadriven and asserted that everything about science is changing because of the impact of information technology and the data delugena data scientist is a professional who creates programming code and combine it with statistical knowledge to create insight from datannn foundation ndata science is an interdisciplinary field focused on extracting knowledge from typically large data set and applying the knowledge and insight from that data to solve problem in a wide range of application domain the field encompasses preparing data for analysis formulating data science problem analyzing data developing datadriven solution and presenting finding to inform highlevel decision in a broad range of application domain a such it incorporates skill from computer science statistic information science mathematics data visualization information visualization data sonification data integration graphic design complex system communication and business statistician nathan yau drawing on ben fry also link data science to humancomputer interaction user should be able to intuitively control and explore data in the american statistical association identified database management statistic and machine learning and distributed and parallel system a the three emerging foundational professional communitiesnnn relationship to statistic nmany statistician including nate silver have argued that data science is not a new field but rather another name for statistic others argue that data science is distinct from statistic because it focus on problem and technique unique to digital data vasant dhar writes that statistic emphasizes quantitative data and description in contrast data science deal with quantitative and qualitative data eg from image text sensor transaction customer information etc and emphasizes prediction and action andrew gelman of columbia university ha described statistic a a nonessential part of data sciencenstanford professor david donoho writes that data science is not distinguished from statistic by the size of datasets or use of computing and that many graduate program misleadingly advertise their analytics and statistic training a the essence of a datascience program he describes data science a an applied field growing out of traditional statisticsnnn etymology nnn early usage nin john tukey described a field he called data analysis which resembles modern data science in in a lecture given to the chinese academy of science in beijing c f jeff wu used the term data science for the first time a an alternative name for statistic later attendee at a statistic symposium at the university of montpellier ii acknowledged the emergence of a new discipline focused on data of various origin and form combining established concept and principle of statistic and data analysis with computingnthe term data science ha been traced back to when peter naur proposed it a an alternative name to computer science in the international federation of classification society became the first conference to specifically feature data science a a topic however the definition wa still in flux after the lecture at the chinese academy of science in beijing in c f jeff wu again suggested that statistic should be renamed data science he reasoned that a new name would help statistic shed inaccurate stereotype such a being synonymous with accounting or limited to describing data in hayashi chikio argued for data science a a new interdisciplinary concept with three aspect data design collection and analysisnduring the s popular term for the process of finding pattern in datasets which were increasingly large included knowledge discovery and data miningnnn modern usage nin technologist thomas h davenport and dj patil declared data scientist the sexiest job of the st century a catchphrase that wa picked up even by majorcity newspaper like the new york time and the boston globe a decade later they reaffirmed it stating that the job is more in demand than ever with employersnthe modern conception of data science a an independent discipline is sometimes attributed to william s cleveland in a paper he advocated an expansion of statistic beyond theory into technical area because this would significantly change the field it warranted a new name data science became more widely used in the next few year in the committee on data for science and technology launched the data science journal in columbia university launched the journal of data science in the american statistical association section on statistical learning and data mining changed it name to the section on statistical learning and data science reflecting the ascendant popularity of data sciencenthe professional title of data scientist ha been attributed to dj patil and jeff hammerbacher in though it wa used by the national science board in their report longlived digital data collection enabling research and education in the st century it referred broadly to any key role in managing a digital data collectionnthere is still no consensus on the definition of data science and it is considered by some to be a buzzword big data is a related marketing term data scientist are responsible for breaking down big data into usable information and creating software and algorithm that help company and organization determine optimal operationsnnn data science and data analysis nndata science and data analysis are both important discipline in the field of data management and analysis but they differ in several key way while both field involve working with data data science is more of an interdisciplinary field that involves the application of statistical computational and machine learning method to extract insight from data and make prediction while data analysis is more focused on the examination and interpretation of data to identify pattern and trendsndata analysis typically involves working with smaller structured datasets to answer specific question or solve specific problem this can involve task such a data cleaning data visualization and exploratory data analysis to gain insight into the data and develop hypothesis about relationship between variable data analyst typically use statistical method to test these hypothesis and draw conclusion from the data for example a data analyst might analyze sale data to identify trend in customer behavior and make recommendation for marketing strategiesndata science on the other hand is a more complex and iterative process that involves working with larger more complex datasets that often require advanced computational and statistical method to analyze data scientist often work with unstructured data such a text or image and use machine learning algorithm to build predictive model and make datadriven decision in addition to statistical analysis data science often involves task such a data preprocessing feature engineering and model selection for instance a data scientist might develop a recommendation system for an ecommerce platform by analyzing user behavior pattern and using machine learning algorithm to predict user preferencesnwhile data analysis focus on extracting insight from existing data data science go beyond that by incorporating the development and implementation of predictive model to make informed decision data scientist are often responsible for collecting and cleaning data selecting appropriate analytical technique and deploying model in realworld scenario they work at the intersection of mathematics computer science and domain expertise to solve complex problem and uncover hidden pattern in large datasetsndespite these difference data science and data analysis are closely related field and often require similar skill set both field require a solid foundation in statistic programming and data visualization a well a the ability to communicate finding effectively to both technical and nontechnical audience both field benefit from critical thinking and domain knowledge a understanding the context and nuance of the data is essential for accurate analysis and modelingnin summary data analysis and data science are distinct yet interconnected discipline within the broader field of data management and analysis data analysis focus on extracting insight and drawing conclusion from structured data while data science involves a more comprehensive approach that combine statistical analysis computational method and machine learning to extract insight build predictive model and drive datadriven decisionmaking both field use data to understand pattern make informed decision and solve complex problem across various domainsnnn cloud computing for data science nncloud computing can offer access to large amount of computational power and storage in big data where volume of information are continually generated and processed these platform can be used to handle complex and resourceintensive analytical tasksnsome distributed computing framework are designed to handle big data workload these framework can enable data scientist to process and analyze large datasets in parallel which can reducing processing timesnnn ethical consideration in data science ndata science involve collecting processing and analyzing data which often including personal and sensitive information ethical concern include potential privacy violation bias perpetuation and negative societal impact nmachine learning model can amplify existing bias present in training data leading to discriminatory or unfair outcomesnnn see also nopen data science conferencenscientific datanwomen in datanpython programming languagenr programming languagendata engineeringnbig datanmachine learningnnn reference',\n",
              " 'a recurrent neural network rnn is one of the two broad type of artificial neural network characterized by direction of the flow of information between it layer in contrast to the unidirectional feedforward neural network it is a bidirectional artificial neural network meaning that it allows the output from some node to affect subsequent input to the same node their ability to use internal state memory to process arbitrary sequence of input make them applicable to task such a unsegmented connected handwriting recognition or speech recognition the term recurrent neural network is used to refer to the class of network with an infinite impulse response whereas convolutional neural network refers to the class of finite impulse response both class of network exhibit temporal dynamic behavior a finite impulse recurrent network is a directed acyclic graph that can be unrolled and replaced with a strictly feedforward neural network while an infinite impulse recurrent network is a directed cyclic graph that can not be unrollednadditional stored state and the storage under direct control by the network can be added to both infiniteimpulse and finiteimpulse network another network or graph can also replace the storage if that incorporates time delay or ha feedback loop such controlled state are referred to a gated state or gated memory and are part of long shortterm memory network lstms and gated recurrent unit this is also called feedback neural network fnn recurrent neural network are theoretically turing complete and can run arbitrary program to process arbitrary sequence of inputsnnn history nthe ising model by wilhelm lenz and ernst isingnwas the first rnn architecture that did not learn shunichi amari made it adaptive in this wa also called the hopfield network see also david rumelharts work in in a neural history compressor system solved a very deep learning task that required more than subsequent layer in an rnn unfolded in timennn lstm nlong shortterm memory lstm network were invented by hochreiter and schmidhuber in and set accuracy record in multiple application domainsnaround lstm started to revolutionize speech recognition outperforming traditional model in certain speech application in a connectionist temporal classification ctctrained lstm network wa the first rnn to win pattern recognition contest when it won several competition in connected handwriting recognition in the chinese company baidu used ctctrained rnns to break the s switchboard hub speech recognition dataset benchmark without using any traditional speech processing methodsnlstm also improved largevocabulary speech recognition and texttospeech synthesis and wa used in google android in google speech recognition reportedly experienced a dramatic performance jump of through ctctrained lstmnlstm broke record for improved machine translation language modeling and multilingual language processing lstm combined with convolutional neural network cnns improved automatic image captioningnnn architecture nnrnns come in many variantsnnn fully recurrent nnfully recurrent neural network frnn connect the output of all neuron to the input of all neuron this is the most general neural network topology because all other topology can be represented by setting some connection weight to zero to simulate the lack of connection between those neuron the illustration to the right may be misleading to many because practical neural network topology are frequently organized in layer and the drawing give that appearance however what appears to be layer are in fact different step in time of the same fully recurrent neural network the leftmost item in the illustration show the recurrent connection a the arc labeled v it is unfolded in time to produce the appearance of layersnnn elman network and jordan network nnan elman network is a threelayer network arranged horizontally a x y and z in the illustration with the addition of a set of context unit u in the illustration the middle hidden layer is connected to these context unit fixed with a weight of one at each time step the input is fed forward and a learning rule is applied the fixed backconnections save a copy of the previous value of the hidden unit in the context unit since they propagate over the connection before the learning rule is applied thus the network can maintain a sort of state allowing it to perform such task a sequenceprediction that are beyond the power of a standard multilayer perceptronnjordan network are similar to elman network the context unit are fed from the output layer instead of the hidden layer the context unit in a jordan network are also called the state layer they have a recurrent connection to themselvesnelman and jordan network are also known a simple recurrent network srnnnelman networknn n n n n n n n n hn n tn n n n n n n n n n hn n n n n wn n hn n n n xn n tn n n n n un n hn n n n hn n tn n n n n n n bn n hn n n n n n n n n yn n tn n n n n n n n n n yn n n n n wn n yn n n n hn n tn n n n n bn n yn n n n n n n n n n displaystyle beginalignedhtsigma hwhxtuhhtbhytsigma ywyhtbyendalignedn nnjordan networknn n n n n n n n n hn n tn n n n n n n n n n hn n n n n wn n hn n n n xn n tn n n n n un n hn n n n yn n tn n n n n n n bn n hn n n n n n n n n yn n tn n n n n n n n n n yn n n n n wn n yn n n n hn n tn n n n n bn n yn n n n n n n n n n displaystyle beginalignedhtsigma hwhxtuhytbhytsigma ywyhtbyendalignedn nnvariables and functionsnn n n n n xn n tn n n n n displaystyle xtn n input vectornn n n n n hn n tn n n n n displaystyle htn n hidden layer vectornn n n n n yn n tn n n n n displaystyle ytn n output vectornn n n n wn n n displaystyle wn n n n n n un n n displaystyle un n and n n n n bn n n displaystyle bn n parameter matrix and vectornn n n n n n n hn n n n n displaystyle sigma hn n and n n n n n n n yn n n n n displaystyle sigma yn n activation functionsnnn hopfield nnthe hopfield network is an rnn in which all connection across layer are equally sized it requires stationary input and is thus not a general rnn a it doe not process sequence of pattern however it guarantee that it will converge if the connection are trained using hebbian learning then the hopfield network can perform a robust contentaddressable memory resistant to connection alterationnnn bidirectional associative memory nnintroduced by bart kosko a bidirectional associative memory bam network is a variant of a hopfield network that store associative data a a vector the bidirectionality come from passing information through a matrix and it transpose typically bipolar encoding is preferred to binary encoding of the associative pair recently stochastic bam model using markov stepping were optimized for increased network stability and relevance to realworld applicationsna bam network ha two layer either of which can be driven a an input to recall an association and produce an output on the other layernnn echo state nnecho state network esn have a sparsely connected random hidden layer the weight of output neuron are the only part of the network that can change be trained esns are good at reproducing certain time series a variant for spiking neuron is known a a liquid state machinennn independently rnn indrnn nthe independently recurrent neural network indrnn address the gradient vanishing and exploding problem in the traditional fully connected rnn each neuron in one layer only receives it own past state a context information instead of full connectivity to all other neuron in this layer and thus neuron are independent of each others history the gradient backpropagation can be regulated to avoid gradient vanishing and exploding in order to keep long or shortterm memory the crossneuron information is explored in the next layer indrnn can be robustly trained with nonsaturated nonlinear function such a relu deep network can be trained using skip connectionsnnn recursive nna recursive neural network is created by applying the same set of weight recursively over a differentiable graphlike structure by traversing the structure in topological order such network are typically also trained by the reverse mode of automatic differentiation they can process distributed representation of structure such a logical term a special case of recursive neural network is the rnn whose structure corresponds to a linear chain recursive neural network have been applied to natural language processing the recursive neural tensor network us a tensorbased composition function for all node in the treennn neural history compressor nthe neural history compressor is an unsupervised stack of rnns at the input level it learns to predict it next input from the previous input only unpredictable input of some rnn in the hierarchy become input to the next higher level rnn which therefore recomputes it internal state only rarely each higher level rnn thus study a compressed representation of the information in the rnn below this is done such that the input sequence can be precisely reconstructed from the representation at the highest levelnthe system effectively minimizes the description length or the negative logarithm of the probability of the data given a lot of learnable predictability in the incoming data sequence the highest level rnn can use supervised learning to easily classify even deep sequence with long interval between important eventsnit is possible to distill the rnn hierarchy into two rnns the conscious chunker higher level and the subconscious automatizer lower level once the chunker ha learned to predict and compress input that are unpredictable by the automatizer then the automatizer can be forced in the next learning phase to predict or imitate through additional unit the hidden unit of the more slowly changing chunker this make it easy for the automatizer to learn appropriate rarely changing memory across long interval in turn this help the automatizer to make many of it once unpredictable input predictable such that the chunker can focus on the remaining unpredictable eventsna generative model partially overcame the vanishing gradient problem of automatic differentiation or backpropagation in neural network in in such a system solved a very deep learning task that required more than subsequent layer in an rnn unfolded in timennn second order rnns nsecondorder rnns use higher order weight n n n n wn n nn n n in jn kn n n n n displaystyle wijkn n instead of the standard n n n n wn n nn n n in jn n n n n displaystyle wijn n weight and state can be a product this allows a direct mapping to a finitestate machine both in training stability and representation long shortterm memory is an example of this but ha no such formal mapping or proof of stabilitynnn long shortterm memory nnlong shortterm memory lstm is a deep learning system that avoids the vanishing gradient problem lstm is normally augmented by recurrent gate called forget gate lstm prevents backpropagated error from vanishing or exploding instead error can flow backward through unlimited number of virtual layer unfolded in space that is lstm can learn task that require memory of event that happened thousand or even million of discrete time step earlier problemspecific lstmlike topology can be evolved lstm work even given long delay between significant event and can handle signal that mix low and highfrequency componentsnmany application use stack of lstm rnns and train them by connectionist temporal classification ctc to find an rnn weight matrix that maximizes the probability of the label sequence in a training set given the corresponding input sequence ctc achieves both alignment and recognitionnlstm can learn to recognize contextsensitive language unlike previous model based on hidden markov model hmm and similar conceptsnnn gated recurrent unit nngated recurrent unit grus are a gating mechanism in recurrent neural network introduced in they are used in the full form and several simplified variant their performance on polyphonic music modeling and speech signal modeling wa found to be similar to that of long shortterm memory they have fewer parameter than lstm a they lack an output gatennn bidirectional nnbidirectional rnns use a finite sequence to predict or label each element of the sequence based on the element past and future context this is done by concatenating the output of two rnns one processing the sequence from left to right and the other one from right to left the combined output are the prediction of the teachergiven target signal this technique ha been proven to be especially useful when combined with lstm rnnsnnn continuoustime na continuoustime recurrent neural network ctrnn us a system of ordinary differential equation to model the effect on a neuron of the incoming inputsnfor a neuron n n n n in n n displaystyle in n in the network with activation n n n n n yn n in n n n n displaystyle yin n the rate of change of activation is given bynn n n n n n n in n n n n n n yn n n n n n in n n n n n yn n in n n n n n n jn n n n n nn n n n wn n jn in n n n n n yn n jn n n n n n n jn n n n n n in n in n n n tn n n n displaystyle tau idot yiyisum jnwjisigma yjtheta jiitn nnwherenn n n n n n n in n n n n displaystyle tau in n time constant of postsynaptic nodenn n n n n yn n in n n n n displaystyle yin n activation of postsynaptic nodenn n n n n n n n yn n n n n n in n n n n displaystyle dot yin n rate of change of activation of postsynaptic nodenn n n n wn n nn n n jn in n n n n displaystyle wjin n weight of connection from pre to postsynaptic nodenn n n n n n xn n n n displaystyle sigma xn n sigmoid of x eg n n n n n n xn n n n n n n n n n n en n n xn n n n n n displaystyle sigma xexn nnn n n n n yn n jn n n n n displaystyle yjn n activation of presynaptic nodenn n n n n n n jn n n n n displaystyle theta jn n bias of presynaptic nodenn n n n n in n in n n n tn n n n displaystyle iitn n input if any to nodenctrnns have been applied to evolutionary robotics where they have been used to address vision cooperation and minimal cognitive behaviournnote that by the shannon sampling theorem discretetime recurrent neural network can be viewed a continuoustime recurrent neural network where the differential equation have transformed into equivalent difference equation this transformation can be thought of a occurring after the postsynaptic node activation function n n n n n yn n in n n n tn n n n displaystyle yitn n have been lowpass filtered but prior to samplingnnn hierarchical recurrent neural network nhierarchical recurrent neural network hrnn connect their neuron in various way to decompose hierarchical behavior into useful subprogram such hierarchical structure of cognition are present in theory of memory presented by philosopher henri bergson whose philosophical view have inspired hierarchical modelsnhierarchical recurrent neural network are useful in forecasting helping to predict disaggregated inflation component of the consumer price index cpi the hrnn model leverage information from higher level in the cpi hierarchy to enhance lowerlevel prediction evaluation of a substantial dataset from the u cpiu index demonstrates the superior performance of the hrnn model compared to various established inflation prediction methodsnnn recurrent multilayer perceptron network ngenerally a recurrent multilayer perceptron network rmlp network consists of cascaded subnetworks each containing multiple layer of node each subnetwork is feedforward except for the last layer which can have feedback connection each of these subnets is connected only by feedforward connectionsnnn multiple timescales model na multiple timescales recurrent neural network mtrnn is a neuralbased computational model that can simulate the functional hierarchy of the brain through selforganization depending on the spatial connection between neuron and on distinct type of neuron activity each with distinct time property with such varied neuronal activity continuous sequence of any set of behavior are segmented into reusable primitive which in turn are flexibly integrated into diverse sequential behavior the biological approval of such a type of hierarchy wa discussed in the memoryprediction theory of brain function by hawkins in his book on intelligence such a hierarchy also agrees with theory of memory posited by philosopher henri bergson which have been incorporated into an mtrnn modelnnn neural turing machine nnneural turing machine ntms are a method of extending recurrent neural network by coupling them to external memory resource which they can interact with by attentional process the combined system is analogous to a turing machine or von neumann architecture but is differentiable endtoend allowing it to be efficiently trained with gradient descentnnn differentiable neural computer nndifferentiable neural computer dncs are an extension of neural turing machine allowing for the usage of fuzzy amount of each memory address and a record of chronologynnn neural network pushdown automaton nneural network pushdown automaton nnpda are similar to ntms but tape are replaced by analog stack that are differentiable and trained in this way they are similar in complexity to recognizers of context free grammar cfgsnnn memristive network ngreg snider of hp lab describes a system of cortical computing with memristive nanodevices the memristors memory resistor are implemented by thin film material in which the resistance is electrically tuned via the transport of ion or oxygen vacancy within the film darpa synapse project ha funded ibm research and hp lab in collaboration with the boston university department of cognitive and neural system cns to develop neuromorphic architecture that may be based on memristive systemsnmemristive network are a particular type of physical neural network that have very similar property to littlehopfield network a they have continuous dynamic a limited memory capacity and natural relaxation via the minimization of a function which is asymptotic to the ising model in this sense the dynamic of a memristive circuit have the advantage compared to a resistorcapacitor network to have a more interesting nonlinear behavior from this point of view engineering analog memristive network account for a peculiar type of neuromorphic engineering in which the device behavior depends on the circuit wiring or topologynthe evolution of these network can be studied analytically using variation of the caravellitraversadi ventra equationnnn pseudocode ngiven a time series x of length sequencelengthnin the recurrent neural network there is a loop that process all entry of the time series x through the layer neuralnetwork one after another these have a return value in each time step i both the prediction ypredi and an updated hidden state hidden which ha the length hiddensize a a result after the loop the collection of all prediction ypred is returnednthe following pseudocode based on the programming language python illustrates the functionality of a recurrent neural networknnmodern library provide runtimeoptimized implementation of the above functionality or allow to speed up the slow loop by justintime compilationnnn training nnn gradient descent nngradient descent is a firstorder iterative optimization algorithm for finding the minimum of a function in neural network it can be used to minimize the error term by changing each weight in proportion to the derivative of the error with respect to that weight provided the nonlinear activation function are differentiable various method for doing so were developed in the s and early s by werbos williams robinson schmidhuber hochreiter pearlmutter and othersnthe standard method is called backpropagation through time or bptt and is a generalization of backpropagation for feedforward network like that method it is an instance of automatic differentiation in the reverse accumulation mode of pontryagins minimum principle a more computationally expensive online variant is called realtime recurrent learning or rtrl which is an instance of automatic differentiation in the forward accumulation mode with stacked tangent vector unlike bptt this algorithm is local in time but not local in spacenin this context local in space mean that a unit weight vector can be updated using only information stored in the connected unit and the unit itself such that update complexity of a single unit is linear in the dimensionality of the weight vector local in time mean that the update take place continually online and depend only on the most recent time step rather than on multiple time step within a given time horizon a in bptt biological neural network appear to be local with respect to both time and spacenfor recursively computing the partial derivative rtrl ha a timecomplexity of onumber of hidden x number of weight per time step for computing the jacobian matrix while bptt only take onumber of weight per time step at the cost of storing all forward activation within the given time horizon an online hybrid between bptt and rtrl with intermediate complexity exists along with variant for continuous timena major problem with gradient descent for standard rnn architecture is that error gradient vanish exponentially quickly with the size of the time lag between important event lstm combined with a bpttrtrl hybrid learning method attempt to overcome these problem this problem is also solved in the independently recurrent neural network indrnn by reducing the context of a neuron to it own past state and the crossneuron information can then be explored in the following layer memory of different range including longterm memory can be learned without the gradient vanishing and exploding problemnthe online algorithm called causal recursive backpropagation crbp implement and combine bptt and rtrl paradigm for locally recurrent network it work with the most general locally recurrent network the crbp algorithm can minimize the global error term this fact improves the stability of the algorithm providing a unifying view of gradient calculation technique for recurrent network with local feedbacknone approach to gradient information computation in rnns with arbitrary architecture is based on signalflow graph diagrammatic derivation it us the bptt batch algorithm based on lee theorem for network sensitivity calculation it wa proposed by wan and beaufays while it fast online version wa proposed by campolucci uncini and piazzannn global optimization method ntraining the weight in a neural network can be modeled a a nonlinear global optimization problem a target function can be formed to evaluate the fitness or error of a particular weight vector a follows first the weight in the network are set according to the weight vector next the network is evaluated against the training sequence typically the sumsquared difference between the prediction and the target value specified in the training sequence is used to represent the error of the current weight vector arbitrary global optimization technique may then be used to minimize this target functionnthe most common global optimization method for training rnns is genetic algorithm especially in unstructured networksninitially the genetic algorithm is encoded with the neural network weight in a predefined manner where one gene in the chromosome represents one weight link the whole network is represented a a single chromosome the fitness function is evaluated a followsnneach weight encoded in the chromosome is assigned to the respective weight link of the networknthe training set is presented to the network which propagates the input signal forwardnthe meansquared error is returned to the fitness functionnthis function drive the genetic selection processnmany chromosome make up the population therefore many different neural network are evolved until a stopping criterion is satisfied a common stopping scheme is nnwhen the neural network ha learned a certain percentage of the training data ornwhen the minimum value of the meansquarederror is satisfied ornwhen the maximum number of training generation ha been reachednthe fitness function evaluates the stopping criterion a it receives the meansquared error reciprocal from each network during training therefore the goal of the genetic algorithm is to maximize the fitness function reducing the meansquared errornother global andor evolutionary optimization technique may be used to seek a good set of weight such a simulated annealing or particle swarm optimizationnnn related field and model nrnns may behave chaotically in such case dynamical system theory may be used for analysisnthey are in fact recursive neural network with a particular structure that of a linear chain whereas recursive neural network operate on any hierarchical structure combining child representation into parent representation recurrent neural network operate on the linear progression of time combining the previous time step and a hidden representation into the representation for the current time stepnin particular rnns can appear a nonlinear version of finite impulse response and infinite impulse response filter and also a a nonlinear autoregressive exogenous model narxnthe effect of memorybased learning for the recognition of sequence can also be implemented by a more biologicalbased model which us the silencing mechanism exhibited in neuron with a relatively high frequency spiking activitynnn library napache singancaffe created by the berkeley vision and learning center bvlc it support both cpu and gpu developed in c and ha python and matlab wrappersnchainer fully in python production support for cpu gpu distributed trainingndeeplearningj deep learning in java and scala on multigpuenabled sparknflux includes interface for rnns including grus and lstms written in juliankeras highlevel api providing a wrapper to many other deep learning librariesnmicrosoft cognitive toolkitnmxnet an opensource deep learning framework used to train and deploy deep neural networksnpytorch tensor and dynamic neural network in python with gpu accelerationntensorflow apache licensed theanolike library with support for cpu gpu and google proprietary tpu mobilentheano a deeplearning library for python with an api largely compatible with the numpy libraryntorch a scientific computing framework with support for machine learning algorithm written in c and luannn application napplications of recurrent neural network includennmachine translationnrobot controlntime series predictionnspeech recognitionnspeech synthesisnbraincomputer interfacesntime series anomaly detectionntexttovideo modelnrhythm learningnmusic compositionngrammar learningnhandwriting recognitionnhuman action recognitionnprotein homology detectionnpredicting subcellular localization of proteinsnseveral prediction task in the area of business process managementnprediction in medical care pathwaysnpredictions of fusion plasma disruption in reactor fusion recurrent neural network frnn code nnn reference nnn further reading nmandic danilo p chamber jonathon a recurrent neural network for prediction learning algorithm architecture and stability wiley isbn nnn external link nrecurrent neural network with over rnn paper by jrgen schmidhubers group at dalle molle institute for artificial intelligence researchnelman neural network implementation for weka',\n",
              " 'convolutional neural network cnn is a regularized type of feedforward neural network that learns feature engineering by itself via filter or kernel optimization vanishing gradient and exploding gradient seen during backpropagation in earlier neural network are prevented by using regularized weight over fewer connection for example for each neuron in the fullyconnected layer weight would be required for processing an image sized pixel however applying cascaded convolution or crosscorrelation kernel only neuron are required to process xsized tile higherlayer feature are extracted from wider context window compared to lowerlayer featuresnthey have application in nnimage and video recognitionnrecommender systemsnnimage classificationnnimage segmentationnnmedical image analysisnnnatural language processingnnbraincomputer interface andnnfinancial time seriesncnns are also known a shift invariant or space invariant artificial neural network siann based on the sharedweight architecture of the convolution kernel or filter that slide along input feature and provide translationequivariant response known a feature map counterintuitively most convolutional neural network are not invariant to translation due to the downsampling operation they apply to the inputnfeedforward neural network are usually fully connected network that is each neuron in one layer is connected to all neuron in the next layer the full connectivity of these network make them prone to overfitting data typical way of regularization or preventing overfitting include penalizing parameter during training such a weight decay or trimming connectivity skipped connection dropout etc robust datasets also increase the probability that cnns will learn the generalized principle that characterize a given dataset rather than the bias of a poorlypopulated setnconvolutional network were inspired by biological process in that the connectivity pattern between neuron resembles the organization of the animal visual cortex individual cortical neuron respond to stimulus only in a restricted region of the visual field known a the receptive field the receptive field of different neuron partially overlap such that they cover the entire visual fieldncnns use relatively little preprocessing compared to other image classification algorithm this mean that the network learns to optimize the filter or kernel through automated learning whereas in traditional algorithm these filter are handengineered this independence from prior knowledge and human intervention in feature extraction is a major advantagennn architecture nna convolutional neural network consists of an input layer hidden layer and an output layer in a convolutional neural network the hidden layer include one or more layer that perform convolution typically this includes a layer that performs a dot product of the convolution kernel with the layer input matrix this product is usually the frobenius inner product and it activation function is commonly relu a the convolution kernel slide along the input matrix for the layer the convolution operation generates a feature map which in turn contributes to the input of the next layer this is followed by other layer such a pooling layer fully connected layer and normalization layersnhere it should be noted how close a convolutional neural network is to a matched filternnn convolutional layer nin a cnn the input is a tensor with shapennumber of input input height input width input channelsnafter passing through a convolutional layer the image becomes abstracted to a feature map also called an activation map with shapennumber of input feature map height feature map width feature map channelsnconvolutional layer convolve the input and pas it result to the next layer this is similar to the response of a neuron in the visual cortex to a specific stimulus each convolutional neuron process data only for it receptive field nnalthough fully connected feedforward neural network can be used to learn feature and classify data this architecture is generally impractical for larger input eg highresolution image which would require massive number of neuron because each pixel is a relevant input feature a fully connected layer for an image of size ha weight for each neuron in the second layer convolution reduces the number of free parameter allowing the network to be deeper for example using a tiling region each with the same shared weight requires only neuron using regularized weight over fewer parameter avoids the vanishing gradient and exploding gradient problem seen during backpropagation in earlier neural networksnto speed processing standard convolutional layer can be replaced by depthwise separable convolutional layer which are based on a depthwise convolution followed by a pointwise convolution the depthwise convolution is a spatial convolution applied independently over each channel of the input tensor while the pointwise convolution is a standard convolution restricted to the use of n n n n n n n n n displaystyle time n n kernelsnnn pooling layer nconvolutional network may include local andor global pooling layer along with traditional convolutional layer pooling layer reduce the dimension of data by combining the output of neuron cluster at one layer into a single neuron in the next layer local pooling combine small cluster tiling size such a are commonly used global pooling act on all the neuron of the feature map there are two common type of pooling in popular use max and average max pooling us the maximum value of each local cluster of neuron in the feature map while average pooling take the average valuennn fully connected layer nfully connected layer connect every neuron in one layer to every neuron in another layer it is the same a a traditional multilayer perceptron neural network mlp the flattened matrix go through a fully connected layer to classify the imagesnnn receptive field nin neural network each neuron receives input from some number of location in the previous layer in a convolutional layer each neuron receives input from only a restricted area of the previous layer called the neuron receptive field typically the area is a square eg by neuron whereas in a fully connected layer the receptive field is the entire previous layer thus in each convolutional layer each neuron take input from a larger area in the input than previous layer this is due to applying the convolution over and over which take the value of a pixel into account a well a it surrounding pixel when using dilated layer the number of pixel in the receptive field remains constant but the field is more sparsely populated a it dimension grow when combining the effect of several layersnto manipulate the receptive field size a desired there are some alternative to the standard convolutional layer for example atrous or dilated convolution expands the receptive field size without increasing the number of parameter by interleaving visible and blind region moreover a single dilated convolutional layer can comprise filter with multiple dilation ratio thus having a variable receptive field sizennn weight neach neuron in a neural network computes an output value by applying a specific function to the input value received from the receptive field in the previous layer the function that is applied to the input value is determined by a vector of weight and a bias typically real number learning consists of iteratively adjusting these bias and weightsnthe vector of weight and bias are called filter and represent particular feature of the input eg a particular shape a distinguishing feature of cnns is that many neuron can share the same filter this reduces the memory footprint because a single bias and a single vector of weight are used across all receptive field that share that filter a opposed to each receptive field having it own bias and vector weightingnnn history ncnn are often compared to the way the brain achieves vision processing in living organismsnnn receptive field in the visual cortex nwork by hubel and wiesel in the s and s showed that cat visual cortex contain neuron that individually respond to small region of the visual field provided the eye are not moving the region of visual space within which visual stimulus affect the firing of a single neuron is known a it receptive field neighboring cell have similar and overlapping receptive field receptive field size and location varies systematically across the cortex to form a complete map of visual space the cortex in each hemisphere represents the contralateral visual fieldntheir paper identified two basic visual cell type in the brainnnsimple cell whose output is maximized by straight edge having particular orientation within their receptive fieldncomplex cell which have larger receptive field whose output is insensitive to the exact position of the edge in the fieldnhubel and wiesel also proposed a cascading model of these two type of cell for use in pattern recognition tasksnnn neocognitron origin of the cnn architecture nthe neocognitron wa introduced by kunihiko fukushima in nit wa inspired by the abovementioned work of hubel and wiesel the neocognitron introduced the two basic type of layer in cnnsnna convolutional layer which contains unit whose receptive field cover a patch of the previous layer the weight vector the set of adaptive parameter of such a unit is often called a filter unit can share filtersndownsampling layer which contain unit whose receptive field cover patch of previous convolutional layer such a unit typically computes the average of the activation of the unit in it patch this downsampling help to correctly classify object in visual scene even when the object are shiftednin kunihiko fukushima also introduced the relu rectified linear unit activation function the rectifier ha become the most popular activation function for cnns and deep neural network in generalnin a variant of the neocognitron called the cresceptron instead of using fukushimas spatial averaging j weng et al in introduced a method called maxpooling where a downsampling unit computes the maximum of the activation of the unit in it patch maxpooling is often used in modern cnnsnseveral supervised and unsupervised learning algorithm have been proposed over the decade to train the weight of a neocognitron today however the cnn architecture is usually trained through backpropagationnthe neocognitron is the first cnn which requires unit located at multiple network position to have shared weightsnconvolutional neural network were presented at the neural information processing workshop in automatically analyzing timevarying signal by replacing learned multiplication with convolution in time and demonstrated for speech recognitionnnn time delay neural network nthe time delay neural network tdnn wa introduced in by alex waibel et al for phoneme recognition and wa one of the first convolutional network a it achieved shiftinvariance a tdnn is a d convolutional neural net where the convolution is performed along the time axis of the data it is the first cnn utilizing weight sharing in combination with a training by gradient descent using backpropagation thus while also using a pyramidal structure a in the neocognitron it performed a global optimization of the weight instead of a local onentdnns are convolutional network that share weight along the temporal dimension they allow speech signal to be processed timeinvariantly in hampshire and waibel introduced a variant that performs a twodimensional convolution since these tdnns operated on spectrogram the resulting phoneme recognition system wa invariant to both time and frequency shift this inspired translation invariance in image processing with cnns the tiling of neuron output can cover timed stagesntdnns now achieve the best performance in fardistance speech recognitionnnn max pooling nin yamaguchi et al introduced the concept of max pooling a fixed filtering operation that calculates and propagates the maximum value of a given region they did so by combining tdnns with max pooling to realize a speakerindependent isolated word recognition system in their system they used several tdnns per word one for each syllable the result of each tdnn over the input signal were combined using max pooling and the output of the pooling layer were then passed on to network performing the actual word classificationnnn image recognition with cnns trained by gradient descent ndenker et al designed a d cnn system to recognize handwritten zip code number however the lack of an efficient training method to determine the kernel coefficient of the involved convolution meant that all the coefficient had to be laboriously handdesignednfollowing the advance in the training of d cnns by waibel et al yann lecun et al used backpropagation to learn the convolution kernel coefficient directly from image of handwritten number learning wa thus fully automatic performed better than manual coefficient design and wa suited to a broader range of image recognition problem and image type nwei zhang et al used backpropagation to train the convolution kernel of a cnn for alphabet recognition the model wa called shiftinvariant artificial neural network siann before the name cnn wa coined later in the early s wei zhang et al also applied the same cnn without the last fully connected layer for medical image object segmentation and breast cancer detection in mammogram nthis approach became a foundation of modern computer visionnnn lenet nnlenet a pioneering level convolutional network by lecun et al in that classifies digit wa applied by several bank to recognize handwritten number on check british english cheque digitized in x pixel image the ability to process higherresolution image requires larger and more layer of convolutional neural network so this technique is constrained by the availability of computing resourcesnnn shiftinvariant neural network na shiftinvariant neural network wa proposed by wei zhang et al for image character recognition in it is a modified neocognitron by keeping only the convolutional interconnection between the image feature layer and the last fully connected layer the model wa trained with backpropagation the training algorithm wa further improved in to improve it generalization ability the model architecture wa modified by removing the last fully connected layer and applied for medical image segmentation and automatic detection of breast cancer in mammogram na different convolutionbased design wa proposed in for application to decomposition of onedimensional electromyography convolved signal via deconvolution this design wa modified in to other deconvolutionbased designsnnn neural abstraction pyramid nnthe feedforward architecture of convolutional neural network wa extended in the neural abstraction pyramid by lateral and feedback connection the resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguity in contrast to previous model imagelike output at the highest resolution were generated eg for semantic segmentation image reconstruction and object localization tasksnnn gpu implementation nalthough cnns were invented in the s their breakthrough in the s required fast implementation on graphic processing unit gpusnin it wa shown by k s oh and k jung that standard neural network can be greatly accelerated on gpus their implementation wa time faster than an equivalent implementation on cpu in another paper also emphasised the value of gpgpu for machine learningnthe first gpuimplementation of a cnn wa described in by k chellapilla et al their implementation wa time faster than an equivalent implementation on cpu subsequent work also used gpus initially for other type of neural network different from cnns especially unsupervised neural networksnin dan ciresan et al at idsia showed that even deep standard neural network with many layer can be quickly trained on gpu by supervised learning through the old method known a backpropagation their network outperformed previous machine learning method on the mnist handwritten digit benchmark in they extended this gpu approach to cnns achieving an acceleration factor of with impressive result in they used such cnns on gpu to win an image recognition contest where they achieved superhuman performance for the first time between may and september their cnns won no le than four image competition in they also significantly improved on the best performance in the literature for multiple image database including the mnist database the norb database the hwdb dataset chinese character and the cifar dataset dataset of x labeled rgb imagesnsubsequently a similar gpubased cnn by alex krizhevsky et al won the imagenet large scale visual recognition challenge a very deep cnn with over layer by microsoft won the imagenet contestnnn intel xeon phi implementation ncompared to the training of cnns using gpus not much attention wa given to the intel xeon phi coprocessorna notable development is a parallelization method for training convolutional neural network on the intel xeon phi named controlled hogwild with arbitrary order of synchronization chaosnchaos exploit both the thread and simdlevel parallelism that is available on the intel xeon phinnn distinguishing feature nin the past traditional multilayer perceptron mlp model were used for image recognition however the full connectivity between node caused the curse of dimensionality and wa computationally intractable with higherresolution image a pixel image with rgb color channel ha million weight per fullyconnected neuron which is too high to feasibly process efficiently at scalennfor example in cifar image are only of size wide high color channel so a single fully connected neuron in the first hidden layer of a regular neural network would have weight a image however would lead to neuron that have weightsnalso such network architecture doe not take into account the spatial structure of data treating input pixel which are far apart in the same way a pixel that are close together this ignores locality of reference in data with a gridtopology such a image both computationally and semantically thus full connectivity of neuron is wasteful for purpose such a image recognition that are dominated by spatially local input patternsnconvolutional neural network are variant of multilayer perceptrons designed to emulate the behavior of a visual cortex these model mitigate the challenge posed by the mlp architecture by exploiting the strong spatially local correlation present in natural image a opposed to mlps cnns have the following distinguishing featuresnnd volume of neuron the layer of a cnn have neuron arranged in dimension width height and depth where each neuron inside a convolutional layer is connected to only a small region of the layer before it called a receptive field distinct type of layer both locally and completely connected are stacked to form a cnn architecturenlocal connectivity following the concept of receptive field cnns exploit spatial locality by enforcing a local connectivity pattern between neuron of adjacent layer the architecture thus ensures that the learned filter produce the strongest response to a spatially local input pattern stacking many such layer lead to nonlinear filter that become increasingly global ie responsive to a larger region of pixel space so that the network first creates representation of small part of the input then from them assembles representation of larger areasnshared weight in cnns each filter is replicated across the entire visual field these replicated unit share the same parameterization weight vector and bias and form a feature map this mean that all the neuron in a given convolutional layer respond to the same feature within their specific response field replicating unit in this way allows for the resulting activation map to be equivariant under shift of the location of input feature in the visual field ie they grant translational equivariance given that the layer ha a stride of onenpooling in a cnns pooling layer feature map are divided into rectangular subregions and the feature in each rectangle are independently downsampled to a single value commonly by taking their average or maximum value in addition to reducing the size of feature map the pooling operation grant a degree of local translational invariance to the feature contained therein allowing the cnn to be more robust to variation in their positionsntogether these property allow cnns to achieve better generalization on vision problem weight sharing dramatically reduces the number of free parameter learned thus lowering the memory requirement for running the network and allowing the training of larger more powerful networksnnn building block nna cnn architecture is formed by a stack of distinct layer that transform the input volume into an output volume eg holding the class score through a differentiable function a few distinct type of layer are commonly used these are further discussed belownnn convolutional layer nthe convolutional layer is the core building block of a cnn the layer parameter consist of a set of learnable filter or kernel which have a small receptive field but extend through the full depth of the input volume during the forward pas each filter is convolved across the width and height of the input volume computing the dot product between the filter entry and the input producing a dimensional activation map of that filter a a result the network learns filter that activate when it detects some specific type of feature at some spatial position in the inputnstacking the activation map for all filter along the depth dimension form the full output volume of the convolution layer every entry in the output volume can thus also be interpreted a an output of a neuron that look at a small region in the input each entry in an activation map use the same set of parameter that define the filternselfsupervised learning ha been adapted for use in convolutional layer by using sparse patch with a highmask ratio and a global response normalization layernnn local connectivity nnwhen dealing with highdimensional input such a image it is impractical to connect neuron to all neuron in the previous volume because such a network architecture doe not take the spatial structure of the data into account convolutional network exploit spatially local correlation by enforcing a sparse local connectivity pattern between neuron of adjacent layer each neuron is connected to only a small region of the input volumenthe extent of this connectivity is a hyperparameter called the receptive field of the neuron the connection are local in space along width and height but always extend along the entire depth of the input volume such an architecture ensures that the learned british english learnt filter produce the strongest response to a spatially local input patternnnn spatial arrangement nthree hyperparameters control the size of the output volume of the convolutional layer the depth stride and padding sizennthe depth of the output volume control the number of neuron in a layer that connect to the same region of the input volume these neuron learn to activate for different feature in the input for example if the first convolutional layer take the raw image a input then different neuron along the depth dimension may activate in the presence of various oriented edge or blob of colornstride control how depth column around the width and height are allocated if the stride is then we move the filter one pixel at a time this lead to heavily overlapping receptive field between the column and to large output volume for any integer n n n n sn n n n n n textstyle sn n a stride s mean that the filter is translated s unit at a time per output in practice n n n n sn n n n n textstyle sgeq n n is rare a greater stride mean smaller overlap of receptive field and smaller spatial dimension of the output volumensometimes it is convenient to pad the input with zero or other value such a the average of the region on the border of the input volume the size of this padding is a third hyperparameter padding provides control of the output volume spatial size in particular sometimes it is desirable to exactly preserve the spatial size of the input volume this is commonly referred to a same paddingnthe spatial size of the output volume is a function of the input volume size n n n n wn n n displaystyle wn n the kernel field size n n n n kn n n displaystyle kn n of the convolutional layer neuron the stride n n n n sn n n displaystyle sn n and the amount of zero padding n n n n pn n n displaystyle pn n on the border the number of neuron that fit in a given volume is thennnif this number is not an integer then the stride are incorrect and the neuron cannot be tiled to fit across the input volume in a symmetric way in general setting zero padding to be n n n n pn n n kn n n n n n n n n n textstyle pkn n when the stride is n n n n sn n n n n displaystyle sn n ensures that the input volume and output volume will have the same size spatially however it is not always completely necessary to use all of the neuron of the previous layer for example a neural network designer may decide to use just a portion of paddingnnn parameter sharing na parameter sharing scheme is used in convolutional layer to control the number of free parameter it relies on the assumption that if a patch feature is useful to compute at some spatial position then it should also be useful to compute at other position denoting a single dimensional slice of depth a a depth slice the neuron in each depth slice are constrained to use the same weight and biasnsince all neuron in a single depth slice share the same parameter the forward pas in each depth slice of the convolutional layer can be computed a a convolution of the neuron weight with the input volume therefore it is common to refer to the set of weight a a filter or a kernel which is convolved with the input the result of this convolution is an activation map and the set of activation map for each different filter are stacked together along the depth dimension to produce the output volume parameter sharing contributes to the translation invariance of the cnn architecturensometimes the parameter sharing assumption may not make sense this is especially the case when the input image to a cnn have some specific centered structure for which we expect completely different feature to be learned on different spatial location one practical example is when the input are face that have been centered in the image we might expect different eyespecific or hairspecific feature to be learned in different part of the image in that case it is common to relax the parameter sharing scheme and instead simply call the layer a locally connected layernnn pooling layer nnanother important concept of cnns is pooling which is a form of nonlinear downsampling there are several nonlinear function to implement pooling where max pooling is the most common it partition the input image into a set of rectangle and for each such subregion output the maximumnintuitively the exact location of a feature is le important than it rough location relative to other feature this is the idea behind the use of pooling in convolutional neural network the pooling layer serf to progressively reduce the spatial size of the representation to reduce the number of parameter memory footprint and amount of computation in the network and hence to also control overfitting this is known a downsampling it is common to periodically insert a pooling layer between successive convolutional layer each one typically followed by an activation function such a a relu layer in a cnn architectureuaua while pooling layer contribute to local translation invariance they do not provide global translation invariance in a cnn unless a form of global pooling is used the pooling layer commonly operates independently on every depth or slice of the input and resizes it spatially a very common form of max pooling is a layer with filter of size applied with a stride of which subsamples every depth slice in the input by along both width and height discarding of the activationsnin this case every max operation is over number the depth dimension remains unchanged this is true for other form of pooling a wellnin addition to max pooling pooling unit can use other function such a average pooling or norm pooling average pooling wa often used historically but ha recently fallen out of favor compared to max pooling which generally performs better in practicendue to the effect of fast spatial reduction of the size of the representation there is a recent trend towards using smaller filter or discarding pooling layer altogethernnregion of interest pooling also known a roi pooling is a variant of max pooling in which output size is fixed and input rectangle is a parameternpooling is a downsampling method and an important component of convolutional neural network for object detection based on the fast rcnn architecturennn channel max pooling na cmp operation layer conduct the mp operation along the channel side among the corresponding position of the consecutive feature map for the purpose of redundant information elimination the cmp make the significant feature gather together within fewer channel which is important for finegrained image classification that need more discriminating feature meanwhile another advantage of the cmp operation is to make the channel number of feature map smaller before it connects to the first fully connected fc layer similar to the mp operation we denote the input feature map and output feature map of a cmp layer a f rcmn and c rcmn respectively where c and c are the channel number of the input and output feature map m and n are the width and the height of the feature map respectively note that the cmp operation only change the channel number of the feature map the width and the height of the feature map are not changed which is different from the mp operationnnn relu layer nrelu is the abbreviation of rectified linear unit introduced by kunihiko fukushima in relu applies the nonsaturating activation function n n n n fn n xn n n maxn n n n xn n n n textstyle fxmaxxn n it effectively remove negative value from an activation map by setting them to zero it introduces nonlinearity to the decision function and in the overall network without affecting the receptive field of the convolution layersnin xavier glorot antoine bordes and yoshua bengio found that relu enables better training of deeper network compared to widely used activation function prior to nother function can also be used to increase nonlinearity for example the saturating hyperbolic tangent n n n n fn n xn n n tanhn un n xn n n n displaystyle fxtanhxn n n n n n fn n xn n n n n n tanhn un n xn n n n n n n displaystyle fxtanhxn n and the sigmoid function n n n n n n xn n n n n n n en n n xn n n n n n n n n n n n textstyle sigma xexn n relu is often preferred to other function because it train the neural network several time faster without a significant penalty to generalization accuracynnn fully connected layer nafter several convolutional and max pooling layer the final classification is done via fully connected layer neuron in a fully connected layer have connection to all activation in the previous layer a seen in regular nonconvolutional artificial neural network their activation can thus be computed a an affine transformation with matrix multiplication followed by a bias offset vector addition of a learned or fixed bias termnnn loss layer nnthe loss layer or loss function specifies how training penalizes the deviation between the predicted output of the network and the true data label during supervised learning various loss function can be used depending on the specific tasknthe softmax loss function is used for predicting a single class of k mutually exclusive class sigmoid crossentropy loss is used for predicting k independent probability value in n n n n n n n n n n n displaystyle n n euclidean loss is used for regressing to realvalued label n n n n n n n n n n n n displaystyle infty infty n nnnn hyperparameters nnhyperparameters are various setting that are used to control the learning process cnns use more hyperparameters than a standard multilayer perceptron mlpnnn kernel size nthe kernel is the number of pixel processed together it is typically expressed a the kernel dimension eg x or xnnn padding npadding is the addition of typically valued pixel on the border of an image this is done so that the border pixel are not undervalued lost from the output because they would ordinarily participate in only a single receptive field instance the padding applied is typically one le than the corresponding kernel dimension for example a convolutional layer using x kernel would receive a pixel pad that is pixel on each side of the imagennn stride nthe stride is the number of pixel that the analysis window move on each iteration a stride of mean that each kernel is offset by pixel from it predecessornnn number of filter nsince feature map size decrease with depth layer near the input layer tend to have fewer filter while higher layer can have more to equalize computation at each layer the product of feature value va with pixel position is kept roughly constant across layer preserving more information about the input would require keeping the total number of activation number of feature map time number of pixel position nondecreasing from one layer to the nextnthe number of feature map directly control the capacity and depends on the number of available example and task complexitynnn filter size ncommon filter size found in the literature vary greatly and are usually chosen based on the data setnthe challenge is to find the right level of granularity so a to create abstraction at the proper scale given a particular data set and without overfittingnnn pooling type and size nmax pooling is typically used often with a x dimension this implies that the input is drastically downsampled reducing processing costngreater pooling reduces the dimension of the signal and may result in unacceptable information loss often nonoverlapping pooling window perform bestnnn dilation ndilation involves ignoring pixel within a kernel this reduces processingmemory potentially without significant signal loss a dilation of on a x kernel expands the kernel to x while still processing evenly spaced pixel accordingly dilation of expands the kernel to xnnn translation equivariance and aliasing nit is commonly assumed that cnns are invariant to shift of the input convolution or pooling layer within a cnn that do not have a stride greater than one are indeed equivariant to translation of the input however layer with a stride greater than one ignore the nyquistshannon sampling theorem and might lead to aliasing of the input signal while in principle cnns are capable of implementing antialiasing filter it ha been observed that this doe not happen in practice and yield model that are not equivariant to translationsnfurthermore if a cnn make use of fully connected layer translation equivariance doe not imply translation invariance a the fully connected layer are not invariant to shift of the input one solution for complete translation invariance is avoiding any downsampling throughout the network and applying global average pooling at the last layer additionally several other partial solution have been proposed such a antialiasing before downsampling operation spatial transformer network data augmentation subsampling combined with pooling and capsule neural networksnnn evaluation nthe accuracy of the final model is based on a subpart of the dataset set apart at the start often called a testset other time method such a kfold crossvalidation are applied other strategy include using conformal predictionnnn regularization method nnregularization is a process of introducing additional information to solve an illposed problem or to prevent overfitting cnns use various type of regularizationnnn empirical nnn dropout nbecause a fully connected layer occupies most of the parameter it is prone to overfitting one method to reduce overfitting is dropout introduced in at each training stage individual node are either dropped out of the net ignored with probability n n n n n n pn n n displaystyle pn n or kept with probability n n n n pn n n displaystyle pn n so that a reduced network is left incoming and outgoing edge to a droppedout node are also removed only the reduced network is trained on the data in that stage the removed node are then reinserted into the network with their original weightsnin the training stage n n n n pn n n displaystyle pn n is usually for input node it is typically much higher because information is directly lost when input node are ignorednat testing time after training ha finished we would ideally like to find a sample average of all possible n n n n n n n nn n n n n displaystyle nn n droppedout network unfortunately this is unfeasible for large value of n n n n nn n n displaystyle nn n however we can find an approximation by using the full network with each node output weighted by a factor of n n n n pn n n displaystyle pn n so the expected value of the output of any node is the same a in the training stage this is the biggest contribution of the dropout method although it effectively generates n n n n n n n nn n n n n displaystyle nn n neural net and a such allows for model combination at test time only a single network need to be testednby avoiding training all node on all training data dropout decrease overfitting the method also significantly improves training speed this make the model combination practical even for deep neural network the technique seems to reduce node interaction leading them to learn more robust feature that better generalize to new datannn dropconnect ndropconnect is the generalization of dropout in which each connection rather than each output unit can be dropped with probability n n n n n n pn n n displaystyle pn n each unit thus receives input from a random subset of unit in the previous layerndropconnect is similar to dropout a it introduces dynamic sparsity within the model but differs in that the sparsity is on the weight rather than the output vector of a layer in other word the fully connected layer with dropconnect becomes a sparsely connected layer in which the connection are chosen at random during the training stagennn stochastic pooling na major drawback to dropout is that it doe not have the same benefit for convolutional layer where the neuron are not fully connectedneven before dropout in a technique called stochastic pooling the conventional deterministic pooling operation were replaced with a stochastic procedure where the activation within each pooling region is picked randomly according to a multinomial distribution given by the activity within the pooling region this approach is free of hyperparameters and can be combined with other regularization approach such a dropout and data augmentationnan alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copy of an input image each having small local deformation this is similar to explicit elastic deformation of the input image which delivers excellent performance on the mnist data set using stochastic pooling in a multilayer model give an exponential number of deformation since the selection in higher layer are independent of those belownnn artificial data nnbecause the degree of model overfitting is determined by both it power and the amount of training it receives providing a convolutional network with more training example can reduce overfitting because there is often not enough available data to train especially considering that some part should be spared for later testing two approach are to either generate new data from scratch if possible or perturb existing data to create new one the latter one is used since mids for example input image can be cropped rotated or rescaled to create new example with the same label a the original training setnnn explicit nnn early stopping nnone of the simplest method to prevent overfitting of a network is to simply stop the training before overfitting ha had a chance to occur it come with the disadvantage that the learning process is haltednnn number of parameter nanother simple way to prevent overfitting is to limit the number of parameter typically by limiting the number of hidden unit in each layer or limiting network depth for convolutional network the filter size also affect the number of parameter limiting the number of parameter restricts the predictive power of the network directly reducing the complexity of the function that it can perform on the data and thus limit the amount of overfitting this is equivalent to a zero normnnn weight decay na simple form of added regularizer is weight decay which simply add an additional error proportional to the sum of weight l norm or squared magnitude l norm of the weight vector to the error at each node the level of acceptable model complexity can be reduced by increasing the proportionality constantalpha hyperparameter thus increasing the penalty for large weight vectorsnl regularization is the most common form of regularization it can be implemented by penalizing the squared magnitude of all parameter directly in the objective the l regularization ha the intuitive interpretation of heavily penalizing peaky weight vector and preferring diffuse weight vector due to multiplicative interaction between weight and input this ha the useful property of encouraging the network to use all of it input a little rather than some of it input a lotnl regularization is also common it make the weight vector sparse during optimization in other word neuron with l regularization end up using only a sparse subset of their most important input and become nearly invariant to the noisy input l with l regularization can be combined this is called elastic net regularizationnnn max norm constraint nanother form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint in practice this corresponds to performing the parameter update a normal and then enforcing the constraint by clamping the weight vector n n n n n n n wn n n n n n n displaystyle vec wn n of every neuron to satisfy n n n n n n n n wn n n n n n n n n n n n cn n n displaystyle vec wcn n typical value of n n n n cn n n displaystyle cn n are order of some paper report improvement when using this form of regularizationnnn hierarchical coordinate frame npooling loses the precise spatial relationship between highlevel part such a nose and mouth in a face image these relationship are needed for identity recognition overlapping the pool so that each feature occurs in multiple pool help retain the information translation alone cannot extrapolate the understanding of geometric relationship to a radically new viewpoint such a a different orientation or scale on the other hand people are very good at extrapolating after seeing a new shape once they can recognize it from a different viewpointnan earlier common way to deal with this problem is to train the network on transformed data in different orientation scale lighting etc so that the network can cope with these variation this is computationally intensive for large datasets the alternative is to use a hierarchy of coordinate frame and use a group of neuron to represent a conjunction of the shape of the feature and it pose relative to the retina the pose relative to the retina is the relationship between the coordinate frame of the retina and the intrinsic feature coordinate framenthus one way to represent something is to embed the coordinate frame within it this allows large feature to be recognized by using the consistency of the pose of their part eg nose and mouth pose make a consistent prediction of the pose of the whole face this approach ensures that the higherlevel entity eg face is present when the lowerlevel eg nose and mouth agree on it prediction of the pose the vector of neuronal activity that represent pose pose vector allow spatial transformation modeled a linear operation that make it easier for the network to learn the hierarchy of visual entity and generalize across viewpoint this is similar to the way the human visual system imposes coordinate frame in order to represent shapesnnn application nnn image recognition ncnns are often used in image recognition system in an error rate of on the mnist database wa reported another paper on using cnn for image classification reported that the learning process wa surprisingly fast in the same paper the best published result a of were achieved in the mnist database and the norb database subsequently a similar cnn callednalexnet won the imagenet large scale visual recognition challenge nwhen applied to facial recognition cnns achieved a large decrease in error rate another paper reported a recognition rate on still image of more than subject cnns were used to ass video quality in an objective way after manual training the resulting system had a very low root mean square errornthe imagenet large scale visual recognition challenge is a benchmark in object classification and detection with million of image and hundred of object class in the ilsvrc a largescale visual recognition challenge almost every highly ranked team used cnn a their basic framework the winner googlenet the foundation of deepdream increased the mean average precision of object detection to and reduced classification error to the best result to date it network applied more than layer that performance of convolutional neural network on the imagenet test wa close to that of human the best algorithm still struggle with object that are small or thin such a a small ant on a stem of a flower or a person holding a quill in their hand they also have trouble with image that have been distorted with filter an increasingly common phenomenon with modern digital camera by contrast those kind of image rarely trouble human human however tend to have trouble with other issue for example they are not good at classifying object into finegrained category such a the particular breed of dog or specie of bird whereas convolutional neural network handle thisnin a manylayered cnn demonstrated the ability to spot face from a wide range of angle including upside down even when partially occluded with competitive performance the network wa trained on a database of image that included face at various angle and orientation and a further million image without face they used batch of image over iterationsnnn video analysis ncompared to image data domain there is relatively little work on applying cnns to video classification video is more complex than image since it ha another temporal dimension however some extension of cnns into the video domain have been explored one approach is to treat space and time a equivalent dimension of the input and perform convolution in both time and space another way is to fuse the feature of two convolutional neural network one for the spatial and one for the temporal stream long shortterm memory lstm recurrent unit are typically incorporated after the cnn to account for interframe or interclip dependency unsupervised learning scheme for training spatiotemporal feature have been introduced based on convolutional gated restricted boltzmann machine and independent subspace analysis it application can be seen in texttovideo modelnnn natural language processing ncnns have also been explored for natural language processing cnn model are effective for various nlp problem and achieved excellent result in semantic parsing search query retrieval sentence modeling classification prediction and other traditional nlp tasksncompared to traditional language processing method such a recurrent neural network cnns can represent different contextual reality of language that do not rely on a seriessequence assumption while rnns are better suitable when classical time series modeling is requirednnn anomaly detection na cnn with d convolution wa used on time series in the frequency domain spectral residual by an unsupervised model to detect anomaly in the time domainnnn drug discovery ncnns have been used in drug discovery predicting the interaction between molecule and biological protein can identify potential treatment in atomwise introduced atomnet the first deep learning neural network for structurebased drug design the system train directly on dimensional representation of chemical interaction similar to how image recognition network learn to compose smaller spatially proximate feature into larger complex structure atomnet discovers chemical feature such a aromaticity sp carbon and hydrogen bonding subsequently atomnet wa used to predict novel candidate biomolecules for multiple disease target most notably treatment for the ebola virus and multiple sclerosisnnn checker game ncnns have been used in the game of checker from to fogel and chellapilla published paper showing how a convolutional neural network could learn to play checker using coevolution the learning process did not use prior human professional game but rather focused on a minimal set of information contained in the checkerboard the location and type of piece and the difference in number of piece between the two side ultimately the program blondie wa tested on game against player and ranked in the highest it also earned a win against the program chinook at it expert level of playnnn go ncnns have been used in computer go in december clark and storkey published a paper showing that a cnn trained by supervised learning from a database of human professional game could outperform gnu go and win some game against monte carlo tree search fuego in a fraction of the time it took fuego to play later it wa announced that a large layer convolutional neural network had correctly predicted the professional move in of position equalling the accuracy of a dan human player when the trained convolutional network wa used directly to play game of go without any search it beat the traditional search program gnu go in of game and matched the performance of the monte carlo tree search program fuego simulating ten thousand playouts about a million position per movena couple of cnns for choosing move to try policy network and evaluating position value network driving mcts were used by alphago the first to beat the best human player at the timennn time series forecasting nrecurrent neural network are generally considered the best neural network architecture for time series forecasting and sequence modeling in general but recent study show that convolutional network can perform comparably or even better dilated convolution might enable onedimensional convolutional neural network to effectively learn time series dependence convolution can be implemented more efficiently than rnnbased solution and they do not suffer from vanishing or exploding gradient convolutional network can provide an improved forecasting performance when there are multiple similar time series to learn from cnns can also be applied to further task in time series analysis eg time series classification or quantile forecastingnnn cultural heritage and ddatasets na archaeological finding like clay tablet with cuneiform writing are increasingly acquired using d scanner first benchmark datasets are becoming available like heicubeda providing almost normalized d and ddatasets prepared with the gigamesh software framework so curvaturebased measure are used in conjunction with geometric neural network gnns eg for period classification of those clay tablet being among the oldest document of human historynnn finetuning nfor many application the training data is le available convolutional neural network usually require a large amount of training data in order to avoid overfitting a common technique is to train the network on a larger data set from a related domain once the network parameter have converged an additional training step is performed using the indomain data to finetune the network weight this is known a transfer learning furthermore this technique allows convolutional network architecture to successfully be applied to problem with tiny training setsnnn human interpretable explanation nendtoend training and prediction are common practice in computer vision however human interpretable explanation are required for critical system such a a selfdriving car with recent advance in visual salience spatial attention and temporal attention the most critical spatial regionstemporal instant could be visualized to justify the cnn predictionsnnn related architecture nnn deep qnetworks na deep qnetwork dqn is a type of deep learning model that combine a deep neural network with qlearning a form of reinforcement learning unlike earlier reinforcement learning agent dqns that utilize cnns can learn directly from highdimensional sensory input via reinforcement learningnpreliminary result were presented in with an accompanying paper in february the research described an application to atari gaming other deep reinforcement learning model preceded itnnn deep belief network nnconvolutional deep belief network cdbn have structure very similar to convolutional neural network and are trained similarly to deep belief network therefore they exploit the d structure of image like cnns do and make use of pretraining like deep belief network they provide a generic structure that can be used in many image and signal processing task benchmark result on standard image datasets like cifar have been obtained using cdbnsnnn notable library ncaffe a library for convolutional neural network created by the berkeley vision and learning center bvlc it support both cpu and gpu developed in c and ha python and matlab wrappersndeeplearningj deep learning in java and scala on multigpuenabled spark a generalpurpose deep learning library for the jvm production stack running on a c scientific computing engine allows the creation of custom layer integrates with hadoop and kafkandlib a toolkit for making real world machine learning and data analysis application in cnmicrosoft cognitive toolkit a deep learning toolkit written by microsoft with several unique feature enhancing scalability over multiple node it support fullfledged interface for training in c and python and with additional support for model inference in c and javantensorflow apache licensed theanolike library with support for cpu gpu google proprietary tensor processing unit tpu and mobile devicesntheano the reference deeplearning library for python with an api largely compatible with the popular numpy library allows user to write symbolic mathematical expression then automatically generates their derivative saving the user from having to code gradient or backpropagation these symbolic expression are automatically compiled to cuda code for a fast onthegpu implementationntorch a scientific computing framework with wide support for machine learning algorithm written in c and luannn see also nattention machine learningnconvolutionndeep learningnnaturallanguage processingnneocognitronnscaleinvariant feature transformntime delay neural networknvision processing unitnnn note nnn reference nnn external link ncsn convolutional neural network for visual recognition andrej karpathys stanford computer science course on cnns in computer vision']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word-Level prediction**"
      ],
      "metadata": {
        "id": "1LLQNoimBokT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(processed_docs)\n",
        "sequences = tokenizer.texts_to_sequences(processed_docs)\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "pmJd1StfL0rX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fPFJ0yRXbHi",
        "outputId": "4bf859d2-54c4-4204-ab25-a3bbf34e3a2f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6363"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = 50\n",
        "\n",
        "def prepare_sequences(sequence, max_seq_length):\n",
        "    input_sequences = []\n",
        "    next_words = []\n",
        "    for i in range(0, len(sequence) - max_seq_length):\n",
        "        input_sequences.append(sequence[i:i + max_seq_length])\n",
        "        next_words.append(sequence[i + max_seq_length])\n",
        "    return input_sequences, next_words\n",
        "\n",
        "# Process each sequence for the entire document set\n",
        "word_sequences = []\n",
        "next_words = []\n",
        "for doc_seq in sequences:\n",
        "    if len(doc_seq) > 50:  # Ensure the sequence is long enough to process\n",
        "        inputs, nexts = prepare_sequences(doc_seq, 50)\n",
        "        word_sequences.extend(inputs)\n",
        "        next_words.extend(nexts)"
      ],
      "metadata": {
        "id": "QjVZq-fIKK9T"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(pad_sequences(word_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "metadata": {
        "id": "JLxt3v32MDsr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "y = to_categorical(next_words, num_classes=len(word_index) + 1)"
      ],
      "metadata": {
        "id": "NISO9tqWS6EZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "HoEatN-UMD0C"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W0uZkOnOElR",
        "outputId": "f35d6d5e-0785-4b5f-bef2-ce62a9555cd7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25805, 50)\n",
            "(17204, 50)\n",
            "(25805, 6364)\n",
            "(17204, 6364)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(word_index) + 1\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=100, input_length=max_sequence_len),\n",
        "    SimpleRNN(100, return_sequences=True),\n",
        "    SimpleRNN(100, return_sequences=True),\n",
        "    SimpleRNN(100),\n",
        "    Dense(num_words, activation='softmax')\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LARaJOwlrG_G",
        "outputId": "324160c7-12c3-49d2-f160-c0c29a7f26bb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 50, 100)           636400    \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 50, 100)           20100     \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, 50, 100)           20100     \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, 100)               20100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6364)              642764    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1339464 (5.11 MB)\n",
            "Trainable params: 1339464 (5.11 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af9EiYL8rM_3",
        "outputId": "03e064bf-83e1-4aa8-fe59-da1acb7e1207"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "503/503 [==============================] - 50s 93ms/step - loss: 8.0751 - accuracy: 0.0280 - val_loss: 7.9982 - val_accuracy: 0.0289\n",
            "Epoch 2/50\n",
            "503/503 [==============================] - 44s 88ms/step - loss: 7.5264 - accuracy: 0.0365 - val_loss: 8.1083 - val_accuracy: 0.0404\n",
            "Epoch 3/50\n",
            "503/503 [==============================] - 48s 96ms/step - loss: 7.2923 - accuracy: 0.0486 - val_loss: 7.9644 - val_accuracy: 0.0484\n",
            "Epoch 4/50\n",
            "503/503 [==============================] - 44s 88ms/step - loss: 6.9170 - accuracy: 0.0554 - val_loss: 8.2345 - val_accuracy: 0.0502\n",
            "Epoch 5/50\n",
            "503/503 [==============================] - 46s 91ms/step - loss: 6.5033 - accuracy: 0.0637 - val_loss: 8.4592 - val_accuracy: 0.0519\n",
            "Epoch 6/50\n",
            "503/503 [==============================] - 47s 94ms/step - loss: 6.0849 - accuracy: 0.0752 - val_loss: 8.7281 - val_accuracy: 0.0502\n",
            "Epoch 7/50\n",
            "503/503 [==============================] - 45s 89ms/step - loss: 5.6792 - accuracy: 0.0904 - val_loss: 8.7932 - val_accuracy: 0.0512\n",
            "Epoch 8/50\n",
            "503/503 [==============================] - 49s 97ms/step - loss: 5.2705 - accuracy: 0.1126 - val_loss: 8.9694 - val_accuracy: 0.0525\n",
            "Epoch 9/50\n",
            "503/503 [==============================] - 45s 90ms/step - loss: 4.8644 - accuracy: 0.1474 - val_loss: 9.1087 - val_accuracy: 0.0504\n",
            "Epoch 10/50\n",
            "503/503 [==============================] - 45s 89ms/step - loss: 4.4433 - accuracy: 0.1972 - val_loss: 9.2796 - val_accuracy: 0.0532\n",
            "Epoch 11/50\n",
            "503/503 [==============================] - 44s 88ms/step - loss: 4.1354 - accuracy: 0.2466 - val_loss: 9.5162 - val_accuracy: 0.0506\n",
            "Epoch 12/50\n",
            "503/503 [==============================] - 46s 91ms/step - loss: 3.7819 - accuracy: 0.3042 - val_loss: 9.6979 - val_accuracy: 0.0513\n",
            "Epoch 13/50\n",
            "503/503 [==============================] - 45s 90ms/step - loss: 3.3201 - accuracy: 0.3995 - val_loss: 9.8822 - val_accuracy: 0.0486\n",
            "Epoch 14/50\n",
            "503/503 [==============================] - 48s 95ms/step - loss: 2.9565 - accuracy: 0.4826 - val_loss: 10.1486 - val_accuracy: 0.0482\n",
            "Epoch 15/50\n",
            "503/503 [==============================] - 45s 89ms/step - loss: 2.6225 - accuracy: 0.5462 - val_loss: 10.3449 - val_accuracy: 0.0478\n",
            "Epoch 16/50\n",
            "503/503 [==============================] - 51s 101ms/step - loss: 2.2847 - accuracy: 0.6149 - val_loss: 10.5673 - val_accuracy: 0.0492\n",
            "Epoch 17/50\n",
            "503/503 [==============================] - 48s 95ms/step - loss: 2.0029 - accuracy: 0.6693 - val_loss: 10.7581 - val_accuracy: 0.0477\n",
            "Epoch 18/50\n",
            "503/503 [==============================] - 48s 96ms/step - loss: 1.7355 - accuracy: 0.7162 - val_loss: 11.0187 - val_accuracy: 0.0479\n",
            "Epoch 19/50\n",
            "503/503 [==============================] - 47s 93ms/step - loss: 1.5407 - accuracy: 0.7530 - val_loss: 11.1936 - val_accuracy: 0.0485\n",
            "Epoch 20/50\n",
            "503/503 [==============================] - 47s 92ms/step - loss: 1.3386 - accuracy: 0.7842 - val_loss: 11.3904 - val_accuracy: 0.0470\n",
            "Epoch 21/50\n",
            "503/503 [==============================] - 44s 87ms/step - loss: 1.1551 - accuracy: 0.8184 - val_loss: 11.5891 - val_accuracy: 0.0457\n",
            "Epoch 22/50\n",
            "503/503 [==============================] - 51s 101ms/step - loss: 1.0578 - accuracy: 0.8323 - val_loss: 11.7976 - val_accuracy: 0.0472\n",
            "Epoch 23/50\n",
            "503/503 [==============================] - 48s 95ms/step - loss: 0.8959 - accuracy: 0.8641 - val_loss: 12.0057 - val_accuracy: 0.0468\n",
            "Epoch 24/50\n",
            "503/503 [==============================] - 45s 90ms/step - loss: 0.7525 - accuracy: 0.8907 - val_loss: 12.1909 - val_accuracy: 0.0465\n",
            "Epoch 25/50\n",
            "503/503 [==============================] - 47s 93ms/step - loss: 0.6260 - accuracy: 0.9147 - val_loss: 12.3634 - val_accuracy: 0.0486\n",
            "Epoch 26/50\n",
            "503/503 [==============================] - 45s 89ms/step - loss: 0.5614 - accuracy: 0.9234 - val_loss: 12.5361 - val_accuracy: 0.0491\n",
            "Epoch 27/50\n",
            "503/503 [==============================] - 50s 100ms/step - loss: 0.4954 - accuracy: 0.9331 - val_loss: 12.6955 - val_accuracy: 0.0484\n",
            "Epoch 28/50\n",
            "503/503 [==============================] - 47s 94ms/step - loss: 0.4527 - accuracy: 0.9405 - val_loss: 12.8656 - val_accuracy: 0.0455\n",
            "Epoch 29/50\n",
            "503/503 [==============================] - 44s 88ms/step - loss: 0.4496 - accuracy: 0.9381 - val_loss: 12.9807 - val_accuracy: 0.0483\n",
            "Epoch 30/50\n",
            "503/503 [==============================] - 50s 100ms/step - loss: 0.4026 - accuracy: 0.9473 - val_loss: 13.2475 - val_accuracy: 0.0476\n",
            "Epoch 31/50\n",
            "503/503 [==============================] - 48s 95ms/step - loss: 0.6219 - accuracy: 0.8851 - val_loss: 13.2838 - val_accuracy: 0.0474\n",
            "Epoch 32/50\n",
            "503/503 [==============================] - 45s 90ms/step - loss: 0.6103 - accuracy: 0.8860 - val_loss: 13.3780 - val_accuracy: 0.0454\n",
            "Epoch 33/50\n",
            "503/503 [==============================] - 46s 91ms/step - loss: 0.4605 - accuracy: 0.9225 - val_loss: 13.4851 - val_accuracy: 0.0452\n",
            "Epoch 34/50\n",
            "503/503 [==============================] - 51s 101ms/step - loss: 0.3154 - accuracy: 0.9580 - val_loss: 13.6559 - val_accuracy: 0.0482\n",
            "Epoch 35/50\n",
            "503/503 [==============================] - 45s 89ms/step - loss: 0.1687 - accuracy: 0.9871 - val_loss: 13.7966 - val_accuracy: 0.0479\n",
            "Epoch 36/50\n",
            "503/503 [==============================] - 49s 98ms/step - loss: 0.1105 - accuracy: 0.9941 - val_loss: 13.9029 - val_accuracy: 0.0479\n",
            "Epoch 37/50\n",
            "503/503 [==============================] - 46s 91ms/step - loss: 0.0831 - accuracy: 0.9962 - val_loss: 14.0292 - val_accuracy: 0.0483\n",
            "Epoch 38/50\n",
            "503/503 [==============================] - 47s 93ms/step - loss: 0.0762 - accuracy: 0.9959 - val_loss: 14.0928 - val_accuracy: 0.0487\n",
            "Epoch 39/50\n",
            "503/503 [==============================] - 49s 98ms/step - loss: 0.5388 - accuracy: 0.8859 - val_loss: 14.0539 - val_accuracy: 0.0454\n",
            "Epoch 40/50\n",
            "503/503 [==============================] - 46s 92ms/step - loss: 0.4598 - accuracy: 0.9111 - val_loss: 14.1470 - val_accuracy: 0.0477\n",
            "Epoch 41/50\n",
            "503/503 [==============================] - 48s 96ms/step - loss: 0.1718 - accuracy: 0.9800 - val_loss: 14.2922 - val_accuracy: 0.0466\n",
            "Epoch 42/50\n",
            "503/503 [==============================] - 50s 99ms/step - loss: 0.2106 - accuracy: 0.9678 - val_loss: 14.3045 - val_accuracy: 0.0495\n",
            "Epoch 43/50\n",
            "503/503 [==============================] - 46s 92ms/step - loss: 0.1406 - accuracy: 0.9854 - val_loss: 14.4669 - val_accuracy: 0.0492\n",
            "Epoch 44/50\n",
            "503/503 [==============================] - 48s 95ms/step - loss: 0.0691 - accuracy: 0.9966 - val_loss: 14.5484 - val_accuracy: 0.0495\n",
            "Epoch 45/50\n",
            "503/503 [==============================] - 47s 93ms/step - loss: 0.0419 - accuracy: 0.9976 - val_loss: 14.6385 - val_accuracy: 0.0487\n",
            "Epoch 46/50\n",
            "503/503 [==============================] - 50s 99ms/step - loss: 0.0307 - accuracy: 0.9986 - val_loss: 14.7216 - val_accuracy: 0.0493\n",
            "Epoch 47/50\n",
            "503/503 [==============================] - 45s 90ms/step - loss: 0.0253 - accuracy: 0.9990 - val_loss: 14.7888 - val_accuracy: 0.0506\n",
            "Epoch 48/50\n",
            "503/503 [==============================] - 45s 90ms/step - loss: 0.2284 - accuracy: 0.9506 - val_loss: 14.6511 - val_accuracy: 0.0450\n",
            "Epoch 49/50\n",
            "503/503 [==============================] - 47s 93ms/step - loss: 0.8251 - accuracy: 0.8020 - val_loss: 14.4155 - val_accuracy: 0.0491\n",
            "Epoch 50/50\n",
            "503/503 [==============================] - 45s 90ms/step - loss: 0.2704 - accuracy: 0.9491 - val_loss: 14.5449 - val_accuracy: 0.0493\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dcae6c2cdf0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RS5-uVzrNDO",
        "outputId": "e7d7532f-3f25-4501-faf4-2cc4519de372"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "336/336 [==============================] - 8s 24ms/step - loss: 14.5449 - accuracy: 0.0493\n",
            "Test Accuracy: 4.934241250157356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(word_index) + 1\n",
        "\n",
        "# Define the RNN model\n",
        "model2 = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=20, input_length=max_sequence_len),\n",
        "    BatchNormalization(),\n",
        "    # Dropout(0.5),\n",
        "    SimpleRNN(25),\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_words, activation='softmax')\n",
        "])\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX-3qpQWMD2l",
        "outputId": "d0279607-1042-44b6-efa2-f636e4c9fc95"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 50, 20)            127280    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 50, 20)            80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " simple_rnn_7 (SimpleRNN)    (None, 25)                1150      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 25)                0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 25)                100       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6364)              165464    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 294074 (1.12 MB)\n",
            "Trainable params: 293984 (1.12 MB)\n",
            "Non-trainable params: 90 (360.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiuj3T3LMD5H",
        "outputId": "84fa6a6e-f842-4b5f-f955-20d6a6b04bbb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "807/807 [==============================] - 69s 82ms/step - loss: 7.5964 - accuracy: 0.0611 - val_loss: 6.9362 - val_accuracy: 0.0881\n",
            "Epoch 2/50\n",
            "807/807 [==============================] - 44s 55ms/step - loss: 6.5735 - accuracy: 0.0899 - val_loss: 6.8961 - val_accuracy: 0.0972\n",
            "Epoch 3/50\n",
            "807/807 [==============================] - 45s 56ms/step - loss: 6.3324 - accuracy: 0.1019 - val_loss: 6.9108 - val_accuracy: 0.1070\n",
            "Epoch 4/50\n",
            "807/807 [==============================] - 44s 54ms/step - loss: 6.1419 - accuracy: 0.1147 - val_loss: 6.9350 - val_accuracy: 0.1167\n",
            "Epoch 5/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 5.9713 - accuracy: 0.1272 - val_loss: 6.9771 - val_accuracy: 0.1242\n",
            "Epoch 6/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 5.8281 - accuracy: 0.1365 - val_loss: 7.0123 - val_accuracy: 0.1289\n",
            "Epoch 7/50\n",
            "807/807 [==============================] - 45s 56ms/step - loss: 5.6948 - accuracy: 0.1445 - val_loss: 7.0654 - val_accuracy: 0.1314\n",
            "Epoch 8/50\n",
            "807/807 [==============================] - 41s 51ms/step - loss: 5.5561 - accuracy: 0.1517 - val_loss: 7.1219 - val_accuracy: 0.1318\n",
            "Epoch 9/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 5.4364 - accuracy: 0.1557 - val_loss: 7.1445 - val_accuracy: 0.1335\n",
            "Epoch 10/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 5.3430 - accuracy: 0.1622 - val_loss: 7.1619 - val_accuracy: 0.1353\n",
            "Epoch 11/50\n",
            "807/807 [==============================] - 44s 54ms/step - loss: 5.2369 - accuracy: 0.1683 - val_loss: 7.2240 - val_accuracy: 0.1335\n",
            "Epoch 12/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 5.1466 - accuracy: 0.1715 - val_loss: 7.2538 - val_accuracy: 0.1337\n",
            "Epoch 13/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 5.0604 - accuracy: 0.1782 - val_loss: 7.2855 - val_accuracy: 0.1344\n",
            "Epoch 14/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 4.9824 - accuracy: 0.1802 - val_loss: 7.3228 - val_accuracy: 0.1337\n",
            "Epoch 15/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 4.9230 - accuracy: 0.1838 - val_loss: 7.3609 - val_accuracy: 0.1344\n",
            "Epoch 16/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.8494 - accuracy: 0.1858 - val_loss: 7.4040 - val_accuracy: 0.1322\n",
            "Epoch 17/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.8009 - accuracy: 0.1885 - val_loss: 7.4492 - val_accuracy: 0.1338\n",
            "Epoch 18/50\n",
            "807/807 [==============================] - 44s 55ms/step - loss: 4.7478 - accuracy: 0.1913 - val_loss: 7.4909 - val_accuracy: 0.1317\n",
            "Epoch 19/50\n",
            "807/807 [==============================] - 41s 51ms/step - loss: 4.6949 - accuracy: 0.1963 - val_loss: 7.5308 - val_accuracy: 0.1315\n",
            "Epoch 20/50\n",
            "807/807 [==============================] - 43s 54ms/step - loss: 4.6363 - accuracy: 0.1961 - val_loss: 7.5908 - val_accuracy: 0.1306\n",
            "Epoch 21/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 4.6047 - accuracy: 0.1984 - val_loss: 7.6359 - val_accuracy: 0.1307\n",
            "Epoch 22/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 4.5418 - accuracy: 0.2053 - val_loss: 7.6881 - val_accuracy: 0.1331\n",
            "Epoch 23/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.5239 - accuracy: 0.2052 - val_loss: 7.7572 - val_accuracy: 0.1281\n",
            "Epoch 24/50\n",
            "807/807 [==============================] - 44s 54ms/step - loss: 4.4905 - accuracy: 0.2065 - val_loss: 7.7768 - val_accuracy: 0.1317\n",
            "Epoch 25/50\n",
            "807/807 [==============================] - 42s 53ms/step - loss: 4.4426 - accuracy: 0.2107 - val_loss: 7.8336 - val_accuracy: 0.1300\n",
            "Epoch 26/50\n",
            "807/807 [==============================] - 44s 55ms/step - loss: 4.3985 - accuracy: 0.2117 - val_loss: 7.8785 - val_accuracy: 0.1287\n",
            "Epoch 27/50\n",
            "807/807 [==============================] - 42s 53ms/step - loss: 4.3688 - accuracy: 0.2145 - val_loss: 7.9169 - val_accuracy: 0.1316\n",
            "Epoch 28/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 4.3560 - accuracy: 0.2173 - val_loss: 7.9599 - val_accuracy: 0.1312\n",
            "Epoch 29/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 4.3394 - accuracy: 0.2146 - val_loss: 7.9652 - val_accuracy: 0.1308\n",
            "Epoch 30/50\n",
            "807/807 [==============================] - 46s 57ms/step - loss: 4.2962 - accuracy: 0.2192 - val_loss: 8.0058 - val_accuracy: 0.1303\n",
            "Epoch 31/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.2979 - accuracy: 0.2180 - val_loss: 8.0439 - val_accuracy: 0.1289\n",
            "Epoch 32/50\n",
            "807/807 [==============================] - 41s 51ms/step - loss: 4.2721 - accuracy: 0.2194 - val_loss: 8.0589 - val_accuracy: 0.1289\n",
            "Epoch 33/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.2424 - accuracy: 0.2212 - val_loss: 8.0730 - val_accuracy: 0.1285\n",
            "Epoch 34/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.2305 - accuracy: 0.2255 - val_loss: 8.1107 - val_accuracy: 0.1303\n",
            "Epoch 35/50\n",
            "807/807 [==============================] - 44s 54ms/step - loss: 4.2178 - accuracy: 0.2245 - val_loss: 8.1261 - val_accuracy: 0.1291\n",
            "Epoch 36/50\n",
            "807/807 [==============================] - 44s 54ms/step - loss: 4.1716 - accuracy: 0.2281 - val_loss: 8.1828 - val_accuracy: 0.1284\n",
            "Epoch 37/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.1782 - accuracy: 0.2301 - val_loss: 8.1879 - val_accuracy: 0.1285\n",
            "Epoch 38/50\n",
            "807/807 [==============================] - 44s 54ms/step - loss: 4.1479 - accuracy: 0.2264 - val_loss: 8.2166 - val_accuracy: 0.1262\n",
            "Epoch 39/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.1318 - accuracy: 0.2318 - val_loss: 8.2331 - val_accuracy: 0.1258\n",
            "Epoch 40/50\n",
            "807/807 [==============================] - 45s 56ms/step - loss: 4.1471 - accuracy: 0.2300 - val_loss: 8.2591 - val_accuracy: 0.1294\n",
            "Epoch 41/50\n",
            "807/807 [==============================] - 46s 58ms/step - loss: 4.1104 - accuracy: 0.2314 - val_loss: 8.2833 - val_accuracy: 0.1249\n",
            "Epoch 42/50\n",
            "807/807 [==============================] - 43s 54ms/step - loss: 4.0861 - accuracy: 0.2351 - val_loss: 8.2849 - val_accuracy: 0.1269\n",
            "Epoch 43/50\n",
            "807/807 [==============================] - 43s 53ms/step - loss: 4.0795 - accuracy: 0.2314 - val_loss: 8.3509 - val_accuracy: 0.1257\n",
            "Epoch 44/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.0678 - accuracy: 0.2381 - val_loss: 8.3318 - val_accuracy: 0.1258\n",
            "Epoch 45/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.0699 - accuracy: 0.2343 - val_loss: 8.3744 - val_accuracy: 0.1257\n",
            "Epoch 46/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.0556 - accuracy: 0.2337 - val_loss: 8.3628 - val_accuracy: 0.1267\n",
            "Epoch 47/50\n",
            "807/807 [==============================] - 44s 54ms/step - loss: 4.0412 - accuracy: 0.2400 - val_loss: 8.4136 - val_accuracy: 0.1251\n",
            "Epoch 48/50\n",
            "807/807 [==============================] - 42s 53ms/step - loss: 4.0363 - accuracy: 0.2369 - val_loss: 8.4032 - val_accuracy: 0.1258\n",
            "Epoch 49/50\n",
            "807/807 [==============================] - 41s 51ms/step - loss: 4.0235 - accuracy: 0.2385 - val_loss: 8.4359 - val_accuracy: 0.1262\n",
            "Epoch 50/50\n",
            "807/807 [==============================] - 42s 52ms/step - loss: 4.0183 - accuracy: 0.2389 - val_loss: 8.4456 - val_accuracy: 0.1261\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd5ac14bb50>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model2.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToD0Iq4NMD7z",
        "outputId": "8ac40d05-4b28-4c92-c52d-66a9171a1d5e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "336/336 [==============================] - 3s 8ms/step - loss: 11.2631 - accuracy: 0.0814\n",
            "Test Accuracy: 8.142897486686707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(word_index) + 1\n",
        "\n",
        "# Define the RNN model\n",
        "model3 = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=30, input_length=max_sequence_len),\n",
        "    SimpleRNN(50, return_sequences=True),\n",
        "    SimpleRNN(10),\n",
        "    Dense(num_words, activation='softmax')\n",
        "])\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79HJH1AMsVNA",
        "outputId": "fa600078-77fc-4e2a-8f05-a94a100c02df"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 50, 30)            187710    \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 50, 50)            4050      \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, 10)                610       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6257)              68827     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 261197 (1020.30 KB)\n",
            "Trainable params: 261197 (1020.30 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)"
      ],
      "metadata": {
        "id": "utv6PcGInFOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model3.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVGAso-2sVap",
        "outputId": "135b9360-1c23-43c7-ad50-06f20719f480"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "336/336 [==============================] - 4s 12ms/step - loss: 10.4323 - accuracy: 0.0362\n",
            "Test Accuracy: 3.619065508246422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to randomly select a starting word from the test set\n",
        "def get_random_start_word(processed_docs):\n",
        "    all_words = ' '.join(processed_docs).split()\n",
        "    return random.choice(all_words)  # Randomly select one word"
      ],
      "metadata": {
        "id": "txcY3VoQlCxj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_words_single(model, start_word, num_prediction_steps, tokenizer, max_sequence_len):\n",
        "\n",
        "    # Initialize the sequence with the start word\n",
        "    current_sequence = start_word\n",
        "    predicted_text = start_word\n",
        "\n",
        "    for _ in range(num_prediction_steps):\n",
        "        # Tokenize the current sequence\n",
        "        sequence_tokens = tokenizer.texts_to_sequences([current_sequence])[0]\n",
        "\n",
        "        # Pad the sequence to the required length\n",
        "        padded_sequence_tokens = pad_sequences([sequence_tokens], maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "        # Predict the next word index\n",
        "        predicted_index = np.argmax(model.predict(padded_sequence_tokens), axis=-1)[0]\n",
        "\n",
        "        # Convert the index back to a word\n",
        "        predicted_word = tokenizer.index_word[predicted_index]\n",
        "\n",
        "        # Append the predicted word to the predicted text\n",
        "        predicted_text += \" \" + predicted_word\n",
        "\n",
        "        # Update the current sequence with the new word\n",
        "        current_sequence += \" \" + predicted_word\n",
        "\n",
        "    return predicted_text"
      ],
      "metadata": {
        "id": "4CWj5A5MlYM3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select a starting word from the processed test documents\n",
        "start_word = get_random_start_word(processed_docs)\n",
        "print(f\"Randomly selected starting word: '{start_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imO9gfnUmx70",
        "outputId": "29353d3f-d5a1-4bf2-8666-32499ffb0c31"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly selected starting word: 'knowledge'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the next 10 words starting from the randomly selected word\n",
        "predicted_text = predict_next_words_single(model2, start_word, 10, tokenizer, max_sequence_len)\n",
        "\n",
        "print(f\"Starting with '{start_word}', predicted text: {predicted_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxFjCn9mm17N",
        "outputId": "736c60aa-a383-4850-96d5-7fb1f2a85b7f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 172ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Starting with 'knowledge', predicted text: knowledge problem data science important term time step called rule applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Character-Level prediction**"
      ],
      "metadata": {
        "id": "17m3idk2AQnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chars = sorted(list(set(\"\".join(processed_docs))))\n",
        "# char_to_index = {char: idx for idx, char in enumerate(chars)}\n",
        "# index_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "# num_chars = len(chars)"
      ],
      "metadata": {
        "id": "q6EWWuILMD-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_sequence_len = 1000\n",
        "\n",
        "# def prepare_sequences(text):\n",
        "#     sequences = []\n",
        "#     next_chars = []\n",
        "#     for i in range(0, len(text) - max_sequence_len, 1):\n",
        "#         seq = text[i:i + max_sequence_len]\n",
        "#         next_char = text[i + max_sequence_len]\n",
        "#         sequences.append([char_to_index[char] for char in seq])\n",
        "#         next_chars.append(char_to_index[next_char])\n",
        "#     return sequences, next_chars\n",
        "\n",
        "# # Prepare sequences for each document\n",
        "# chars_sequences = []\n",
        "# next_chars_list = []\n",
        "# for doc in processed_docs:\n",
        "#     sequences, next_chars = prepare_sequences(doc)\n",
        "#     chars_sequences.extend(sequences)\n",
        "#     next_chars_list.extend(next_chars)"
      ],
      "metadata": {
        "id": "75MB-SOLBt0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sequences_padded = pad_sequences(chars_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "# X = np.array(sequences_padded)\n",
        "# y = to_categorical(next_chars_list, num_classes=num_chars)"
      ],
      "metadata": {
        "id": "SEjwIZl7Bt2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X.shape"
      ],
      "metadata": {
        "id": "ly5avW-TGedP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y.shape"
      ],
      "metadata": {
        "id": "C3zJEtOUJQbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "LexpNHw-Bt50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(y_train.shape)\n",
        "# print(y_test.shape)"
      ],
      "metadata": {
        "id": "0HzDw9VxE2GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the RNN model\n",
        "# char_model1 = Sequential([\n",
        "#     Embedding(input_dim=num_chars, output_dim=100, input_length=max_sequence_len),\n",
        "#     SimpleRNN(100),\n",
        "#     Dense(num_chars, activation='softmax')\n",
        "# ])\n",
        "# char_model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# char_model1.summary()"
      ],
      "metadata": {
        "id": "kpZqDgj6E2I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# char_model1.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)"
      ],
      "metadata": {
        "id": "QJhJ2k_eIz71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss, accuracy = char_model1.evaluate(X_test, y_test)\n",
        "# print(\"Test Accuracy:\", accuracy*100)"
      ],
      "metadata": {
        "id": "B7aNtS2bIz-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the RNN model\n",
        "# char_model2 = Sequential([\n",
        "#     Embedding(input_dim=num_chars, output_dim=300, input_length=max_sequence_len),\n",
        "#     SimpleRNN(128),\n",
        "#     Dense(num_chars, activation='softmax')\n",
        "# ])\n",
        "# char_model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# char_model2.summary()"
      ],
      "metadata": {
        "id": "YHJlqrJlI0BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# char_model2.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)"
      ],
      "metadata": {
        "id": "RgUNQirDI0EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss, accuracy = char_model2.evaluate(X_test, y_test)\n",
        "# print(\"Test Accuracy:\", accuracy*100)"
      ],
      "metadata": {
        "id": "pKUzYi5dI0Gs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}